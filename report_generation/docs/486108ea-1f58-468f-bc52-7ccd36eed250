{"lc": 1, "type": "constructor", "id": ["langchain", "schema", "document", "Document"], "kwargs": {"metadata": {"source": "/home/guanzhideng145/research/ip_portal/patent_kg/patents/1023 outsourced (Done on website).pdf"}, "page_content": "[19] Patents Registry\n\n[11] 30057394 A\n\nThe Hong Kong Special Administrative Region \u9999\u6e2f\u7279\u5225\u884c\u653f\u5340\n\n\u5c08\u5229\u8a3b\u518a\u8655\n\n[12] SHORT-TERM PATENT SPECIFICATION \u77ed\u671f\u5c08\u5229\u8aaa\u660e\u66f8\n\nApplication no. \u7533\u8acb\u7de8\u865f 32021043681.4\n\n[21]\n\n[51] Int. Cl.\n\nG06F 19/00 (2011.01)\n\n[22] Date of filing \u63d0\u4ea4\u65e5\u671f\n\n03.12.2021\n\n[45] Date of publication of grant of patent \u6279\u4e88\u5c08\u5229\u7684\u767c\u8868\u65e5\u671f [73]\n\nProprietor \u5c08\u5229\u6240\u6709\u4eba\n\n08.04.2022\n\nCity University of Hong Kong\n\nTat Chee Avenue, Kowloon\n\nHONG KONG\n\n[72] Inventor \u767c\u660e\u4eba\n\nKei Hang Katie CHAN \u9673\u7d00\u884c\n\nYat Ming WOO \u80e1\u65e5\u660e\n\nJundong LIU \u5289\u4fca\u6771\n\nRuixuan HUANG \u9ec3\u777f\u8ed2\n\nTsz Kin WAN \u6e29\u6893\u5065\n\nAgent and / or address for service \u4ee3\u7406\u4eba\u53ca/\u6216\u9001\u9054\u5730\u5740\n\nIDEA INTELLECTUAL LIMITED\n\n21st Floor, Skyway Centre\n\n23 Queen\u2019s Road West, Sheung Wan\n\nHONG KONG\n\n[54]\n\nMETHOD AND SYSTEM FOR MACHINE LEARNING AND DEEP LEARNING BASED ASSESSMENT OF STROKE\n\n\u57fa\u65bc\u6a5f\u5668\u5b78\u7fd2\u548c\u6df1\u5ea6\u5b78\u7fd2\u7684\u4e2d\u98a8\u8a55\u4f30\u65b9\u6cd5\u548c\u7cfb\u7d71\n\n[57] A machine learning and deep learning-based stroke assessment system, comprising: a clinical data collection module configured to extract and organize stroke patients related clinical data into structured, textual, and image datasets; a machine learning and deep learning-based mortality prediction module configured to analyse the structured and the textual datasets to predict a long- or short- term mortality rate of the stroke patients; a machine learning-based accurate stroke subtype classification module configured to analyse the structured datasets to generate a classification of stroke subtypes suffered by the stroke patients; a machine learning and deep learning-based treatment decision module configured to analyse the structured, textual, and image datasets to generate medical decisions for treating the stroke patients; and a deep learning-based large vessel occlusion (LVO) patient classification module\n\nconfigured to analyse the structured and image datasets to screen out LVO patients from ischemic stroke patients.\n\n\u4e00\u7a2e\u57fa\u65bc\u6a5f\u5668\u5b78\u7fd2\u548c\u6df1\u5ea6\u5b78\u7fd2\u7684\u4e2d\u98a8\u8a55\u4f30\u7cfb\u7d71\uff0c\u5305\u62ec\uff1a\u81e8\u5e8a\u6578\u64da\u63a1\u96c6\u6a21\u584a\uff0c\u88ab\u914d\u7f6e\u70ba\u4e2d\u98a8\u60a3\u8005\u76f8\u95dc\u7684\u81e8\u5e8a\u6578\u64da\u63d0\u53d6\u4e26\u7d44\u7e54 \u6210\u7d50\u69cb\u5316\u3001\u6587\u672c\u5316\u548c\u5716\u50cf\u5316\u7684\u6578\u64da\u96c6\uff1b\u57fa\u65bc\u6a5f\u5668\u5b78\u7fd2\u548c\u6df1\u5ea6\u5b78\u7fd2\u7684\u6b7b\u4ea1\u7387\u9810\u6e2c\u6a21\u584a\uff0c\u88ab\u914d\u7f6e\u70ba\u5206\u6790\u7d50\u69cb\u5316\u548c\u6587\u672c\u6578\u64da\u96c6\uff0c \u4ee5\u9810\u6e2c\u4e2d\u98a8\u60a3\u8005\u7684\u9577\u671f\u6216\u77ed\u671f\u6b7b\u4ea1\u7387\uff1b\u57fa\u65bc\u6a5f\u5668\u5b78\u7fd2\u7684\u6e96\u78ba\u4e2d\u98a8\u4e9e\u578b\u5206\u985e\u6a21\u584a\u88ab\u914d\u7f6e\u70ba\u5206\u6790\u7d50\u69cb\u5316\u6578\u64da\u96c6\u4ee5\u751f\u6210\u4e2d\u98a8\u60a3\u8005 \u6240\u60a3\u4e2d\u98a8\u4e9e\u578b\u7684\u5206\u985e\uff1b\u57fa\u65bc\u6a5f\u5668\u5b78\u7fd2\u548c\u6df1\u5ea6\u5b78\u7fd2\u7684\u6cbb\u7642\u6c7a\u7b56\u6a21\u584a\uff0c\u88ab\u914d\u7f6e\u70ba\u5206\u6790\u7d50\u69cb\u5316\u3001\u6587\u672c\u548c\u5716\u50cf\u6578\u64da\u96c6\uff0c\u4ee5\u751f\u6210\u6cbb\u7642 \u4e2d\u98a8\u60a3\u8005\u7684\u91ab\u7642\u6c7a\u7b56\uff1b\u4ee5\u53ca\u57fa\u65bc\u6df1\u5ea6\u5b78\u7fd2\u7684\u5927\u8840\u7ba1\u9589\u585e (LVO) \u60a3\u8005\u5206\u985e\u6a21\u584a\uff0c\u88ab\u914d\u7f6e\u70ba\u5206\u6790\u7d50\u69cb\u5316\u548c\u5716\u50cf\u6578\u64da\u96c6\uff0c\u4ee5\u5f9e\u7f3a \u8840\u6027\u4e2d\u98a8\u60a3\u8005\u4e2d\u7be9\u9078\u51fa LVO \u60a3\u8005\u3002\n\nHK 30057394 A\n\nMETHOD AND SYSTEM FOR MACHINE LEARNING AND DEEP LEARNING BASED ASSESSMENT OF STROKE \u57fa\u65bc\u6a5f\u5668\u5b78\u7fd2\u548c\u6df1\u5ea6\u5b78\u7fd2\u7684\u4e2d\u98a8\u8a55\u4f30\u65b9\u6cd5\u548c\u7cfb\u7d71\n\n5\n\nInventors: Kei Hang Katie CHAN, Yat Ming WOO, Ruixuan HUANG, Jundong LIU, and Tsz Kin WAN\n\nField of the Invention:\n\n10\n\n[0001] The present invention relates to the application of machine learning and deep learning-based methods and systems for assessing and predicting strokes in a population using medical data.\n\nBackground of the Invention:\n\n15\n\n20\n\n[0002] Strokes are some of the leading causes of death and disability across the globe.\n\nThere are 13.7 million new stroke cases worldwide every year, and 5.5 million people die from strokes each year. Moreover, strokes are some of the primary causes of disability and death worldwide. The Hong Kong Special Administrative Region (HKSAR) is facing a significant challenge in relation to strokes as a group it is currently the 4th leading cause of death in HKSAR. Each year, there are approximately 25,000 new stroke patients, accounting for 0.8% of its population. Specifically, every year, 3.2% of individuals aged 65 years and older suffered from strokes, which resulted in more\n\nthan 1,000 deaths as direct causes.\n\n25\n\n30\n\n[0003] A stroke occurs when a blood clot blocks the blood vessels that carries oxygen\n\nand nutrients to the brain. As a result, brain cells are irreversibly damaged and begin to die within a few minutes. Thus, stroke patients' mortality and disability rates are very high. There are two sub-types of strokes: ischemic strokes and haemorrhagic strokes. Ischemic strokes account for more than 60% of stroke cases. They are due to blood vessels in the brain becoming too narrow or blocked by plaques and thereby result in insufficient blood supply to the brain. In particular, large vessel occlusions (LVOs) are a subtype of ischemic stroke where either the proximal intracranial anterior or the posterior circulation are obstructed. LVO can cause a variety of serious neurological symptoms, including facial paralysis, dyskinesia, and language disorders.\n\nHaemorrhagic strokes, however, account for approximately 30% of stroke cases and are\n\nDocket No. UM1104HK00\n\n1\n\nHK 30057394 A\n\ndue to the rupture of blood vessels resulting in blood flooding into the brain. This causes severe damage to brain cells and can even result in cell death.\n\n5\n\n[0004] Medical data is diverse and highly complex. The use of machine learning and\n\ndeep learning methods to analyse medical data including structured, text, and images could better predict and help prevent strokes more effectively and thereby provide stroke patients with a more accurate diagnosis and more effective treatment. Therefore, a better stroke assessment system based on machine learning and deep learning is wanted in the art. Such stroke assessment system would be beneficial to both medical providers and patients as it can provide doctors with effective diagnostic support, medical decision-\n\n10\n\nmaking assistance, and in turn provide better services for stroke patients as a result.\n\nSummary of the Invention:\n\n15\n\n[0005] It is an objective of the present invention to provide a stroke assessment system\n\nbased on machine learning and deep learning that addresses the aforementioned needs in the art. In accordance with one aspect, the stroke assessment system comprises a clinical data collection module, a mortality prediction module, an accurate stroke subtypes classification (ICD-9 prediction) module, a treatment decision module, and a\n\nLVO patient\u2019s classification module.\n\n20\n\n[0006] In accordance with various embodiments, the stroke assessment system uses structured data, image data, textual report data as input to each of the modules, through data pre-processing and data analysis steps, to complete the function of each of the module.\n\n25\n\n[0007] The mortality prediction module predicts the mortality of one or more stroke\n\npatients. The module receives structured data (including diagnosis information, biological test data, etc.) and textual data (including patient clinical reports, radiology test reports, etc.) of the stroke patients as the module's input, processes the structured data through one or more networks of multi-level machine learning model, deep learning model, and/or ensemble models thereof, then generates and outputs short-term\n\nor long-term probabilities of deaths of the stroke patients.\n\n30\n\n[0008] The accurate stroke subtypes classification module predicts specific subtypes of\n\nstroke for the stroke patients. The module receives clinical data of the stroke patients as\n\nDocket No. UM1104HK00\n\n2\n\nHK 30057394 A\n\nthe module's input, processes the clinical data through one or more networks of machine learning model and deep learning model, then generates and outputs specific subtypes\n\nof the stroke.\n\n5\n\n[0009] The treatment decision module generates medication and treatment recommendations for the stroke patients. The module receives basic physical information, biological test data, radiology test data, and textual reports of the stroke patients as input, processes these data through a deep learning network, then generates and outputs the medication and treatment recommendations that enable the patient to\n\n[0009] The\n\nobtain the best prognostic effect.\n\n10\n\n[0010] The LVO patient classification module is an end-to-end LVO screening tool based on a deep learning model. The module receives radiological examination data and clinical data of one or more of the stroke patients identified by ischemic strokes as input, processes the radiological examination data and clinical data through a deep learning network, generates and outputs a probability of each of the stroke patients being a LVO\n\n15\n\npatient.\n\nBrief Description of the Drawings:\n\n20\n\n[0011] The scope of the present invention is not limited to the content of the accompanying drawings provided. In order to make the advantages of the present invention easier to understand, aspects and embodiments of the present invention are illustrated in the drawings, in which:\n\n[0012]\n\n[0012] FIG. 1 illustrates the overall structure of a stroke assessment system in accordance with one embodiment of the present invention;\n\n25\n\n[0013]\n\nFIG. 2 illustrates the data sources required by the stroke assessment system; FIG. 3 illustrates the pre-processing pipeline of structured data used in the\n\n[0014]\n\nstroke assessment system;\n\n[0015]\n\nFIG. 4 illustrates the pre-processing pipeline of textual data used in the stroke\n\nassessment system;\n\n30\n\n[0016]\n\n[0016] FIG. 5A and FIG. 5B illustrate the pre-processing pipeline of image data used in the stroke assessment system;\n\nDocket No. UM1104HK00 3\n\nHK 30057394 A\n\n[0017] FIG. 6 illustrates the machine learning and deep learning models\u2019 training, validating, and testing pipeline for structured data in accordance with one embodiment of the present invention;\n\n[0017]\n\n5\n\n[0018]\n\n[0018] FIG. 7 illustrates the machine learning, deep learning and ensemble models\u2019 training, validating, and testing pipeline for structured and textual data in accordance with one embodiment of the present invention;\n\n[0019]\n\nFIG. 8 illustrates the deep learning model\u2019s training, validating, and testing\n\npipeline for structured and image data in accordance with one embodiment of the\n\npresent invention; and\n\n10\n\n[0020]\n\nFIG. 9 illustrates the machine learning, deep learning, and reinforcement\n\nlearning models\u2019 training, validating, and testing pipeline for structured data, image data and textual data in accordance with one embodiment of the present invention.\n\nDetailed Description:\n\n15\n\n20\n\n[0021]\n\nIn the following detailed description, the figures are referred to in explaining\n\nthe detailed designs of the various embodiments of the present invention. Certain figures and descriptions provide examples of some modules and models in the stroke assessment systems in accordance with the various embodiments, so that ordinarily- skilled persons in the art can better understand the present invention, better adopt its embodiments, and use them more effectively. It should be understood that various implementations and logical and structural modifications to the modules of the stroke assessment system are readily realizable without undue experimentation and departure\n\nfrom the spirit of the present invention.\n\n25\n\n[0022] The following detailed description is intended to provide an exemplary\n\ndescription of the present invention, rather than a restrictive description. When introducing the stroke assessment system and its modules, the articles \u201ca\u201d, \u201can\u201d, and \u201cthe\u201d are intended to mean that there are one or more elements. The terms \u201ccomprising\u201d, \u201cincluding\u201d, and \u201cfor example\u201d are intended to be inclusive and mean that there may be\n\nother elements in addition to the listed elements.\n\n30\n\n[0023]\n\nIn the referenced figures, there are different modules and their function\n\nrealization processes. The various elements in the figures are connected by arrows or\n\nDocket No. UM1104HK00\n\n4\n\nHK 30057394 A\n\n5\n\n10\n\nsurrounded by boxes. This does not mean that the related modules have a geographical\n\nrelationship, but instead the arrows indicate the logical relationship between the boxed content. These connections can be realized by a corresponding application, a piece of code, or commands executed by multiple pieces of code stored in multiple memories. [0024] All or portions of the embodiments disclosed herein may be implemented using one or more of specially configured computing devices, computer processors, or electronic circuitries including but not limited to graphics processing units (GPUs), application specific integrated circuits (ASICs), field programmable gate arrays (FPGAs), and other programmable logic devices configured or programmed according to the teachings of the present disclosure. Computer instructions or codes running in the computing devices, computer processors, or programmable logic devices can readily be prepared by practitioners skilled in the software or electronic art based on the teachings of the present disclosure. The aforesaid one or more computing devices may include one or more of server computers, personal computers, laptop computers, mobile\n\n15\n\ncomputing devices such as smartphones and tablet computers.\n\n20\n\n[0025] The electronic embodiments include computer-readable storage media\n\nhaving the computer instructions or codes stored therein, which can be used to configure or program the computing devices, computer processors, or electronic circuitries to perform any of the processes of the present invention; and to store data generated by any of the processes of the present invention. The computer-readable storage media include, but are not limited to, floppy disks, optical discs, Blu-ray Disc, DVD, CD- ROMs, magneto-optical disks, solid-state discs, ROMs, RAMs, SRAMs, DRAMs, flash memory devices, electrically programmable read-only memories (EPROMs), electrically erasable programmable read-only memories (EEPROMs), or any type of\n\n25\n\nmedia or devices suitable for storing instructions, codes, and/or data.\n\n30\n\n[0026] Various embodiments of the present invention also may be implemented in\n\ndistributed computing environments and/or Cloud computing environments, wherein the whole or portions of computer instructions or codes are executed in distributed fashion by one or more processing devices interconnected by a communication network, such as an intranet, Wide Area Network (WAN), Local Area Network (LAN), the\n\nInternet, and other forms of data transmission medium.\n\nDocket No. UM1104HK00\n\n5\n\nHK 30057394 A\n\n[0027] The programming language used to implement the embodiments disclosed herein is not limited, and the functions of each module in the systems in accordance with the various embodiments can be implemented by one or more programming languages, such as R, C, C++, Python, Java, etc.\n\n5\n\n[0028] The data processing described herein is only used as a sample, and its description is not used as a data use restriction of the present invention. Data types and data contents other than the data sample also have the possibility of being loaded by the various embodiments of the present invention and run smoothly.\n\n10\n\n[0029] The numbers in the boxes of each element in the system are only used to make the explanation of the systems in accordance with the various embodiments more convenient. In all the figures, the same number represents the same element, including alternative embodiments of the same element. Numbers are only used for labelling, and the size of their value does not represent the relationship between elements.\n\n15\n\n20\n\n[0030] Referring to FIG. 1 for the following description. In accordance with one\n\nembodiment, a stroke assessment system is provided and it comprises a medical data collection module 104 for receiving combinations of one or more of three different types of data, which are structured data element 101, textural data element 102 and image data element 103. The data collection module 104 may save in a data storage device, database or hardware computing device with processors and memory. The stroke assessment system further comprises a number of machine learning module; which are mortality prediction module 105, ICD-9 code prediction module 106, treatment module 107 and LVO prediction module 108. These modules are configured to receive the data from\n\ndata collection module 104.\n\n25\n\n[0031] Usually, the data collection module 104 is configured to receive the data from\n\none or more data sources. The received data may be saved in the data storage device, database or hardware computing device as an unstructured data set. For the structured data element 101, textural data element 102, and image data element 103, a unique key or ID is required to identify each individual record or patient\u2019s information. This unique key or ID is also used to make sure the data can be merged and synchronized correctly.\n\n30\n\nIn general, the unique key or ID may include record key, episode key, and patient key\n\nDocket No. UM1104HK00\n\n6\n\nHK 30057394 A\n\nto make sure each data merge is done with the correct records. The data merging may be one to one, one to many, many to one or many to many.\n\n5\n\n[0032] The data collection module 104 is configured for data pre-processing the data from unstructured data to structured data. The data collection module 104 is further configured for converting features into numerical representations or using one-hot- coding in processing the data; and executing table merging in the data.\n\n10\n\n[0033]\n\nIn the various embodiments, structured data element 101 is about information\n\nof patients and the clinical record. For example, the information may contain gender, age, weight, height, date and time of patient admission, laboratory test data, diagnosis name or ID designed by the hospital, indication on the diagnosis, patient may have principal diagnosis or non-principal diagnosis etc., and provide to the data collection module 104 as unstructured data. In general, patient demographics information in the structured data element 101 may also include a key for each patient to recognize and merge with other modules.\n\n15\n\n20\n\n[0034]\n\nIn the various embodiments, textual data element 102 contains text reports\n\nsuch as radiology examination text report, supplementary amended report, clinical and discharge note or any related clinical report. The radiology examination report may include the body text and the standardized code of examination of the radiology examination report. The clinical and discharge note may include the dates of discharge and/or admission and the body text of the clinical documentation. For the clinical report, a sequence order number by reference datetime among all clinical result datasets for identifying the clinical report record is necessary to ensure its correctness. For merging the patient records, an episode key assigned to the patient upon attendance for the examination and a unique patient key assigned to each individual patient are required\n\n25\n\nby the data collection module 104.\n\n30\n\n[0035]\n\nIn the various embodiments, image data element 103 contains image data for\n\nthe patients fulfilling some criteria by hospital, for example the CT Brain for brain plain. In this case, the CT Brain may contain computed and compressed tomography images, wherein the image compression may be made under a lossy-compression ratio, which means the quality of the images may be affected. In general, a sequence order number\n\nwhich references time among all image data datasets for identifying the image test is\n\nDocket No. UM1104HK00\n\n7\n\nHK 30057394 A\n\nnecessary to ascertain the patients\u2019 examination attendances for the data collection module 104.\n\n[0036] The mortality prediction module 105 is configured to predict the mortality of\n\n5\n\n10\n\n15\n\nstroke patients from input received from data collection module 104. The structured data and textual data used in mortality prediction module 105 are received from data collection module 104. The data in data pre-processing element 109 includes, but is not limited to, stroke patients\u2019 demographics, diagnosis, family medical history, laboratory results and radiology reports, all of which are then used as input in the machine learning and deep learning models 113. The demographics data includes, but is not limited to, gender and age. Family medical history data may contain indications of new symptoms or illnesses in a family through mapping of International Classification of Primary Care (ICPC) Code or other standard codes such as the ICD-9 code. The laboratory result data includes the results from chemical pathology test, haematology test, immunology test, microbiology, test and virology test. Due to the different testing methods and equipment, the detection unit of the sample needs to be unified in the process of data summarizing and pre-processing. As for the radiology examination report, body text of the\n\nexamination reports, standardized codes of examinations are included.\n\n20\n\n25\n\n[0037] The machine learning and deep learning models 113 include, but are not\n\nlimited to, one or more of random forest (RF) classifier, Adaptive Boosting (AdaBoost), Extremely randomized trees (ExtraTree) classifier, XGBoost classifier, and TabNET, which constitute the first layer of the prediction model of the machine learning and deep learning models 113. The second layer of the prediction model of the machine learning and deep learning models 113 is an ensemble model, which uses the input data to the machine learning and deep learning models 113 and results from the first layer as its input, then generates and outputs the probability of mortality 117. The output result may have different timescale of the mortality prediction such as with 30-day, 6-month, or\n\nlonger.\n\n30\n\n[0038] The ICD-9 prediction module 106 is configured to predict the specific subtype of strokes for stroke patients from input received from data collection module 104. The structured data used in ICD-9 Prediction module 106 are received from data collection module 104. The data in data pre-processing element 110 includes, but is not\n\nDocket No. UM1104HK00\n\n8\n\nHK 30057394 A\n\n5\n\nlimited to, stroke patients\u2019 demographics, diagnosis, family medicine and laboratory\n\nresults, all of which are then used as input in the machine learning and deep learning models 114. The demographics data may contain gender, age, weight, height, etc. The family medical history data may contain indications of new symptoms or illnesses in a family through mapping of International Classification of Primary Care (ICPC) Codes or other standard codes such as the ICD-9 code. The laboratory result data includes the results from chemical pathology test, haematology test, immunology test, microbiology, test, and virology test. Due to the different testing methods and equipment, the detection unit of the sample needs to be unified in the process of data summarizing and pre-\n\n10\n\nprocessing.\n\n15\n\n[0039] The machine learning and deep learning model 114 is configured to\n\ncommunicate with the ICD-9 prediction model data pre-processing element 110. The machine learning and deep learning models 114 include, but are not limited to, one or more of RF classifier, AdaBoost, ExtraTree classifier, XGBoost classifier, and DNN or CNN models. Applying different models and parameters is required to achieve the best performance and output to provide accurate stroke subtype classification 118. The output result is the specific subtype of stroke which corresponds to a particular ICD-9\n\ncode.\n\n20\n\n25\n\n30\n\n[0040] The treatment decision module 107 is configured to generate medication and\n\ntreatment recommendations for stroke patients from input received from the data collection module 104. The structured data, textual data, and image data used in Treatment module 106 are received from data collection module 104. The data in data pre-processing element 111 includes, but is not limited to, stroke patients\u2019 demographics, diagnosis, family medical history, laboratory results, CT / MRI images, drug use, and medical procedures, all of which are then used as input in the reinforcement learning model 115. The demographics data may contain gender, age, weight, and height etc. The family medical history data may contain indications of new symptoms or illnesses in a family through mapping of ICPC Codes or other standard codes such as ICD-9 code. The laboratory result data includes the results from chemical pathology test, haematology test, immunology test, microbiology, test and virology test. Due to the\n\ndifferent testing methods and equipment, the detection unit of the sample needs to be\n\nDocket No. UM1104HK00\n\n9\n\nHK 30057394 A\n\n5\n\nunified in the process of data summarizing and pre-processing. The CT Brain for brain\n\nplain are in the format of Digital Imaging and Communications in Medicine (DICOM) and may contain computed and compressed tomography images, wherein the image compression may be made under a lossy-compression ratio, which means that the quality of the images may be affected. The drug use and medical procedures should provide the item code defined by government or hospital, drug name, dosage, and strength of the item for the drug. Also, dispensing date, duration, and the route form of the drug intake by the patient should also be included in the data of the data pre-\n\nprocessing element 111.\n\n10\n\n15\n\n[0041] Reinforcement learning model 115 is based on the SVM model or other machine learning methods or deep learning models such as DNN and CNN. Different models and parameters may be applied to achieve the best performance on the medication and treatment recommendations 119. The output medication and treatment recommendations 119 includes drug name, dosage, duration, surgical operations and other clinical treatments for each patient which enable the patient to obtain the best prognostic effect.\n\n20\n\n25\n\n[0042]\n\nFor the LVO prediction module 108, the certain system can provide the\n\nprobability that the patient is an LVO patient by receiving data from data collection module 104. The structured data and image data used in LVO prediction module 108 are derived from data collection module 104. The data in data pre-processing element 112 includes, but is not limited to, stroke patients\u2019 demographics, diagnosis and CT images, all of which are then used as input in the deep learning models 116. The demographics data may contain gender, age, weight, and height etc. Family medical history data, may contain indications of new symptoms or illnesses in a family through mapping of International Classification of Primary Care (ICPC) Codes or other standard codes such as ICD-9 code. The CT Brain for brain plain may contain computed tomography images, the Image compression may follow a ratio leveraged to have lossy\n\ncompression, which meaning the quality of the images may affected.\n\n30\n\n[0043] The deep learning models 116 receive input from the data pre-processing element 112. The deep learning models 116 comprises at least a deep learning model based on CNN, and/or a three-dimensional CNN (3DCNN) that may be one or more of\n\nDocket No. UM1104HK00 10\n\nHK 30057394 A\n\n5\n\nDensely Connected Convolutional Networks (DenseNets), EfficientNets, Squeeze-and-\n\nExcitation Networks (SENets or SEResNets) and a Vision Transformer (ViT). The deep learning models 116 apply different models and parameters to achieve the best performance and output LVO patient\u2019s classification 120. The output LVO patient\u2019s classification 120 is provided a classification such as large-artery atherosclerosis, cardio embolism, small-vessel occlusion, and others (which are strokes of other determined\n\netiology and stokes of undermined etiology).\n\n[0044]\n\nFIG. 2 illustrates the data sources that by the stroke assessment system. The\n\n10\n\n15\n\ndata collection process 206 includes the basic data collection 201 of the patient, the admission and discharge data 202 of the patient, the diagnosis information 203 from the doctor, the examination result 204 from the biological examination, and the examination result 205 from the imaging examination, etc. There are many types of data collected in the data collection process 206, including structured data, textual data, and image data. Among them, structured data can be integer numbers, float numbers, numbers in string format, or empty; textual data requires that the text language be English; image data requires that the data be CT scan images or MRI images of the brain. The data collected through the data collection process 206 is called medical data 104, or raw data. The raw data 301 in FIG. 3, the raw data 401 in FIG. 4, and the Digital Imaging and Communications in Medicine 501 in FIG. 5 are all part of the data collected by the data\n\n20\n\ncollection process 206.\n\n[0045]\n\nFIG. 3 illustrates the pre-processing pipeline of structured data used in the\n\n25\n\n30\n\nstroke assessment system. Raw data 301 are the data received from data collection process 206. In certain embodiments, it is configured to generate a processed dataset for the machine learning models and deep learning models 113, 114, 115 and 116. The raw data have patients\u2019 information and three different types of data which are structured data, textural data, and image data. Of which, only the structured data is sent to first filter 302. The first filter 302 is used to filter non-stroke patients as they are not within the scope of this system. Some patients are classified as suspected patients because they have stroke-like symptoms, but after a series of clinical examinations, the diagnosis is cancelled or diagnosed with other diseases. Only samples that have been principle\n\ndiagnosed as a stroke can pass through the first filter 302. The second filter 303 pre-\n\nDocket No. UM1104HK00\n\n11\n\nHK 30057394 A\n\nprocesses the data to remove samples with excessive missing values as well as other\n\n5\n\n10\n\n15\n\nirrelevant samples. For a given feature, a certain threshold of missing values will be\n\napplied to eliminate samples with a missing rate equal to or greater than the threshold. Since there are different objectives for each of the four modules, the models present in the different modules have different requirements for the usage of the structured data. The models of each module select data related to their purpose as relevant data, and irrelevant data are excluded in that particular element. The data imputation 304, which receives data from the second filter 303, performs the imputation of missing data. Imputation is the process of replacing missing data (including \u201cNA\u201d, \u201cNone\u201d, \u201cNot record\u201d etc.) with substituted values. Imputation methods including min-max imputation, mean imputation, non-negative matrix factorization, regression imputation, stochastic imputation, or multiple imputation method are applied in the data imputation 304. The data imputation 304 provides the imputed data to data normalization 305. Normalization refers to the process of adjusting values measured on different scales to a notionally common scale. Continuity data for different data ranges are redistributed within the range from 0 to 1 by data normalization 305 according to the distribution characteristics of the data itself. The data normalization 305 provides the normalized data to feature selection 306. The feature selection 306 is a function generator element which provides the optimize data to models. Redundant data are eliminated by different feature selection methods. Different feature selectors are applied to calculate the importance of each feature, and features are selected according to the importance\n\n20\n\nranking. The output of the feature selection 306 is called the processed structured data\n\n307.\n\n25\n\n30\n\n[0046]\n\nFIG. 4 illustrates the pre-processing pipeline of textual data used in the stroke\n\nassessment system. This element is a component of the elements 109 and element 111 in FIG. 1. The raw data 401 is the textual data part collected by the data collection process 206. The raw data 401 is to pass through 3 layers of filters. The first filter 402 is used to filter non-stroke patients, which are irrelevant within the scope of the stroke assessment system. Some patients are classified as suspected patients because they have stroke-like symptoms, but after a series of clinical examinations, the diagnosis is\n\ncancelled or are diagnosed with other diseases. Only samples that have been principle\n\nDocket No. UM1104HK00 12\n\nHK 30057394 A\n\n5\n\n10\n\ndiagnosed as a stroke can pass through the first filter 402. The data passing through the\n\nfilter 402 comes to the filter 403 which eliminates irrelevant reports. In the text report of the medical imaging examination, there are error reports, non-final reports, or other reports with insufficient information for data processing, and these data cannot pass the filter 403. In addition, because the patient may take multiple CT or MRI during the entire admission treatment period, it reflects the condition of the disease at different stages during the treatment process. For example, in element 109, the mortality of a patient is output after the first round of examinations after admission to the hospital. Therefore, a textual data that can represent a confirmed stroke or the first effective imaging examination after a stroke is selected to be used in the follow-up study. However, in element 111, since the aim is to predict the patient's treatment, one or more data are selected for use according to the patient's treatment stage. The third filter 404 is used to pre-process the selected text data. It can delete stop words that do not contribute to the meaning of the research report, and organize the format of the text\n\n15\n\nreport. The sample after three filters is called processed textual data 405.\n\n20\n\n25\n\n[0047]\n\nFIG. 5A is a schematic block diagram illustrating one embodiment of a data\n\nextracting module. The DICOM from element 501 is the input of the first filter 502, which excludes the slides with specific meta information from DICOM, including non- brain exam body parts, RGB planes, missing Image Position or Image Orientation information, diagnosis and patient ID. The following image normalization 503 is used to normalize the image size. All images are standardized as squares, such as 512 pixels * 512 pixels pictures. The input of the second filter are the processed structured data 307 from the structured data pre-processing process 300, and the output from images normalization 503, which can screen out the samples that only have one of structured data and image data. The images labelling 505 is designed to select and provide labels to the image that represents a confirmed stroke or the first effective imaging examination after a stroke is selected, because of the multi-level (patient level, accession level, and episode level) of images. The output of the images labelling 505 is the\n\nprocessed image data 506.\n\n30\n\n[0048]\n\nFIG. 6 illustrates the machine learning and deep learning models\u2019 training,\n\nvalidating and testing pipeline for structured data. This element is a component of the\n\nDocket No. UM1104HK00 13\n\nHK 30057394 A\n\n5\n\nelement 114 in FIG. 1. After receiving data from model 307, data are randomly divided\n\ninto training set 602, validation set 603 and testing set 604. Usually, the ratio of training set 602 may be imbalanced. Imbalanced data is a challenge for predictive modelling since most of algorithms are designed to handle balanced data. The Synthetic Minority Over-sampling TEchnique (SMOTE) is applied in element 602, 603 and 604 to handle the imbalanced data. AUROC, accuracy AUPRC, precision, recall, and f1-score are applied to measure the performance of models in element 603 and 604. The models with good performance are stored into element 607.\n\n10\n\n15\n\n20\n\n25\n\n[0049] FIG. 7 illustrates the machine learning, deep learning and ensemble models\u2019 training, validating and testing pipeline for structured and textual data. This element is a component of the element 113 in FIG. 1. The processed structured data 307 is from the structured data pre-processing process 300, and the processed textual data 405 is from the textual data pre-processing process 400. Element 701 is a combination filter, which can screen out the samples that only have one of structured data and textual data. All the data passing through the filter element 701 are mixed data 703, where the structured data and textual data are filtered structured data 702 and filtered textual data 704, respectively. The filtered structured data needs to go through machine learning and deep learning pipelines. The data are first randomly divided into training set 705, validation set 706 and testing set 707. The training set 705 and the validation set 706 are used to train various machine learning and deep learning models, and then the testing set 707 is added for model verification 702, and finally trained machine learning and deep learning models are obtained and saved into element 715. As for the filtered textual data 704, the data is first divided into training set 708, validation set 709 and testing set 710. The training set 708 and the validation set 709 are used to train various machine learning and deep learning models, and then the testing set 714 is added for model verification 710, and finally trained deep learning models are obtained and saved into element 716. The input data of ensemble models 717 is mixed data 703. All the ensemble models have a structure of two or more layers, the first layer is the\n\ncombination of trained models from element 715 and 716, the ensemble methods\n\n30\n\ninclude, but are not limited to, various voting models and stacking models.\n\nDocket No. UM1104HK00\n\n14\n\nHK 30057394 A\n\n[0050]\n\nFIG. 8 illustrates the deep learning model\u2019s training, validating and testing\n\n5\n\n10\n\npipeline for structured and image data. This element is a component of the element 116 in FIG. 1. The processed structured data 307 is from the structured data pre-processing process 300, and the processed textual data 506 is from the textual data pre-processing process 500. Element 801 is a combination filter, which can screen out the samples that have only either structured data or image data. The data passing through the filter 801 are divided into structured data training set 802 and image data training set 803, respectively. The training sets 802 and 803 are mixed into concatenating data and become the input of the 3DCNN and ViT training 805. A plurality of backbones is used and compared in the 3DCNN, including Densely Connected Convolutional Networks (DenseNets), EfficientNets, Squeeze-and-Excitation Networks (SENets or SEResNets). We first input the image data into the models and then concatenate the embeddings from the last fully connected layers with clinical data. The prediction outputs of the 3DCNN and ViT are ensembled 806. The LVO classifier is tested using the testing dataset. To improve performance and reduce generalization errors of the LVO classifier, test-time\n\n15\n\naugmentation (TTA) and prediction averaging are added during the inference 807.\n\n20\n\n25\n\n[0051] FIG. 9 illustrates the machine learning, deep learning and reinforcement learning models\u2019 training, validating and testing pipeline for structured data, image data and textual data. This element is a component of the element 115 in FIG. 1. The processed structured data 307 is from the structured data pre-processing process 300, the processed textual data 405 is from the textual data pre-processing process 400, and the processed image data is from the image data pre-processing process 500. Element 901 is a combination filter configured to screen out the samples having one of structured data, textual data, and image data. All the data passing through the filter element 901 are mixed data 902, where the structured data, image data, and textual data are filtered structured data 903, filtered image data 904, and filtered textual data 905, respectively. The filtered structured data is to pass through the machine learning and deep learning pipelines. The data is first divided into training set 906, validation set 907 and testing set 908. The training set 906 and the validation set 907 are used to train various machine learning and deep learning models, and then the testing set 908 is added for model\n\n30\n\nverification 916. Finally, the trained machine learning and deep learning models are\n\nDocket No. UM1104HK00 15\n\nHK 30057394 A\n\nobtained and saved into element 921. As for the filtered image data 904, the data is first\n\n5\n\n10\n\ndivided into training set 909, validation set 910 and testing set 911. The training set 909 and the validation set 910 are used to train various machine learning and deep learning models, and then the testing set 911 is added for model verification 918, and finally trained deep learning models are obtained and saved into element 922. As for the filtered textual data 905, the data is first divided into training set 912, validation set 913 and testing set 914. The training set 912 and the validation set 913 are used to train various machine learning and deep learning models, and then the testing set 914 is added for model verification 920, and finally trained deep learning models are obtained and saved into element 923. The input data of reinforcement learning models 924 are mixed data\n\n902 and output data from trained models 921, 922, and 923.\n\n15\n\n[0052] The foregoing description of the present invention has been provided for the purposes of illustration and description. It is not intended to be exhaustive or to limit the invention to the precise forms disclosed. Many modifications and variations will be apparent to the practitioner skilled in the art.\n\n[0053] The embodiments were chosen and described in order to best explain the principles of the invention and its practical application, thereby enabling others skilled in the art to understand the invention for various embodiments and with various modifications that are suited to the particular use contemplated.\n\n20\n\nDocket No. UM1104HK00\n\n16\n\nHK 30057394 A\n\nClaims:\n\nWhat is claimed is:\n\n5\n\n1.\n\nA machine learning and deep learning-based stroke assessment system,\n\ncomprising:\n\n10\n\na clinical data collection module configured to extract stroke patients\n\nrelated clinical data from one or more data sources, organize the extracted stroke patients related clinical data into one or more of structured, textual, and image datasets; and preserve patient identity information or encrypted identity information in the clinical data records to ensure that the clinical data records of same patient are having same patient identifier and the clinical data records\n\nof same episode are having same episode key;\n\n15\n\na machine learning and deep learning-based mortality prediction module configured to analyse the structured datasets and the textual datasets to predict a long- or short-term mortality rate of the stroke patients referred to in the extracted stroke patients related clinical data;\n\n20\n\na machine learning-based accurate stroke subtype classification module configured to analyse the structured datasets to generate a classification of stroke subtypes suffered by the stroke patients referred to in the extracted stroke patients related clinical data;\n\n25\n\na machine learning and deep learning-based treatment decision module configured to analyse the structured datasets, the textual datasets, and the image datasets to generate medical decisions for treating the stroke patients; and\n\na deep learning-based large vessel occlusion (LVO) patient classification module configured to analyse the structured datasets and the image datasets to screen out LVO patients from ischemic stroke patients;\n\nwherein each of the modules comprises one or more computer\n\n30\n\nprocessors specially configured by one or more machine instructions stored in one or more non-transient memory circuities.\n\nDocket No. UM1104HK00 17\n\nHK 30057394 A\n\n5\n\n2. The system of claim 1, wherein each of the modules comprises one or more supervised machine learning and deep learning models configured specifically to process and analyse one or more of the structured, textual, and image datasets organized from the clinical data.\n\n3. The system of claim 1,\n\nwherein the mortality prediction module comprises one or more\n\nensemble models; and\n\n10\n\nwherein the ensemble models are logical multi-level structures in which one or more higher-level models are configured to process input data to the mortality prediction module and output data from one or more lower-level models in the logical multi-level structures.\n\n15\n\n4. The system of claim 1,\n\nwherein the treatment decision module comprises one or more reinforcement learning models; and\n\n20\n\nwherein the reinforcement learning models are logical multi-level structures in which one or more higher-level models are configured to process input data to the treatment decision module and output data from one or more lower-level models in the logical multi-level structures.\n\n5.\n\nThe system of claim 1, further comprising:\n\n25\n\na first filter configured to select from the structured dataset data records of patients classified as stroke patients as principal diagnosis data records; and eliminate from the structured dataset data non-principal diagnosis data records;\n\n30\n\na second filter configured to eliminate from the structured dataset data records with excessive missing values, and/or of irrelevant samples; wherein sample relevancy is based on selected demographics, diagnosis, family history, and laboratory results; and wherein the data records with excessive missing\n\nDocket No. UM1104HK00\n\n18\n\nHK 30057394 A\n\nvalues are data records having a number of missing values larger than a defined threshold for number of missing values;\n\n5\n\na data imputation module configured to apply one or more of min-max imputation method, mean imputation method, non-negative matrix factorization method, regression imputation method, stochastic imputation method, and multiple imputation method to replace the missing values in the structured dataset data records; and\n\n10\n\na data normalization module configured to adjust one or more values in one or more of the structured datasets data records to within a range from 0 to 1.\n\nThe system of claim 1, further comprising:\n\n15\n\na first filter configured to select from the textual dataset reports of patients classified as stroke patients as principal diagnosis reports; and eliminate from the textual dataset non-principal diagnosis reports;\n\na second filter configured to eliminate from the textual dataset irrelevant reports including error reports, non-final reports, and reports that are unrelated to the principal diagnosis reports; and\n\n20\n\na third filter configured to delete stop words that do not contribute to the meaning of the research report, and organizes the format of the text report.\n\nThe system of claim 1, further comprising:\n\n25\n\na first filter configured to eliminate from the image dataset slides with specific meta information from DICOM, the specific meta information includes one or more of non-brain exam body parts, RGB planes, missing or corrupted image position, missing or corrupted image orientation information, missing or corrupted diagnosis, and missing or corrupted patient ID;\n\nan image normalization module configured to standardize all the images as squares;\n\nDocket No. UM1104HK00\n\n19\n\nHK 30057394 A\n\nthe second filter eliminates excessive missing values samples and\n\nirrelevant samples; the images labelling element assigns labels to the selected images representing the patient\u2019s diagnosis.\n\n5 8. The system of claim 2,\n\nwherein the machine learning models that are specifically configured to\n\nprocess and analyse the structured dataset comprise:\n\na random forest (RF) classifier,\n\nan Adaptive Boosting (AdaBoost),\n\n10\n\nan Extremely randomized trees (ExtraTree) classifier, and\n\na XGBoost classifier;\n\nwherein the deep learning models that are specifically configured to\n\nprocess and analyse the structured dataset comprise a TabNet classifier;\n\n15\n\nwherein during training, validation, and testing of the machine learning models and the deep learning models, random sampling is applied to the structured dataset, dividing the structured dataset into one or more of training datasets, validation datasets, and testing datasets;\n\nwherein each of the machine learning models and the deep learning models is trained respectively using the training dataset;\n\n20\n\nwherein each of the machine learning models and the deep learning models is evaluated by using AUC value of the validation set, and the models with highest AUC values are selected as the best performing machine learning models and deep learning models for run-time; and\n\n25\n\nwherein during the run-time, the structured dataset is reloaded to the best performing machine learning models and deep learning models to generate one or more prediction results.\n\n9. The system of claim 2,\n\n30\n\nwherein the deep learning models that are specifically configured to process and analyse the textual dataset comprise a DistilBERT;\n\nDocket No. UM1104HK00\n\n20\n\nHK 30057394 A\n\nwherein during training, validation, and testing of the deep learning models, random sampling is applied to the textual dataset, dividing the structured dataset into one or more of training datasets, validation datasets, and testing datasets;\n\n5\n\nwherein the deep learning models are loaded on to multiple-block GPUs and trained in parallel using the training dataset;\n\nwherein each of the deep learning models is evaluated by using AUC value of the validation set, and the models with highest AUC values are selected as the best performing deep learning models for run-time; and\n\n10\n\nwherein during the run-time, the textual dataset is reloaded to the best\n\nperforming deep learning models to generate one or more prediction results.\n\n10.\n\nThe system of claim 2,\n\n15\n\nwherein the deep learning models that are specifically configured to\n\nprocess and analyse the image dataset comprise:\n\na three-dimensional convoluted neural network (3DCNN), and\n\na Vision Transformer (ViT);\n\n20\n\nwherein during training, validation, and testing of the deep learning models, random sampling is applied to the textual dataset, dividing the structured dataset into one or more of training datasets, validation datasets, and testing datasets;\n\nwherein the deep learning models are loaded on to multiple-block\n\nGPUs and trained in parallel using the training dataset;\n\n25\n\nwherein test-time augmentation (TTA) is applied to the testing dataset and test prediction results are averaged during inference during the testing of\n\nthe deep learning models;\n\nwherein each of the deep learning models is evaluated by using AUC value of the validation set, and the models with highest AUC values are selected as the best performing deep learning models for run-time; and\n\n30\n\nwherein during the run-time, the image dataset is reloaded to the best\n\nperforming deep learning models to generate one or more prediction results.\n\nDocket No. UM1104HK00\n\n21\n\nHK 30057394 A\n\n11. The system of claim 3,\n\nwherein the ensemble models are one or more of voting ensemble models and stacking ensemble models;\n\n5\n\nwherein validation results from structured dataset and textual dataset are merged according to the patient information and formed as input to the\n\nensemble models;\n\n10\n\nwherein a weight of each result from each of the ensemble models is decided by one or more loss values during the training and testing; and wherein a logistic regression is applied as a secondary model for stacking ensemble model to avoid overfitting.\n\nDocket No. UM1104HK00\n\n22\n\nHK 30057394 A\n\nMedical Data 104 Textual Data 102 ! 4 Sy a / AN \u3001 Mortality Prediction ICD-9 Prediction Treatment Decision LVO Prediction i [ [ >\u00bb \u4e86 Demographics >) (\u2014 >) i Demographics . Diagnosis i Diagnosis Demograp ies Family Medicine Demographics f E a Diagnosis \u548c H Family Medicine Faiaily Medicine Laboratory Results Diagnosis i Laboratory Results Tabata Results CT / MRI Images CT Images H Radiology reports ay Drug Use 2 H 109 _ Medical Procedures | | XN T Zp XN | S Machine Li i Machine Li ing ) ( \u9084 ( ) | nee eee ae aE Reinforcement Deep Learning and Deep Learning and Deep Learning - Learning Model Models H Models Models H Ji 6 113 4 i \u5668 X ry \u201cJ Mortality Prediction Aes Stroke SS pe Treatment Decision NO Patients Classification Classification \u4e00 Ls is FIG. 1 J\n\nDocket No. UM1104HK00\n\n23\n\nHK 30057394 A\n\nDocket No. UM1104HK00\n\n24\n\nHK 30057394 A\n\n109,110, fY 111,112 Raw Data 301 Non-Principle Diagnosed Patients 1st Filter 302 LZ Excessive Missing Values Samples, Irrelevant Samples \u3001 2nd Filter 303 Data Imputation 304 Data Normalization 305 Feature Selection 306 Processed Structured Data 307 \\ FIG. 3 ?\n\nDocket No. UM1104HK00\n\n25\n\nHK 30057394 A\n\n109,111 AR Raw Data 401 Non-Stroke Patients . 15t Filter 402 Irrelevant Reports 2nd Filter 403 Remove Stop Words, Clear Format 3rd Filter 404 Processed Textual Data 405 Ss, 2 > Free,\n\nDocket No. UM1104HK00\n\n26\n\nHK 30057394 A\n\n111,112 Non-Stroke Patients\uff0c Non-Brain, Non-Standard Images Excessive Missing Values Samples, Irrelevant Sampels i Riel ia er\u2019 D igital Imaging and Communications in \u4e8c \u4e00 Images Normalization Medicine 1st Filter 502 503 \u2018a \u53ea 2nd Filter Processed Structured Data 307 504 Ns J Images Labelling Pra Processed Image Data 506 s, \u8981 S05\n\nDocket No. UM1104HK00\n\n27\n\nHK 30057394 A\n\nDocket No. UM1104HK00\n\n28\n\nHK 30057394 A\n\n114 Processed Structured Data 307 f - 1 Training Set Validation Set Testing Set 602 603 604 S Testing Models Training Models 606 605 Final Model 607 >\n\nDocket No. UM1104HK00\n\n29\n\nHK 30057394 A\n\n/ 9 TZ slepoN slquesu3 OZ lepoW eyeq Iemxel i774 ETZ slepoN 6unsel SlepoN 6ululeJl { | | OZ 507 507 1eS 6unsal 1eS uomeplleA yes 6ulule \u5458 J (OT) VOL EOL Blea Ilenjxel perey|i4 Big pexIW OZ slepoW eye peunionns TZ aL slepoW Buysey slepoW Buiuresy \u53f8 =e | oO Jelld -\u4e00 \u4e00 | sor eeq Iemxal pesseoojd penlonns pesseoold 507 ws ae yes en yas 6ulule \u653b Z0Z eyeq PaINJONS pelJelld sajdweg sane, 6ulssiW seAlsseox3 | Toe Beg ebb 002\n\nDocket No. UM1104HK00\n\n30\n\nHK 30057394 A\n\n\\ 116 fY Processed Structured Processed Image Data Data 307 506 J Excessive Missing Values Samples Image Data Training Set 803 Structured Data Training Set 802 TF Concatenating Data 804 \\ Training 3DCNN & ViT 805 Inference with TTA 807 XK \u2026\n\nDocket No. UM1104HK00\n\n31\n\nHK 30057394 A\n\ndo es 226 jepot elea lenixeL lapoW e1eq e6eull [ 066 oe \u4eba 6 sjepow 6unsel SIlepoW Gururesy \u2018sjepoy 6unsel sjepoy i \u4e86 | | jos Suiuresy jog 5unsel 1eS uolieplleA TFTE 6 Jes 6unsel JOS uofieplleA t i J t i an a 506 WS Beg lenixel pejallld Beg e6eul peJei \u5446 | es | 108 eleg PaXIN Jelld Peunjonas ea Iemxel pesseoojd\n\n6 \u2018Sls RE lepo Bulwiee 206\n\nRE lepo Bulwiee 206 do cre Pony Te es 226 lapoW jepot elea lenixeL lapoW e1eq e6eull egie0 pemonig [ | 066 oe \u4eba 6 6 \u53ef 5 STS sjepow 6unsel SIlepoW Gururesy \u2018sjepoy 6unsel sjepoy 6ulule \u4e2d sjepow 6unsel $lepoN 6ulute \u5916 i \u4e86 | | ] | | jos Suiuresy jog 5unsel 1eS uolieplleA yes 6ulule \u4e2d Jos 5unsel Jeg uonieplleA jos TFTE 6 Jes 6unsel JOS uofieplleA t i J t i J t i an a 506 WS es Beg lenixel pejallld Beg e6eul peJei \u5446 penionnS pedeil | es | 108 eleg PaXIN Jelld SeldwueS senleA Burssiyy entsseox3 Beg Peunjonas pesseooJd ea Iemxel pesseoojd\n\ncre Pony Te lapoW egie0 pemonig | 6 \u53ef 5 STS 6ulule \u4e2d sjepow 6unsel $lepoN 6ulute \u5916 ] | | | yes 6ulule \u4e2d Jos 5unsel Jeg uonieplleA jos 5ulule \u513f J t i j es penionnS pedeil SeldwueS senleA Burssiyy entsseox3 Beg pesseooJd Sib\n\nDocket No. UM1104HK00\n\n32", "type": "Document"}}