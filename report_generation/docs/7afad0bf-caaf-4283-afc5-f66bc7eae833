{"lc": 1, "type": "constructor", "id": ["langchain", "schema", "document", "Document"], "kwargs": {"metadata": {"source": "/home/guanzhideng145/research/ip_portal/patent_kg/patents/130-US8,019,804(active).pdf"}, "page_content": "US008O19804B2\n\nUnited States Patent\n\n(12)\n\n(10) Patent No.:\n\nUS 8,019,804 B2\n\nP0 et al.\n\n(45) Date of Patent:\n\nSep. 13, 2011\n\n(54) METHOD AND APPARATUS FOR\n\n2007/0162236 A1* 7/2007 Lamblin et al. ............... 708,235\n\nCALCULATING AN SSD AND ENCODNGA\n\n2007/0183500 A1* 8/2007 Nagarajetal. ...\n\n375,240.16\n\nVIDEO SIGNAL\n\n2008/0037642 A1* 2/2008 Tsuchiya et al. ......... 375,240.16\n\nOTHER PUBLICATIONS\n\n(75) Inventors: Lai-Man Po, Tsing Yi (HK); Kai Guo,\n\nKowloon Tong (HK)\n\nWiegand, T., et al., \u201cOverview of the H.264/AVC Video Coding\n\nStandard.\u201d IEEE Trans. Circuits Syst. Video Technol., vol. 13, No. 7.\n\n(73) Assignee: City University of Hong Kong,\n\npp. 560-576, Jul. 2003.\n\nKowloon (HK)\n\nWiegand, T., et al., \u201cRate-Distortion Optimized Mode Selection for\n\nVery Low Bit Rate Video Coding and the Emerging H.263 Standard.\u201d\n\n(*) Notice:\n\nSubject to any disclaimer, the term of this\n\nIEEE Trans. Circuits Syst. Video Technol., vol. 6, No. 2, pp. 182-190,\n\npatent is extended or adjusted under 35\n\nApr. 1996.\n\nU.S.C. 154(b) by 1205 days.\n\nSullivan, G.J., et al., \u201cRate-Distortion Optimization for Video Com\n\npression.\u201d IEEE Signal Process. Mag., vol. 15, pp. 74-90, Nov. 1998.\n\n(21) Appl. No.: 11/690,891\n\nWiegand, T., et al., \u201cRate-Constrained Coder Control and Compari\n\nson of Video Coding Standards.\u201d IEEE Trans. Circuits Syst. Video\n\n(22) Filed:\n\nMar. 26, 2007\n\nTechnol., vol. 13, No. 7, pp. 688-703, Jul. 2003.\n\n(65)\n\nPrior Publication Data\n\n(Continued)\n\nUS 2008/O243971 A1\n\nOct. 2, 2008\n\nPrimary Examiner \u2014 Chuong DNgo\n\n(74) Attorney, Agent, or Firm \u2014 Stites & Harbison PLLC;\n\n(51) Int. Cl.\n\nDouglas E. Jackson\n\nG06F 7/4\n\n(2006.01)\n\nH04N 7/2\n\n(2006.01)\n\n(57)\n\nABSTRACT\n\n(52) U.S. Cl. ............... 708/402; 375/240.02; 375/240.12\n\nThe present invention relates to a method and apparatus for\n\n(58) Field of Classification Search .................. 708/490,\n\ncalculating the Sum of Squared Differences (SSD) between a\n\n708/200, 495, 401, 402; 375/240.02, 240.12\n\nSource block and a reconstructed block of image or video data\n\nSee application file for complete search history.\n\nencoding according to an encoding scheme Such as H.264/\n\nAVC. In a preferred embodiment, the method computes the\n\n(56)\n\nReferences Cited\n\nSSD by finding the SSD between coefficients of an integer\n\ntransformed residual block and the corresponding inverse\n\nU.S. PATENT DOCUMENTS\n\nquantized coefficients. Preferably the inverse quantized coef\n\n5,295,077 A * 3/1994 Fukuoka ....................... TO8/402\n\nficients are found with the aid of a look up table. This method\n\n39; A :\n\nSineral .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n. 23. may save computing time and processing power compared to\n\n6,366.6 14 B1\n\n4/2002 Pianet al. \" calculating the SSD directly from the source and recon\n\n6,430,222 B1\n\n8/2002 Okada ........................... TO8/203\n\nstructed blocks. The SSD is related to the distortion caused by\n\n6,507,614 B1* 1/2003 Li ................................. TO8/402\n\nencoding and the method may be used in calculating the\n\n$$$ B2, 429 Malvar\n\nrate-distortion of a particular encoding mode. One embodi\n\n: R: 1.58: SE .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n. 382/251\n\nment of the invention encodes a block of data by selecting the\n\n7. 106,797 B2\n\n9, 2006 Malvar\n\nencoding mode with the least rate-distortion.\n\n2001/0050959 A1* 12/2001 Nishio et al. .................. 375,243\n\n2004/OO95997 A1\n\n5/2004 Altunbasak et al.\n\n21 Claims, 12 Drawing Sheets\n\n410\n\n420\n\nA40\n\n450\n\nOriginal --\n\nD\n\nk\n\nBlock S\n\nItcrative\n\nICT\n\nF\n\ntable- lookup Z Entropy\n\nquantization\n\nCoding\n\n400 -\n\nPredicted\n\nask\n\nBlock P\n\nF\n\n460\n\nSSD\n\nUS008019804B2\n\naz United States Patent\n\nUS 8,019,804 B2 (10) Patent No.:\n\nPo et al.\n\nSep. 13, 2011 (45) Date of Patent:\n\n(54) METHOD AND APPARATUS FOR CALCULATING AN SSD AND ENCODING A VIDEO SIGNAL\n\n2007/0162236 Al* 7/2007 Lamblin et al. - 708/235 2007/0183500 Al* 8/2007 Nagaraj et al 375/240.16 2008/0037642 Al* 2/2008 Tsuchiya et al. . 375/240.16\n\nOTHER PUBLICATIONS\n\n, Inventors: Lai-Man Po, Tsing Yi (HK); Kai Guo, Kowloon Tong (HK)\n\nWiegand, T., et al., \u201cOverview of the H.264/AVC Video Coding Standard,\u201d IEEE Trans. Circuits Syst. Video Technol., vol. 13, No. 560-576, Jul. 2003.\n\nAssignee: City University of Hong Kong, Kowloon (HK)\n\nWiegand, T., et al., \u201cRate-Distortion Optimized Mode Selection for Very Low Bit Rate Video Coding and the Emerging H.263 Standard,\u201d IEEE Trans. Circuits Syst. Video Technol., vol. 6, No. 2, pp. 182-190, Apr. 1996.\n\n(*) Notice: Subject to any disclaimer, the term of this patent is extended or adjusted under 35 USC. 154(b) by 1205 days.\n\nSullivan, G. J., et al., \u201cRate-Distortion Optimization for Video Com- pression,\u201d IEEE Signal Process. Mag., vol. 15, pp. 74-90, Nov. 1998. Wiegand, T., et al., \u201cRate-Constrained Coder Control and Compari- son of Video Coding Standards,\u201d IEEE Trans. Circuits Syst. Video Technol., vol. 13, No. 7, pp. 688-703, Jul. 2003.\n\n(21) Appl. No.: 11/690,891\n\n(22) Filed: Mar. 26, 2007\n\n(65) Prior Publication Data\n\nPrimary Examiner \u2014 Chuong D Ngo\n\nUS 2008/0243971 Al Oct. 2, 2008\n\n(74) Attorney, Agent, or Firm \u2014 Stites & Harbison PLLC; Douglas E. Jackson\n\nGO6F 17/14 (2006.01) HOAN 7/12 (2006.01)\n\n(57) ABSTRACT\n\n(52) US. cl. 708/402; 375/240.02; 375/240.12\n\nThe present invention relates to a method and apparatus for calculating the Sum of Squared Differences (SSD) between a source block and a reconstructed block ofimage or video data encoding according to an encoding scheme such as H.264/ AVC. In a preferred embodiment, the method computes the SSD by finding the SSD between coefficients of an integer transformed residual block and the corresponding inverse- quantized coefficients. Preferably the inverse quantized coef- ficients are found with the aid of a look up table. This method may save computing time and processing power compared to calculating the SSD directly from the source and recon- structed blocks. The SSD is related to the distortion caused by encoding and the method may be used in calculating the rate-distortion of a particular encoding mode. One embodi- ment of the invention encodes a block of data by selecting the\n\n(58) Field of Classification Search . - 708/490, 708/200, 495, 401, 402; 9.02, 240.12 See application file for complete search history.\n\n. (56) References Cited\n\nU.S. PATENT DOCUMENTS\n\na ones \u4eba \u5247 1 oka 08203 5983.251 A * 11/1999 wae Stal 708/203 6366614 BL 4/2002 Pianetal. 6,430,222 Bl* 8/2002 Okada . 708/203 6,507,614 BI* 1/2003 Li ... 708/402 6,882,685 B2 \uff0c 4/2005 Malvar Coos es \u570b I Sonos Rokose ae 382/251 7.106.797 B2 9/2006 Malvar 2001/0050959 Al* 12/2001 Nishio etal. 0.0.0.0... 375/243 2004/0095997 Al 5/2004 Altunbasak et al.\n\n21 Claims, 12 Drawing Sheets\n\n410 420 440 450 Original D * Block S + F Iterative Z ICT table- lookup Entropy quantization Coding 400 \u4e00 \u4e00 \u4e00 \u5716 Predicted Block P\n\n(75)\n\n7,\n\n(73)\n\npp.\n\n(Continued)\n\n(51)\n\nInt. CL.\n\nnt\n\nencoding mode with the least rate-distortion.\n\nUS 8,019,804 B2\n\nPage 2\n\nISO/IEC MPEG and ITU-T VCEG, Doc. JVT-B038, 18 pp., Jan.\n\nOTHER PUBLICATIONS\n\n2002.\n\nTu, Y.K., et al., \u201cEfficient Rate-Distortion Estimation for H.264/AVC\n\nChen, Q., et al., \u201cA Fast Bits Estimation Method for Rate-Distortion\n\nCoders.\u201d IEEE Trans. Circuits Syst. Video Technol. vol. 16, No. 5, pp.\n\nOptimization in H. 164/AVC,\u201d in Proc. Picture Coding Syst. (PCS\n\n600-611, May 2006.\n\n2004), Paper No. 35, 5 pp. Dec. 2004.\n\nTourapis, A. M., et al., Revised H.264/MPEG-4 AVC Reference Sofi\n\nCot\u00e9, G., et al., \u201cH.263+: Video Coding at Low Bit Rates.\u201d IEEE\n\nware Manual, FastVDO LLC, Fraunhofer-Institute HHI, Microsoft\n\nTrans. Circuits Syst. Video Technol. vol. 8, No. 7, pp. 849-866, Nov.\n\nCorporation, 63 pp., Oct. 2005.\n\n1998.\n\nFan, C. P. et al., \u201cFast Center Weighted Hadamard Transform Algo\n\nSullivan, G. J., et al., \u201cVideo Compression\u2014From Concepts to the\n\nrithms.\u201d IEEE Trans. Circuits Syst.\u2014Part II: Analog and Digital\n\nH.264/AVC Standard.\u201d Proceedings of the IEEE, vol. 93, No. 1, pp.\n\nSignal Processing, vol. 45, No. 3, pp. 429-432, Mar. 1998.\n\n18-31, Jan. 2005.\n\nFan, C. P. et al., \u201cFixed-PipelineTwo-Dimensional Hadamard Trans\n\nMarpe, D., et al., \u201cContext-Based Adaptive Binary Arithmetic Cod\n\nform Algorithms.\u201d IEEE Trans. on Signal Process., vol. 45, No. 6, pp.\n\ning in the H.264/AVC Video Compression Standard.\u201d IEEE Trans.\n\n1669-1674, Jun. 1997.\n\nCircuits Syst. Video Technol. vol. 13, No. 7, pp. 620-636, Jul. 2003.\n\nHallapuro, A., et al., \u201cLow Complexity Transform and Quantiza\n\ncited by examiner\n\ntion\u2014Part I: Basic Implementation.\u201d in Joint Video Team (JVT) of\n\nUS 8,019,804 B2\n\nPage 2\n\nISO/IEC MPEG and ITU-T VCEG, Doe. JVT-B038, 18 pp., Jan. 2002.\n\nOTHER PUBLICATIONS\n\nTu. Y. K,, etal., \u201cEfficient Rate-Distortion Estimation for H.264/ Coders,\u201d IEEE Trans. Circuits Syst. Video Technol. vol. 16, No. 5, 600-611, May 2006.\n\nChen, Q., et al., \u201cA Fast Bits Estimation Method for Rate-Distortion Optimization in H.164/AVC,\u201d in Proc. Picture Coding Syst. (PCS 2004), Paper No. 35, 5 pp. Dec. 2004.\n\nTourapis, A. M., et al., Revised H.264/MPEG-4 AVC Reference Sofi- ware Manual, FastVDO LLC, Fraunhofer-Institute HHI, Microsoft Corporation, 63 pp. , Oct. 2005.\n\nCot\u00e9, G., et al., \u201cH.263+: Video Coding at Low Bit Rates,\u201d IEEE Trans. Circuits Syst. Video Technol. vol. 8, No. 7, pp. 849-866, Nov. 1998.\n\nFan, C. P., et al., \u201cFast Center Weighted Hadamard Transform Algo- rithms,\u201d IEEE Trans. Circuits Syst.\u2014Part II: Analog and Digital Signal Processing, vol. 45, No. 3, pp. 429-432, Mar. 1998.\n\nSullivan, G. J., et al., \u201cWideo Compression\u2014From Concepts to H.264/AVC Standard,\u201d Proceedings of the IEEE, vol. 93, No. 1, Jan. 2005.\n\nC. P., et al., \u201cFixed-Pipeline Two-Dimensional Hadamard Trans- Algorithms,\u201d IEEE Trans. on Signal Process., vol. 45, No. 6, 1669-1674, Jun. 1997.\n\nMazrpe, D., et al., \u201cContext-Based Adaptive Binary Arithmetic in the H.264/AVC Video Compression Standard,\u201d IEEE Trans. Circuits Syst. Video Technol. vol. 13, No. 7, pp. 620-636, Jul. 2003.\n\nHallapuro, A., et al., \u201cLow Complexity Transform and Quantiza- tion\u2014Part I: Basic Implementation,\u201d in Joint Video Team (JVT) of\n\n* cited by examiner\n\nAVC pp.\n\nFan, form\n\npp.\n\nthe\n\npp.\n\n18-31,\n\nCod-\n\ning\n\nU.S. Patent\n\nSep. 13, 2011\n\nSheet 1 of 12\n\nUS 8,019,804 B2\n\nFig. 1: H.264 Rate-distortion performance comparison using RDO-based, SAD-based and\n\nSATD-based cost functions in terms of PSNR (dB) and Rate (Kbps)\n\nQP\n\n28\n\n32\n\n36\n\n40\n\nRDO SAD SATD RDO SAD SATD RDO SAD SATD RDO SAD\n\nSATD\n\nAkiyo\n\nPSNR 39.94\n\n39.76\n\n39.81\n\n36.95\n\n36.86\n\n36.88\n\n34.30\n\n3412 3143 31.36\n\n31.40\n\nRate\n\n21809 225.16 221.64 15403 16047 15754111.77 114.78\n\n112.64 80.78\n\n82.85\n\n8086\n\n34.54\n\n258.36\n\nStefan\n\n3320 3329 3022 3001\n\n30.15\n\n26.91\n\n26.58\n\n26.88\n\nRate\n\n891.62.91564 91084. 597,2961.031\n\nFig. 2\n\n120\n\n130\n\nDiscrete Cosine Transform\n\n/\n\nICT\n\nScale Transform\n\nCDC,\n\nF'80\n\nQuantization\n\nD\n\nA F\n\nF\n\nZ.\n\n110\n\n150\n\nInverse ICT\n\nScale Transform 74\n\nM\n\nA.\n\nInverse\n\nr\n\n(\n\nCFC K\n\nF&Q\n\nQuantization\n\nD\n\nF\n\nInverse Discrete Cosine Transform\n\n/\n\n160\n\n140\n\nFig. 3: Ain different positions\n\nPosition R. Position (i,j)\n\nI\n\n(\n\n0,0),(0,2),(2,0),(2.2)\n\nII\n\n(1,1),(1,3),(3,1),(33)\n\nU.S. Patent\n\nUS 8,019,804 B2\n\nSep. 13, 2011\n\nSheet 1 of 12\n\n1: H.264 Rate-distortion performance comparison using RDO-based, SAD-based SATD-based cost functions in terms of PSNR (dB) and Rate (Kbps)\n\na ET ae eS SATD ADD Akiyo Foreman | PSNR | 37.84 | 37. 6 37. 68 349 34.54 Rate | 421.58 | 432.09 | 427.49 258.36 Stefan PSNR | 37.16 36.85 36.94 3 33.20 [Rate | 891.62 | 915.64 | 910.84 | 597.29 | 610.31 | 611.58 . bspaer [sor | 20225 | 250-0 | 255.31\n\nFig. 2\n\nDiscrete Cosine Transform / ICT Scale Transform C,DC; F'8Q,,, Quantization D / \u4e86 Z 110 150 Inverse ICT Scale Transform A a a Tnverse 8 aAT ( CRC, {| F@Qua Quantization i) F Inverse Discrete Cosine Transform /\n\nFig. 3: A, in different positions\n\nPosition | position (ij) A Region J ui I (0,0),(0,2),(2,0),(2,2) Ala\u2019 \u4e0b (1,1),0.,3),3,0),G,3) 4A1b* I Others 2A/lab\n\nFig.\n\nand\n\n120\n\n130\n\n160\n\n140\n\nU.S. Patent\n\nSep. 13, 2011\n\nSheet 2 of 12\n\nUS 8,019,804 B2\n\nFig. 4: Quantization Diagram\n\n260\n\nInverse\n\nAired\n\na A\n\nis\n\nA\n\nA.\n\nWale\n\nQuantization\n\n(-2.5 A, - (-1.5 A, (-0.5 A, (0.5A,\n\nsub-zone\n\nboundaries\n\n0.5 A. )\n\n0.5 As )\n\nFig. 6: Relation between A, quantization sub-zone and quantization points\n\nQstep Ea, A,\n\nQuantization range\n\nInverse a so\n\nava\n\n2\n\n2\n\nvalue\n\nara araca?a'awa)\n\nI\n\nAfa\n\nQuantization\n\nsub-zone\n\nboundaries\n\nInverse\n\nII\n\nb/4\n\nvalue\n\nQuantization\n\nsub-zone\n\nboundaries\n\nInverse\n\nquantized\n\nvalue\n\nIII\n\nab/2 2A/ab Quantization\n\n(-A/ab, Afab)\n\n(A/ab,3A/ab)\n\nsub-zone\n\nboundaries\n\nU.S. Patent\n\nUS 8,019,804 B2\n\nSep. 13, 2011\n\nSheet 2 of 12\n\nFig. 4: Quantization Diagram\n\nFig. 5: Quantization points and quantization zones\n\nInverse quantized a | 2Ay -Ay O Ay 2A, value Quantization (25 Ay, -| CLSA,, COSA, 5A, asA,, sub-zone a boundaries L5A,) -05A,) 05A,;) L5A,) 25A,)\n\nPosition See se Ala? . | ((A/2a?,A/ 2a\u201d) | (A/2a?,3A/2a\u201d) i [Oo 4A/b? vi | 4A \u4e00 \u4e00 6 | (-2A/b?,2A/b*) | (2A/b?,6A/b\") 2A/ab oO abi2. | 2 Alab (-A/ab,Alab) \u201c| (A/ab,3A/ ab) boundaries\n\nU.S. Patent\n\nSep. 13, 2011\n\nSheet 3 of 12\n\nUS 8,019,804 B2\n\nFig. 7\n\n390\n\nFig. 8:\n\n410\n\n420\n\n\"\n\n450\n\nOriginal\n\nD\n\nk\n\nBlock S H\n\nF\n\nItcrativc\n\nZ\n\nICT\n\ntable- lookup\n\nEntropy\n\nquantization\n\nCoding\n\n400\n\nProdicted\n\n2N is\n\nBlock P\n\nF\n\n460\n\nSSAO\n\nU.S. Patent\n\nUS 8,019,804 B2\n\nSheet 3 of 12\n\nSep. 13, 2011\n\nFig. 7\n\nFig. 8:\n\n410 420 | Original D . Block S + F iterative \u540c ICT table- lookup | Entr OPy quantization Coding 400 - Predicted \u3001 Block P | F 460 | \u4e00 SSD\n\n390\n\n450\n\nU.S. Patent\n\nSep. 13, 2011\n\nSheet 4 of 12\n\nUS 8,019,804 B2\n\nFig. 9\n\n550\n\nA\n\n525\n\n510\n\nQuantization\n\n520\n\nN Iable Generator\n\n522\n\nIterative\n\nhift\n\nTable-lookup\n\nHo RAM (Table I)\n\nesset\n\nuantiation\n\nstar - on\n\nSea\n\nf,\n\nSign\n\nera.\n\n500\n\n9. REG\n\n523\n\nCounter\n\n2\n\nN f\n\nSi Sign\n\nReset\n\nR\"\n\nSign\n\nComparator\n\n2. ool\n\nN Out\n\n521\n\n552.\n\n524\n\n\\\n\nIterative\n\nhift\n\nTable-lookup H530\n\nram cable in 5\n\nQuantization\n\nH. RAM (Table IID Reset\n\nSi\n\nW\n\nOut\n\nSign\n\nes f\n\nE REG\n\nCounter Out\n\n2\n\nSign\n\nReset\n\nf\n\nSign\n\nReset\n\nLoop Add\n\nReset\n\ne\n\nComparator\n\nSelector\n\nut\n\nD\n\nD\n\nD\n\nD\n\nD\n\nD\n\nD\n\nD\n\nD\n\nD\n\n562\n\nD\n\nD\n\nIterative\n\nTable-lookup\n\nH540\n\n> RAM (Table II)\n\nOuantiation\n\nSign\n\n1 &\n\nOut\n\ne f\n\nf33\n\nSign REG\n\nCounter Out\n\nZ.\n\ne-\n\nSign\n\ny\n\nReset\n\nA\n\nSign\n\nReset\n\nLoop Add\n\nReset\n\nSelector it\n\nComparator\n\neleCO If,\n\nut\n\nU.S. Patent\n\nUS 8,019,804 B2\n\nSep. 13, 2011\n\nSheet 4 of 12\n\nFig. 9\n\n510 Quantization 520 \\ \u2018Table Generator 522 Iterative hift Table-lookup \u4e00 ml RAM (lable I) \u2018eset uantization 4 5 ~ fs 523 Counter ut -2 Sign Reset > | Sool | Sign - Loop \u5168 Selector ei ee \u5143 \u4e00 521 552 524 \\ Iterative hift Table-lookup 1 \u4e00 \u4e00 \u4e00 \u4e00 \u4e00 ml RAM (\u2018Table III) \u2018eset Quantization Si ~ Sigp = Out ~ for = REG Counter > Zao Sign \u4e86 or Sign c Reset Loop Reset \u751f | Selector | omparator -\u4e00 or 0 0 0 0 0 0 0 0 0 0 562 [ 0 Iterative | 540 i Table-lookup Le} RAM (Table 1D bet Quantization Si ne sign \u4e0b Out \u4e00 \u4e00 \u70ba a 33 MS} REG Counter \u4e8c > Sign \u00a5 Reset | poop |Addf \u2014f Reset\n\n550;\n\n\u4eba F\n\n530\n\nSi \u4e00 Selector |\n\nComparator\n\n[Setector]\n\naE\n\nU.S. Patent\n\nUS 8,019,804 B2\n\nSep. 13, 2011\n\nSheet 5\n\nof 12\n\nFig. 10\n\nDefine Source Block (S)\n\n600\n\nDefine Predicted Block (P)\n\n610\n\nDefine Residual Block (D)\n\n620\n\nICT Transform to obtain (F)\n\n630\n\nIterative look-up process\n\nEntropy Encode\n\n640\n\n650\n\nCalculate f,\n\nNote the number\n\n670\n\n\"\n\nof bits\n\n660\n\nCompute SSD\n\n680\n\nCompute R-D Cost\n\n690\n\nU.S. Patent\n\nUS 8,019,804 B2\n\nSep. 13, 2011\n\nSheet 5 of 12\n\nFig. 10\n\nDefine Source Block (S) 600\n\nDefine Predicted Block (P) 610\n\n620 \u548c ICT Transform to obtain (F*) 630 \u548c Iterative look-up process 640 \u4e00 \u548c \u4e00 Entropy Encode 650 Calculate f 670 i \u91cc Note the number of bits 660 | Compute SSD 680 \u4e00 \u548c \u4e00 Compute R-D Cost 690\n\n\u4e86\n\nY\n\nDefine Residual Block (D)\n\nU.S. Patent\n\nUS 8,019,804 B2\n\nSep. 13, 2011\n\nSheet 6 of 12\n\nFig. 11\n\nDefine Area\n\n700\n\nDefine Blocks\n\n710\n\nR-D cost of first\n\nR-D cost of second\n\nencoding mode\n\nencoding mode\n\n720\n\n730\n\nCompare R-D cost and select\n\nb encoding mode -\n\n740\n\nEncoding\n\n750\n\nU.S. Patent\n\nUS 8,019,804 B2\n\nSep . 13, 2011\n\nSheet 6 of 12\n\nFig. 11\n\nDefine Area 700 | Define Blocks 10 R-D cost of first encoding mode R-D cost of second encoding mode 220 230 Compare R-D cost and select i encoding mode <<\u2019 740 Encoding\n\n750\n\nU.S. Patent\n\nUS 8,019,804 B2\n\nSep. 13, 2011\n\nSheet 7 of 12\n\nFig. 12\n\nSource block defining module\n\n900\n\nPrediction module\n\n910\n\nResidual block defining module\n\n920\n\nInteger Image Transform module\n\n930\n\nQuantizing and inverse\n\nO. Entropy encoding module\n\nquantizing module\n\n950\n\n940\n\nDifference computing module\n\n960\n\nR-D computing module\n\n970\n\nU.S. Patent\n\nUS 8,019,804 B2\n\nSep. 13, 2011\n\nSheet 7 of 12\n\nFig. 12\n\nSource block defining module 200 Prediction module 910 Residual block defining module 920 Integer Image Transform module 930 Quantizing and inverse % | Entropy encoding module quantizing module \u4e00 \u4e00 950 940 \u672c | & fi Difference computing module 960 R-D computing module 970\n\nU.S. Patent\n\nUS 8,019,804 B2\n\nSep. 13, 2011\n\nSheet 8 of 12\n\nFig. 13\n\nArea defining module\n\n1000\n\nBlock defining module\n\n1010\n\nEncoding with mode 1\n\nEncoding with mode 2\n\nRate distortion module\n\n1020\n\nEncoding with mode 1\n\nEncoding with mode 2\n\nComparison module\n\n1030\n\nOutput module\n\n1040\n\nU.S. Patent\n\nUS 8,019,804 B2\n\nSheet 8 of 12\n\nSep. 13, 2011\n\nFig. 13\n\nArea defining module 1000 | Block defining module 1010 Encoding with mode 1 Encoding with mode 2 Rate distortion module 1020 Encoding with mode 1 Encoding with mode 2 Comparison module 1030 |\n\nOutput module 1040\n\nU.S. Patent\n\nSep. 13, 2011\n\nSheet 9 of 12\n\nUS 8,019,804 B2\n\nFig. 14: Comparison of the encoding time between standard algorithm (JM encoder) and the\n\nproposed FSSD algorithms in Akiyo\n\nSyentional FSSD\n\nTime reduction by E. Total reduction\n\nQP\n\nAlgorithm iterative Fig.-lookup\n\nAlgorithm\n\nand pixel\n\nof encoding time (%)\n\n(mS)\n\nquantization (%)\n\n(ms)\n\nreconstruction (%)\n\n2\n\n89261\n\n76512\n\n6.61\n\n7.67\n\n14.28\n\n3\n\n85365\n\n72374\n\n6.85\n\n8.37\n\n15.22\n\n2\n\n3\n\n6\n\n83705\n\n71731\n\n6.74\n\n7.56\n\n14.30\n\nFig. 15: Comparison of the encoding time between standard algorithm (JM encoder) and the\n\nproposed FSSD algorithms in Foreman\n\nConventional FSSD\n\nTime reduction by Time reduction by\n\nSSD\n\n- -\n\n\n\ninverse transform\n\nTotal reduction\n\nAlgorithm\n\niterative Fig.-lookup\n\nAlgorithm\n\n(ms)\n\nuantization (%)\n\nand pixel\n\nof encoding time (%)\n\n(ms)\n\nC\n\nO\n\nreconstruction (%)\n\n28\n\n10362\n\n9082\n\n5.65\n\n6.7\n\n12.36\n\nFig. 16: Comparison of the encoding time between standard algorithm (JM encoder) and the\n\nproposed FSSD algorithms in Container\n\nConventional FSSD\n\nTime reduction by Time reduction by\n\nQP SSD\n\nAlgorithm literative Fig.-lookup\"\n\ntransform\n\nTotal reduction\n\nAlgorithm\n\nE.\n\nquantizato. ) P and pixel\n\nof encoding time (%)\n\n(Ins)\n\nreconstruction (%)\n\n93.789\n\n83394\n\n4.64\n\n6.44\n\n11.08\n\n87862\n\n76931\n\n5.12\n\n7.32\n\n12.44\n\nU.S. Patent\n\nUS 8,019,804 B2\n\nSheet 9 of 12\n\nSep. 13, 2011\n\n14: Comparison of the encoding time between standard algorithm (JM encoder) and proposed FSSD algorithms in Akiyo\n\nConventional < \u3002 Time reduction by SSD FSSD Time reduction by inverse transform Total reduction QP Algori Algorithm | iterative Fig.-lookup \uff0c aaa gorithm (ms) uantization (%) and pixel of encoding time (%) (ms) 9 reconstruction (%) 28 | 89261 76512 | 6.61 7.67 14.28 32 | 85365 72374 6.85 8.37 15.22 36 | 83705 71731 6.74 7.56 14.30 40 | 83363 71468 6.68 7.79 14.47\n\n15: Comparison of the encoding time between standard algorithm (JM encoder) and proposed FSSD algorithms in Foreman\n\nConventional SSD Algorithm (ms) FSSD Algorithm (ms) Time reduction by iterative Fig.-lookup quantization (%) Time reduction by inverse transform and pixel reconstruction (%) Total reduction of encoding time (%) 103621 90812 5.65 6.71 12.36\n\n16: Comparison of the encoding time between standard algorithm (JM encoder) and proposed FSSD algorithms in Container\n\nConventional . . Time reduction by SSD FSSD Time reduction by inverse transform Total reduction QP , Algorithm | iterative Fig.-lookup . aor Algorithm (ms) uantization (%) and pixel of encoding time (%) (ms) q reconstruction (%) 28 | 101251 90139 4.48 6.49 10.97 32 | 93789 83394 4.64 6.44 11.08 36 | 87862 76931 5.12 7.32 12.44 40 | 82681 72158 5.50 7.23 12.73\n\nFig.\n\nthe\n\nFig.\n\nthe\n\nFig.\n\nthe\n\nU.S. Patent\n\nSep. 13, 2011\n\nSheet 10 of 12\n\nUS 8,019,804 B2\n\nFig. 17: Comparison of the encoding time between standard algorithm (JM encoder) and the\n\nproposed FSSD algorithms in Stefan\n\nConventional FSSD\n\nTime reduction by Time reduction by\n\nQP SSD\n\nAlgorithm\n\niterative Fig.-lookup inverse transform\n\nTotal reduction\n\nAlgorithm\n\nand pixel\n\nof encoding time (%)\n\n(ms)\n\nquantization (%)\n\n(ms)\n\nreconstruction (%)\n\n126685\n\n115892\n\n4.06\n\n4.46\n\n8.52\n\nFig. 18: Average number of iterative lookup operation for different videos\n\nAkiyo\n\nForeman\n\nContainer\n\nStefan\n\nQP\n\nFig. 19: Comparison of the rate-distortion performance between standard algorithm (JM\n\nencoder) and the proposed FSSD algorithms in Akiyo\n\nPSNR - dB\n\nPSNR - dB\n\nBit-rate - Kbps\n\nBit-rate - Kbps\n\nQP\n\n(Conventional SSD) (FSSD)\n\n(Conventional SSD) (FSSD)\n\n28\n\n39.94\n\n39.94\n\n28.09\n\n28.09\n\n15403\n\n154.18\n\n111.77\n\n111.84\n\n40\n\n31.43\n\n31:42\n\n8O.78\n\n80.71\n\nU.S. Patent\n\nUS 8,019,804 B2\n\nSep. 13, 2011\n\nSheet 10 of 12\n\n17: Comparison of the encoding time between standard algorithm (JM encoder) and proposed FSSD algorithms in Stefan\n\nConventional . . Time reduction by SSD FSSD Time reduction by inverse transform Total reduction Algorithm Algorithm Meratiy \u00a9 Fig--lookup and pixel of encoding time (%) sort (ms) quantization (%) \u4e86 g (ms) reconstruction (%) 126685 115892 4.06 4.46 8.52 114568 103625 4.25 5.30 9.55 102638 92258 471 5.40 10.11 95921 85784 5.08 5.49 10.57\n\nFig. 18: Average number of iterative lookup operation for different videos\n\nQP Akiyo Foreman Container Stefan 28 0.29 0.40 0.45 0.73 32 0.26 0.37 0.40 0.67 36 0.11 0.16 0.20 0.31 40 0.05 0.08 0.11 0.15\n\n19: Comparison of the rate-distortion performance between standard algorithm FSSD algorithms in Akiyo encoder) and the proposed\n\nQP PSNR -dB PSNR - dB Bit-rate - Kbps Bit-rate - Kbps (Conventional SSD) _ | (FSSD) (Conventional SSD) | (FSSD) 28 39.94 39.94 218.09 218.09\n\nFig.\n\nthe\n\nFig.\n\n(JM\n\nU.S. Patent\n\nSep. 13, 2011\n\nSheet 11 of 12\n\nUS 8,019,804 B2\n\nFig. 20: Comparison of the rate-distortion performance between standard algorithm (JM\n\nencoder) and the proposed FSSD algorithms in Foreman\n\nPSNR - dB\n\nPSNR - dB\n\nBit-rate - Kbps\n\nBit-rate - Kbps\n\n(Conventional SSD) (FSSD)\n\n(Conventional SSD) (FSSD)\n\n34.90\n\n34.87\n\n251.64\n\n251.35\n\n32.40\n\n32.40\n\n163.58\n\n163,70\n\nFig. 21: Comparison of the rate-distortion performance between standard algorithm (JM\n\nencoder) and the proposed FSSD algorithms in Container.\n\nQP\n\nPSNR - dB\n\nPSNR - dB\n\nBit-rate - Kbps\n\nBit-rate - Kbps\n\n(Conventional SSD) (FSSD)\n\n(Conventional SSD) (FSSD)\n\n28\n\n38.09\n\n38.09\n\n331.82\n\n33 192\n\n32\n\n35.28\n\n212.09\n\n21153\n\n36\n\n32.61\n\n32.60\n\n145.46\n\n145.18\n\n40\n\n29.85\n\n29.84\n\n100.13\n\n100.10\n\nFig. 22: Comparison of the rate-distortion performance between standard algorithm (JM\n\nencoder) and the proposed FSSD algorithms in Stefan\n\nPSNR - dB\n\nPSNR - dB\n\nBit-rate - Kbps\n\nBit-rate - Kbps\n\n(Conventional SSD) (FSSD)\n\n(Conventional SSD) (FSSD)\n\n33.49\n\n33.48\n\n597.29\n\n597.58\n\n36\n\n30.22\n\n30.21\n\n388.42\n\n389,12\n\n40\n\n26.91\n\n26.88\n\n242.23\n\n242.06\n\nU.S. Patent\n\nUS 8,019,804 B2\n\nSep. 13, 2011\n\nSheet 11 of 12\n\n20: Comparison of the rate-distortion performance between standard algorithm encoder) and the proposed FSSD algorithms in Foreman\n\nQP PSNR - dB PSNR - dB Bit-rate ~ Kbps Bit-rate - Kbps (Conventional SSD) | (FSSD) (Conventional SSD) | (FSSD) 28 37.84 37.82 421.58 420.86 32 34.90 34.87 251.64 251.35 36 32.40 32.40 163.58 163.70 40 29.69 29.67 110.09 109.94\n\nFig. 21: Comparison of the rate-distortion performance between standard algorithm encoder) and the proposed FSSD algorithms in Container.\n\nPSNR - dB PSNR - dB Bit-rate - Kbps Bit-rate - Kbps QP (Conventional SSD) | (FSSD) (Conventional SSD) | (FSSD) 28 38.09 38.09 331.82 331.92 32 35.28 35.27 212.09 211.53 36 32.61 32.60 145.46 145.18 40 29.85 29.84 100.13 100.10\n\n22: Comparison of the rate-distortion performance between standard algorithm encoder) and the proposed FSSD algorithms in Stefan\n\nPSNR - dB PSNR - dB Bit-rate - Kbps Bit-rate - Kbps QP (Conventional SSD) | (FSSD) (Conventional SSD) | (FSSD) 28 37.16 37.15 891.62 890.88 32 33.49 33.48 597.29 597.58 36 30.22 30.21 388.42 389.12 40 26.91 26.88 242.23 242.06\n\nFig.\n\n(JM\n\n(JM\n\nFig.\n\n(JM\n\nU.S. Patent\n\nSep. 13, 2011\n\nSheet 12 of 12\n\nUS 8,019,804 B2\n\nFig. 23: Performance of fast SSD algorithms with rate estimation in Akiyo\n\nQP\n\nReduction of encoding PSNR reduction-dB\n\nBit rate increase (%)\n\ntime (%)\n\n28\n\n40.85\n\n32\n\n37.66\n\n36\n\n34.91\n\n0.08\n\n2.63\n\n40\n\n31.19\n\nO.O2\n\n0.47\n\nFig. 24: Performance of FSSD algorithms with rate estimation in Foreman\n\nReduction of encoding PSNR reduction -dB\n\nBitrate increase (%)\n\ntime (%)\n\n40.03\n\n36.43\n\n34.32\n\n30.45\n\nFig. 25 Performance of FSSD algorithms with rate estimation in Container\n\nQP\n\nReduction of encoding PSNR reduction-dB\n\nBitrate increase (%)\n\ntime (%)\n\n28\n\n39.84\n\n0.91\n\n32\n\n38.02\n\n0.02\n\n36\n\n40\n\nFig. 26 Performance of FSSD algorithms with rate estimation in Stefan\n\nQP\n\nReduction of encoding PSNR reduction-dB\n\nBitrate increase (%)\n\ntime (%)\n\n28\n\n32\n\n36\n\n40\n\nU.S. Patent\n\nUS 8,019,804 B2\n\nSep. 13, 2011\n\nSheet 12 of 12\n\n23: Performance of fast SSD algorithms with rate estimation in Akiyo\n\nReduction of encoding time (%) PSNR reduction -dB Bit rate increase (%)\n\nFig. 24: Performance of FSSD algorithms with rate estimation in Foreman\n\nQP Reduction of encoding | PSNR reduction -dB | Bit rate increase (%) time (%) 28 40.03 0.03 101 32 36.43 \u201c0.04 215 36 34.32 0.02 0.62 40 30.45 0.02 0.24\n\nFig. 25 Performance of FSSD algorithms with rate estimation in Container\n\nReduction of encoding PSNR reduction -dB Bit rate increase (%) time (%) 28 39.84 -0.08 0.91 32 38.02 -0.10 0.02 36 34.50 -0.03 1.61 40 33.51 -0.06 1.59\n\nFig. 26 Performance of FSSD algorithms with rate estimation in Stefan\n\nReduction of encoding PSNR reduction -dB Bit rate increase (%) 36.09 -0.06 time (%) 28 43.00 -0.11 0.51 32 38.57 -0.10 0.53 0.52 29.75 -0.08 1.31\n\nFig.\n\nUS 8,019,804 B2\n\n1.\n\n2\n\nthe coefficient by 20 and rounding to the nearest integer\n\nMETHOD AND APPARATUS FOR\n\nquantizes the coefficient to the nearest of 41 quantization\n\nCALCULATING AN SSD AND ENCODNGA\n\npoints (from -20 to +20, including 0).\n\nVIDEO SIGNAL\n\nAfter quantization, the number of bits required to encode\n\nthe data is reduced further by taking advantage of certain\n\nFIELD OF THE INVENTION\n\nstatistical properties of the quantized data. This process is\n\ncalled entropy encoding. For example, after quantization,\n\nThe present invention relates to a method and apparatus for\n\nmany of the coefficients may have a value of Zero; a type of\n\ncalculating the sum of squared differences between an origi\n\nentropy encoding called run-length coding, takes account of\n\nnal block and a reconstructed block of image or video data\n\nconsecutive Zero coefficients and encodes the length of each\n\nand/or a method and apparatus for determining the distortion\n\n10\n\nSuch run, rather than encoding each Zero value separately.\n\ncaused by encoding a block of image or video data. The\n\nOther types of entropy encoding which take advantage of the\n\npresent invention also proposes an apparatus and method for\n\nstatistical properties of the data, for example variable length\n\nencoding image or video data, in which an appropriate encod\n\nencoding (VLC) or arithmetic coding, may also be used. The\n\ning mode is selected from a plurality of possible encoding\n\nabove describes simple encoding methods in which each\n\nmodes. The method and apparatus may be used for encoding\n\n15\n\nblock in each frame is encoded independently of the other\n\na H.264/AVC video signal, but the present invention is not\n\nframes. This method of encoding is still used, however most\n\nlimited to that format and may be used to encode other for\n\nmodern compression algorithms allow a variety of different\n\nmats of video and image data as well.\n\nblock encoding modes, any of which may be used to encode\n\na particular block.\n\nBACKGROUND TO THE INVENTION\n\nAn intra encoding mode is a mode in which each block is\n\nA video signal typically comprises a series of frames, each\n\nencoded on the basis of data held within that block (the source\n\nshowing an image at one instant in time. When the frames are\n\nblock) and on the basis of data in other blocks (reference\n\ndisplayed quickly in Succession they give the impression of a\n\nblocks) in the same frame. The encoding process may work as\n\nmoving image. In order to reduce the data rate required to\n\nfollows. The contents of the source block are predicted on the\n\n25\n\nstore or send a video signal, compression algorithms (com\n\nbasis one or more reference blocks in the same frame (this is\n\ncalled intra prediction). The difference between the predicted\n\nmonly known as a codecs) are used to encode the data. Such\n\ncompression algorithms typically divide each frame into a\n\nblock and the source block is called a residual block. The\n\nresidual block is encoded by image transforming, quantizing\n\nnumber of smaller blocks, each of which is encoded.\n\nand entropy encoding, as explained in the paragraphs above.\n\nColor video images typically comprise several color\n\n30\n\nplanes, for example a RGB image comprises red, green and\n\nThe encoded residual block is stored together with coding\n\ndata identifying the reference blocks and identifying the\n\nblue color planes, which when overlaid or mixed makeup the\n\nencoding mode used for the intra prediction. During decoding\n\nfull color image. Video applications commonly use a color\n\nscheme in which the planes do not correspond to specific\n\nthe predicted block is computed from the coding data and the\n\ncolors. Instead one plane corresponds to luminance (the\n\nSource block is reconstructed by adding the (decoded)\n\n35\n\nbrightness of each pixel in the color image), and the other\n\nresidual block to the predicted block. There may be several\n\ndifferent possible intra encoding modes based on different\n\nplanes\u2014usually two of them\u2014contain certain color informa\n\nblock sizes or different positions of the reference block(s)\n\ntion (chrominance). When the chrominance information is\n\ncombined with the luminance information, the color image\n\nrelative to the source block.\n\ncan be derived and displayed, either directly or by first con\n\nAn inter encoding mode makes use of the fact that in a\n\n40\n\nverting the information into separate RGB levels. The reason\n\nvideo signal there are often substantial similarities between\n\nthat a luminance-chrominance system is commonly used is\n\nSuccessive frames, for example, in areas of the image in which\n\nthere is no movement, or areas relating to a moving object\n\nthat human perception is much more sensitive to differences\n\nin luminance than chrominance. Therefore video compres\n\nwhich translates in position between Successive frames. An\n\ninter encoding mode predicts the content of a particular\n\nsion algorithms typically encode the chrominance informa\n\n45\n\nblock (a source block) on the basis of another block (called a\n\ntion at a lower resolution than the luminance information, in\n\norder to reduce the amount of data needed, without unduly\n\nreference block) in a different frame (which may be one or\n\naffecting image quality. Such blocks of data with differing\n\nmore frames before or after the frame containing the block\n\nbeing predicted). This is called inter-prediction as the predic\n\nresolutions of luminance and chrominance data are called\n\nmacroblocks. A typical macroblock may, for example, have\n\ntion is based in blocks in other frames. The residual block is\n\n50\n\nthe difference between the predicted block and the source\n\ntwo planes of chrominance data at half the vertical and half\n\nblock. The residual block is encoded by using an image trans\n\nthe horizontal resolution of the luminance data. However, in\n\nform, quantizing and entropy encoding. The encoded residual\n\nthis patent specification the term macroblock is used to\n\nblock is stored together with coding data identifying the ref\n\nmean any block of image data that has chrominance data at\n\nerence block used and the particular inter-prediction mode\n\nless resolution than luminance data.\n\n55\n\nused. The coding data may for example comprise a motion\n\nData in the blocks of the video frame is typically encoded\n\nvector relating the reference block and the predicted block.\n\nby use of a transform, which transforms the data into fre\n\nDuring decoding the predicted block is computed from the\n\nquency space. A Discrete Cosine Transform (DCT) is often\n\nused for this purpose, but other types of transform may be\n\ncoding data and the source block is reconstructed by adding\n\nthe predicted block to the (decoded) residual block. There\n\nused instead. The human eye is less sensitive to information\n\n60\n\nmay be several different possible inter-prediction modes,\n\ncontained in the high frequency components and therefore\n\nSome information relating to the higher frequencies may be\n\neach based on different block sizes, different reference blocks\n\ndiscarded or encoded using fewer bits, in order to reduce the\n\nor different frames relative to the source block.\n\nA skip mode is a special case of an inter encoding mode. It\n\namount of data. Once this is done the transformed block may\n\nbe quantized, by Scaling the transform coefficients to the\n\nrelates a source block directly to a reference block in another\n\n65\n\nnearest of a number of predetermined values. For example, if\n\nframe (i.e. the two are predicted to be identical). Thus, the\n\nSource block is predicted to have exactly the same contents as\n\nthe transform coefficients are between -1 and 1, then scaling\n\nUS 8,019,804 B2\n\n1\n\n2\n\nMETHOD AND APPARATUS FOR CALCULATING AN SSD AND ENCODING A VIDEO SIGNAL\n\ncoefficient by 20 and rounding to the nearest integer quantizes the coefficient to the nearest of 41 quantization points (from -20 to +20, including 0).\n\nthe data is reduced further by taking advantage of certain statistical properties of the quantized data. This process is called \u2018entropy encoding\u2019. For example, after quantization, many of the coefficients may have a value of zero; a type of entropy encoding called run-length coding, takes account of consecutive zero coefficients and encodes the length of each such \u2018run\u2019, rather than encoding each zero value separately. Other types of entropy encoding which take advantage of the statistical properties of the data, for example variable length encoding (VLC) or arithmetic coding, may also be used. The above describes simple encoding methods in which each block in each frame is encoded independently of the other frames. This method of encoding is still used, however most modern compression algorithms allow a variety of different lock encoding modes, any of which may be used to encode\n\nFIELD OF THE INVENTION\n\nThe present invention relates to a method and apparatus for calculating the sum of squared differences between an origi- nal block and a reconstructed block of image or video data and/or a method and apparatus for determining the distortion caused by encoding a block of image or video data. The present invention also proposes an apparatus and method for encoding image or video data, in which an appropriate encod- ing mode is selected from a plurality of possible encoding modes. The method and apparatus may be used for encoding a H.264/AVC video signal, but the present invention is not limited to that format and may be used to encode other for- of video and data well.\n\nBACKGROUND TO THE INVENTION\n\nencoding mode a encoded on the basis of data held within that block (the source lock) and on the basis of data in other blocks (reference locks) in the same frame. The encoding process may work as follows. The contents of the source block are predicted on the asis one or more reference blocks in the same frame (this is called intra prediction). The difference between the predicted block and the source block is called a residual block. The residual block is encoded by image transforming, quantizing and entropy encoding, as explained in the paragraphs above. The encoded residual block is stored together with coding data identifying the reference blocks and identifying the encoding mode used for the intra prediction. During decoding the predicted block is computed from the coding data and the source block is reconstructed by adding the (decoded) residual block to the predicted block. There may be several different possible intra encoding modes based on different block sizes or different positions of the reference block(s) relative the block.\n\nA video signal typically comprises a series of frames, each showing an image at one instant in time. When the frames are displayed quickly in succession they give the impression of a moving image. In order to reduce the data rate required to store or send a video signal, compression algorithms (com- monly known as a \u2018codecs\u2019) are used to encode the data. Such compression algorithms typically divide each frame into a number of smaller blocks, each of which is encoded.\n\nplanes, for example a RGB image comprises red, green and blue color planes, which when overlaid or mixed make up the full color image. Video applications commonly use a color scheme in which the planes do not correspond to specific colors. Instead one plane corresponds to luminance (the brightness of each pixel in the color image), and the other planes\u2014usually two of them\u2014contain certain color informa- tion (chrominance). When the chrominance information is combined with the luminance information, the color image can be derived and displayed, either directly or by first con- verting the information into separate RGB levels. The reason that a luminance-chrominance system is commonly used is that human perception is much more sensitive to differences in luminance than chrominance. Therefore video compres- sion algorithms typically encode the chrominance informa- tion at a lower resolution than the luminance information, in order to reduce the amount of data needed, without unduly affecting image quality. Such blocks of data with differing resolutions of luminance and chrominance data are called \u2018macroblocks\u2019. A typical macroblock may, for example, have two planes of chrominance data at half the vertical and half the horizontal resolution of the luminance data. However, in this patent specification the term \u2018macroblock\u2019 is used to mean any block of image data that has chrominance data at\n\nvideo signal there are often substantial similarities between successive frames, for example, in areas of the image in which there is no movement, or areas relating to a moving object which translates in position between successive frames. An inter encoding mode \u2018predicts\u2019 the content of a particular lock (a source block) on the basis of another block (called a reference block) in a different frame (which may be one or more frames before or after the frame containing the block ing predicted). This is called inter-prediction as the predic- tion is based in blocks in other frames. The residual block is the difference between the predicted block and the source lock. The residual block is encoded by using an image trans- form, quantizing and entropy encoding. The encoded residual block is stored together with coding data identifying the ref- erence block used and the particular inter-prediction mode used. The coding data may for example comprise a motion vector relating the reference block and the predicted block. During decoding the predicted block is computed from the coding data and the source block is reconstructed by adding the predicted block to the (decoded) residual block. There may be several different possible inter-prediction modes, each based on different block sizes, different reference blocks\n\nData in the blocks of the video frame is typically encoded by use of a transform, which transforms the data into fre- quency space. A Discrete Cosine Transform (DCT) is often used for this purpose, but other types of transform may be used instead. The human eye is less sensitive to information contained in the high frequency components and therefore some information relating to the higher frequencies may be discarded or encoded using fewer bits, in order to reduce the amount of data. Once this is done the transformed block may be quantized, by scaling the transform coefficients to the nearest of a number of predetermined values. For example, if the transform coefficients are between -1 and 1, then scaling\n\nA skip mode is a special case of an inter encoding mode. relates a source block directly to a reference block in another frame (i.e. the two are predicted to be identical). Thus, source block is predicted to have exactly the same contents\n\nmats\n\nimage\n\nas\n\nColor\n\nvideo\n\nimages typically comprise several\n\ncolor\n\nless resolution than luminance data.\n\n20\n\n35\n\n40\n\n45\n\n50\n\n55\n\n60\n\n65\n\nthe\n\nAfter quantization, the number of bits required to encode\n\na particular block. An intra\n\nis\n\nmode in which each block is\n\nto\n\nsource An inter encoding mode makes use of the fact that in a\n\nor different frames relative to the source block.\n\nIt\n\nthe\n\nas\n\nUS 8,019,804 B2\n\n3\n\n4\n\nzation (RDO). It can find the best mode accurately, but takes\n\nthe reference block. The source block may then be encoded as\n\na lot of time and processing power.\n\ndata indicating that it is a skip mode and data indicating the\n\nidentity of the reference block. Decoding is carried out by\n\nTo accelerate the coding process, the JVT reference soft\n\nfinding the identity of the reference block and copying its data\n\nware version JM 6.1d estimates the rate-distortion cost by\n\nusing a fast SAD-based cost function instead:\n\nto form the reconstructed block.\n\nIt can be useful to know the distortion caused by encoding\n\na block of video or image data; for example, if it is desired to\n\nencode an image but retain a given image quality. The distor\n\nf\n\no P) + 1. 4K if intra 4x4 mode\n\n(EQUATION 3)\n\nSAD F\n\ntion is typically measured as the sum of squared differences\n\nSAD(S, P)\n\notherwise\n\n10\n\nbetween coefficients of the original source block and the\n\ncoefficients of the reconstructed block. Knowing the distor\n\nwhere SAD(SP) is the sum of absolute differences\n\ntion is also useful when deciding which encoding mode to\n\nbetween the original block Sand the predicted block P. W is\n\nuse, as will be explained below.\n\nan approximate exponential function of the quantization\n\nIt is important to select the best mode for encoding each\n\nparameter (QP) which is almost the square of W, and Kis equal\n\n15\n\nblock, as this is an important factor in the performance of the\n\nto 0 for the probable mode and 1 for the other modes. The\n\ncompression algorithm. There are two principal consider\n\nSAD(S.P) is expressed by:\n\nations when selecting the block encoding mode; the first is the\n\ndistortion which results from the encoding (i.e. the difference\n\nbetween the Source image and the reconstructed image after\n\ndecoding) and the second is the number of bits required to\n\n(EQUATION 4)\n\nW W\n\nSAD(S, P) =\n\nsii - Pil\n\nencode the block. Sometimes the latter consideration is\n\ni\n\nO\n\nO\n\nreferred to as bit rate, which is the number of bits required\n\nper second required to transmit the image at a given resolu\n\nwhere s, and p, are the (i,j)th elements of the current\n\ntion. The bit rate is related to the overall number of bits\n\n25\n\nrequired to encode the block. It is necessary not only to select\n\noriginal block S and the predicted block P. respectively. This\n\nbetween inter, intra and skip modes, but also to select the best\n\nSAD-based cost function could save a lot of computations as\n\ntype of inter encoding or best type of intra encoding.\n\nthe distortion part is based on the differences between the\n\nOne known theoretical method of choosing the best block\n\noriginal block and the predicted block instead of the recon\n\nencoding mode is to compute the rate-distortion cost of all the\n\nstructed block. However, this computation reduction usually\n\n30\n\npossible modes. The rate-distortion cost is a parameter, which\n\ncomes with a quite significant degradation of coding effi\n\ntakes account of both the distortion caused by the encoding\n\nciency. To achieve better rate-distortion performance, JM6.1d\n\nand the number of bits required to encode the block.\n\nalso provided an alternative SATD-based cost function:\n\nIt is possible to encode and decode each block to find the\n\ndistortion and bit rate for each mode directly. For example, in\n\n35\n\nthe H.264/AVC encoding process, the best macroblock\n\n(EQUATION 5)\n\nSATD(S, P) + 1. 4K if intra 4x4 mode\n\nJSATD =\n\nencoding mode may be selected by computing the rate-dis\n\notherwise\n\nSATD(S, P)\n\ntortion cost of all possible modes. The best mode is typically\n\nthe one with minimum rate-distortion cost. The rate distortion\n\nwhere SATD(S.P) is the sum of absolute Hadamard-trans\n\ncost for a given mode may be defined as:\n\nformed difference between the original block S and the pre\n\n40\n\ndicted block P. which is given by:\n\nJ=SSD(S,C)+WR\n\n(EQUATION 1)\n\nwhere J\n\nrepresents the rate distortion, w is the Lagrange\n\nmultiplier, R is the number of bits required to encode the\n\n(EQUATION 6)\n\nblock according to that mode, and the SSD(S,C) is the sum of\n\nSATD(S, P) =\n\n45\n\nthe squared differences (SSD) between the original blocks S\n\nand the reconstructed block C when that encoding mode is\n\nused. The Sum of squared differences can be expressed as:\n\nwhere h are the (i,j)th element of the Hadamard trans\n\nformed image block H which is the difference between the\n\n50\n\noriginal block S and the predicted block P. The Hadamard\n\nW\n\n2\n\n2\n\n(EQUATION 2)\n\ntransformed block His defined as:\n\n(sii - cii) = |S \u2013 CIlf\n\nO\n\nH = T, (S-P)T,\n\n(EQUATION 7)\n\nwhere s, and c, are the (i,j)th elements of the current\n\n55\n\nWith:\n\noriginal block S and the reconstructed block C, respectively.\n\nMoreover, N is the image block size (N=4 in H.264/AVC\n\n(EQUATION 8)\n\nstandard) and\n\nis Frobenius norm. We shall call the SSD\n\nTH\n\n(S,C) a spatial-domain SSD since the distortion computation\n\nis performed in spatial-domain pixel values. The inventors\n\n60\n\nhave found that the computation of a spatial-domain SSD is\n\nvery time-consuming, since it is necessary to obtain the\n\nExperimental results show that the Js\n\ncan achieve better\n\nreconstructed block after Transformation\u2014Quantization\u2014\n\nrate-distortion performance than the Js, but its overall rate\n\nInverse\n\nQuantization\u2014Inverse Transformation Pixel\n\ndistortion performance is still lower than the optimized J.\n\nReconstruction for each possible mode. The above method of\n\n65\n\nfinding the best mode by calculating the SSD (S,C) and bit\n\n(found by computing the rate distortion of each mode\n\nrate directly for each mode is called Rate Distortion Optimi\n\ndirectly). Thus, neither SAD nor SATD-based functions can\n\nUS 8,019,804 B2\n\n4\n\n3\n\nzation (RDO). It can find the best mode accurately, but lot of time and processing power.\n\nreference block. The source block may then be encoded as data indicating that it is a skip mode and data indicating the identity of the reference block. Decoding is carried out by finding the identity of the reference block and copying its data form the reconstructed block.\n\nTo accelerate the coding process, the IVT reference soft- ware version JM 6.1d estimates the rate-distortion cost a fast SAD-based cost function instead:\n\nIt can be useful to know the distortion caused by encoding a block of video or image data; for example, if it is desired to encode an image but retain a given image quality. The distor- tion is typically measured as the sum of squared differences between coefficients of the original source block and the coefficients of the reconstructed block. Knowing the distor- tion is also useful when deciding which encoding mode to use, as will be explained below.\n\nfare. P)+A,-4K if intradx4mode \u2014 (EQUATION 3) SAD = SAD(S, P) otherwise\n\nwhere SAD(S,P) is the sum of absolute differences between the original block S and the predicted block P. 4, is an approximate exponential function of the quantization parameter (QP) which is almost the square of, and K is equal to 0 for the probable mode and 1 for the other modes. The SAD(S,P) is expressed by:\n\nblock, as this is an important factor in the performance of the compression algorithm. There are two principal consider- ations when selecting the block encoding mode; the first is the distortion which results from the encoding (i.e. the difference between the source image and the reconstructed image after decoding) and the second is the number of bits required to encode the block. Sometimes the latter consideration is referred to as \u2018bit rate\u2019, which is the number of bits required per second required to transmit the image at a given resolu- tion. The bit rate is related to the overall number of bits required to encode the block. It is necessary not only to select between inter, intra and skip modes, but also to select the best\n\n(EQUATION 4)\n\nNoro SAD(S, P) = 0 \u4e8c Isiz \u2014 pil\n\nwhere sy and py are the (ij)th elements of the current original block S and the predicted block P respectively. This SAD-based cost function could save a lot of computations as the distortion part is based on the differences between the original block and the predicted block instead of the recon- structed block. However, this computation reduction usually comes with a quite significant degradation of coding effi- ciency. To achieve better rate-distortion performance, JM6.1d also provided an alternative SATD-based cost function:\n\nOne known theoretical method of choosing the best block encoding mode is to compute the rate-distortion cost of all the possible modes. The rate-distortion cost is aparameter, which takes account of both the distortion caused by the encoding and the number of bits required to encode the block.\n\nIt is possible to encode and decode each block to find the distortion and bit rate for each mode directly. For example, in the H.264/AVC encoding process, the best macroblock encoding mode may be selected by computing the rate-dis- tortion cost of all possible modes. The best mode is typically the one with minimum rate-distortion cost. The rate distortion cost for a given mode may be defined as:\n\nSATD(S, P)+21-4K if intra 4x4 mode SATD\\S, P) (EQUATION 5) Isarp = otherwise\n\nwhere SATD(S,P) is the sum of absolute Hadamard-trans- formed difference between the original block S and the dicted block P, which is given by:\n\nJap=SSDS.CMR (BQUATION 1)\n\nwhere Jp represents the rate distortion, A is the Lagrange multiplier, R is the number of bits required to encode the block according to that mode, and the SSD(S,C) is the sum of the squared differences (SSD) between the original blocks S and the reconstructed block C when that encoding mode is used. The sum of squared differences can be expressed as:\n\nN-IN-1 SATD(S, P) = > 70 70 (EQUATION 6) Vl\n\nwhere hz are the (i, j)th element of the Hadamard trans- formed image block H which is the difference between original block S and the predicted block P. The Hadamard transformed block H is defined as:\n\nACTN-1 ee \u4e00 (EQUATION 2) 0 Fa SSDS, C) =\n\n(EQUATION 7)\n\nH=T;(S-P)T} With:\n\nwhere sy and co are the (i,j)th elements of the current original block S and the reconstructed block C, respectively. Moreover, N is the image block size (N=4 in H.264/AVC standard) and || ||; is Frobenius norm. We shall call the SSD (S,C) a spatial-domain SSD since the distortion computation is performed in spatial-domain pixel values. The inventors have found that the computation of a spatial-domain SSD is very time-consuming, since it is necessary to obtain the reconstructed block after Transformation\u2014Quantization\u2014 Inverse Quantization\u2014Inverse Trans formation\u2014Pixel Reconstruction for each possible mode. The above method of finding the best mode by calculating the SSD (S,C) and bit 65\n\nExperimental results show that the J..,7,, can achieve rate-distortion performance than the J, ,,,, but its overall rate- distortion performance is still lower than the optimized (found by computing the rate distortion of each mode directly). Thus, neither SAD nor SATD-based functions\n\nthe\n\nto\n\nIt is important to select the best mode for encoding each\n\ntype of inter encoding or best type of intra encoding.\n\nrate directly for each mode is called Rate Distortion Optimi-\n\n10\n\n15\n\n40\n\n45\n\n50\n\ntakes\n\na\n\nby\n\nusing\n\npre-\n\nthe\n\n8)\n\nTy\n\nbetter\n\nJz,\n\ncan\n\nUS 8,019,804 B2\n\n6\n\n5\n\nThe quantizing performed by the operator Q may be pre\n\npredict the real distortion accurately, and therefore they lead\n\nscaled quantizing. Pre-scaled quantizing means that the quan\n\nto selection of Sub-optimum encoding modes which have a\n\ntization step for each coefficient is scaled according to the\n\nhigher bit rate or higher distortion than the optimum.\n\nlocation of the coefficient in the integer transformed residual\n\nA rate-distortion performance comparison of H.264/AVC\n\nblock F*. This has the effect of making the integer image\n\nusing RDO-based, SAD-based and SATD-based cost func\n\ntransform orthogonal (which is required by most video and\n\ntions for different QPs (quantization step sizes) and three\n\nimage encoding processes). In other words, the necessary\n\nwell-known test sequences in terms of PSNR and bit-rate is\n\nScaling of the integer transform is integrated into the quanti\n\nshown in the table in FIG. 1. As can be seen from the table,\n\nZation process.\n\ncompared with a RDO-based encoder, the SAD-based and\n\nFor example, the ICT transform requires Scaling to make it\n\n10\n\nSATD-based cost functions are not good at selecting the\n\northogonal. Carrying out pre-scaled quantizing on a ICT\n\nmode having the best (lowest) rate-distortion cost.\n\ntransformed block F, gives the same quantization matrix Z\n\nIn Summary, computing the rate-distortion cost (hereinaf\n\nas would be obtained by (unscaled) quantizing of a DCT\n\nter also referred to as rate-distortion) of each mode directly\n\ntransformed residual block. The same is true of some other\n\nfrom the source and reconstructed blocks takes a lot of pro\n\ninteger image transforms and their discrete equivalents. How\n\n15\n\ncessing power and is not practical to carry out in real time\n\never, not every integer image transform requires Scaling; for\n\nwithout high end computing hardware. Meanwhile using the\n\nexample the Walsh and Hadamard transforms are integer\n\nSAD and SADT functions are not good at predicting the real\n\nimage transforms which do not require Scaling.\n\nrate-distortion caused by the encoding process and may result\n\nPreferably step d) is carried out with the aid of a look up\n\nin Sub-optimum modes being selected.\n\ntable. As a look up table is used it may be possible to avoid\n\nmultiplication, division and/or rounding operations in the\n\nquantization and/or inverse quantization processes. For\n\nSUMMARY OF THE INVENTION\n\nexample, it may be possible to carry out the quantization\n\nand/or inverse quantization by simple comparison off, * val\n\nIt would be desirable to have a quick and efficient way of\n\ndetermining the distortion caused by encoding a block and a\n\nues with values held in the look up table. Preferably the look\n\n25\n\nup table is referred to iteratively.\n\nquick and efficient method of encoding blocks using an\n\nPreferably step (d) comprises the step of iteratively com\n\nencoding scheme that is capable of utilizing a plurality of\n\ndifferent possible encoding modes and selecting the best\n\nparing each coefficient f* of the transformed residual block\n\nto boundary points of quantization Sub-Zones stored in the\n\nmode for the job.\n\nAccordingly, one aspect of the present invention proposes\n\nlook up table. A quantization Sub-Zone contains all the values\n\n30\n\nof f* between its upper and lower boundary points. The\n\nthat the distortion is calculated in transform domain space, for\n\noperator Q maps all the values of f* within the sub-zone to a\n\nexample on the basis of a difference between the source and\n\nparticular quantization point having a quantized value Z,\n\nreconstructed blocks in frequency space. It is further advan\n\ncorresponding to that sub-zone. The operator Q\" maps the\n\ntageous if the quantization of the transformed block in fre\n\nquantized value Z, to an inverse quantized value i. CO\n\nquency space is carried out with the aid of a look up table. In\n\n35\n\npreferred embodiments of the invention it may be possible to\n\nsponding to that Sub-Zone.\n\nThe look up table may comprise a plurality of quantization\n\ncarry out the quantization and/or inverse quantization step\n\nSub-Zone boundaries each corresponding to a quantization\n\nwithout multiplication or division functions, which take a lot\n\nof processing power.\n\npoint. In a preferred embodiment it may only be necessary for\n\nthe look up table to relate each quantization point to a respec\n\nA first aspect of the present invention provides a method for\n\n40\n\ncalculating the sum of squared differences between an origi\n\ntive upper boundary, rather than both upper and lower bound\n\naries. In the look up process, the value of each coefficient f*\n\nnal block S and a reconstructed block R of image or video\n\nmay be iteratively compared with the upper boundaries of\n\ndata, the method comprising the steps of\n\nquantization points and when said upper boundary is greater\n\na) computing a predicted block P corresponding to the\n\noriginal block S. using inter or intra frame prediction;\n\nthan said coefficient, the coefficient f* can be assigned a\n\n45\n\nquantized value Z, and an inverse quantized value f* corre\n\nb) calculating a residual block D from the original block S\n\nsponding to the quantization Sub-Zone having that upper\n\nand the predicted block P. said residual block D having a\n\nbounday. The quantized value may be stored in a look up table\n\nplurality of coefficients;\n\nc) applying an integer image transform to the coefficients\n\nor based on the number of comparisons made. The inverse\n\nquantized value may be stored in the lookup table or found by\n\nof the residual block D so as to obtain a transformed residual\n\n50\n\nmultiplying the quantized value with a quantization param\n\nblock F*, said transformed residual block having a plurality\n\neter A, which may be stored in the look up table. The quan\n\nof coefficients f*:\n\nM\n\nM\n\nd) finding a plurality of coefficients f*, the coefficients f*\n\ntization parameter A, may have different values for different\n\ni,j positions. In this way the Q and Q' operations can be\n\nbeing defined by the equation 1,-Q- (Q(?)), where Qisan\n\noperator which performs quantizing and Q is the inverse of\n\ncarried out by using the look up table.\n\n55\n\nthe Q operator, and\n\nPreferably the absolute value of each coefficient f* is\n\niteratively compared to boundaries of quantization Sub-Zones\n\ne) computing a sum of squared differences between f* and\n\nhaving progressively higher quantization point values until\n\nf*.\n\nAS the Sum of squared differences is calculated in the\n\nsaid absolute value of said coefficient is lower than a quanti\n\nZation Sub-Zone boundary. Because an absolute value is used,\n\nresidual domain, it is not necessary to reconstruct the block in\n\n60\n\nthe sign (positive or negative) of the coefficient f* can be\n\norder to calculate the distortion. This saves some processing\n\nignored in the look up process and introduced later to ensure\n\ntime. Furthermore, as the sum of squared differences is cal\n\nthat the i. and/or Z values are given the right sign. This\n\nculated in the transform domain, further processing is saved\n\nmakes the comparison process simpler and quicker and sim\n\nas it is not necessary to carry out the inverse image transform\n\npler (as only positive values have to be compared in the look\n\nto calculate the distortion. In addition, as the method uses an\n\n65\n\ninteger image transform, the coefficients f*, will be integers.\n\nup process and the look up table does not have to contain\n\nnegative values).\n\nThe coefficients f* may be integers or fractional numbers.\n\nUS 8,019,804 B2\n\n5\n\n6\n\nThe quantizing performed by the operator Q may be pre- scaled quantizing. Pre-scaled quantizing means that the quan- tization step for each coefficient is scaled according to the location of the coefficient in the integer transformed residual block F*. This has the effect of making the integer image transform orthogonal (which is required by most video and image encoding processes). In other words, the necessary scaling of the integer transform is integrated into the quanti- zation process.\n\npredict the real distortion accurately, and therefore they lead selection of sub-optimum encoding modes which have higher bit rate or higher distortion than the optimum.\n\nA rate-distortion performance comparison of H.264/AVC using RDO-based, SAD-based and SATD-based cost func- tions for different QPs (quantization step sizes) and three well-known test sequences in terms of PSNR and bit-rate is shown in the table in FIG. 1. As can be seen from the table, compared with a RDO-based encoder, the SAD-based and SATD-based cost functions are not good at selecting the mode having the best (lowest) rate-distortion cost.\n\nIn summary, computing the rate-distortion cost (hereinaf- ter also referred to as rate-distortion) of each mode directly from the source and reconstructed blocks takes a lot of pro- cessing power and is not practical to carry out in real time without high end computing hardware. Meanwhile using the SAD and SADT functions are not good at predicting the real rate-distortion caused by the encoding process and may result in sub-optimum modes being selected.\n\nPreferably step d) is carried out with the aid of a look up table. As a look up table is used it may be possible to avoid multiplication, division and/or rounding operations in the quantization and/or inverse quantization processes. For example, it may be possible to carry out the quantization and/or inverse quantization by simple comparison of f,,* val- ues with values held in the look up table. Preferably the look up table is referred to iteratively.\n\nSUMMARY OF THE INVENTION\n\nIt would be desirable to have a quick and efficient way of determining the distortion caused by encoding a block and a quick and efficient method of encoding blocks using an encoding scheme that is capable of utilizing a plurality of different possible encoding modes and selecting the best mode for the job.\n\nPreferably step (d) comprises the step of iteratively com- paring each coefficient f,,* of the transformed residual block to boundary points of quantization sub-zones stored in the look up table. A quantization sub-zone contains all the values of f,* between its upper and lower boundary points. The operator Q maps all the values of f,,* within the sub-zone to a particular quantization point having a quantized value zy corresponding to that sub-zone. The operator Qt maps the quantized value z,, to an inverse quantized value f,,* corre- sponding to that sub-zone.\n\nAccordingly, one aspect of the present invention proposes that the distortion is calculated in transform domain space, for example on the basis of a difference between the source and reconstructed blocks in frequency space. It is further advan- tageous if the quantization of the transformed block in fre- quency space is carried out with the aid of a look up table. In preferred embodiments of the invention it may be possible to carry out the quantization and/or inverse quantization step without multiplication or division functions, which take a lot of processing power.\n\nup may sub-zone boundaries each corresponding to a quantization point. In a preferred embodiment it may only be necessary for the look up table to relate each quantization point to a respec- tive upper boundary, rather than both upper and lower bound- aries. In the look up process, the value of each coefficient f,,* may be iteratively compared with the upper boundaries of quantization points and when said upper boundary is greater than said coefficient, the coefficient f,,* can be assigned a quantized value z,, and an inverse quantized value f,,* corre- sponding to the quantization sub-zone having that upper bounday. The quantized value may be stored in a look up table or based on the number of comparisons made. The inverse quantized value may be stored in the look up table or found by multiplying the quantized value with a quantization param- eter A,, which may be stored in the look up table. The quan- tization parameter A,, may have different values for different i,j positions. In this way the Q and Qv! operations can be\n\nA first aspect of the present invention provides a method for calculating the sum of squared differences between an origi- block S and a reconstructed block R of image or video data, the method comprising the steps of:\n\na) computing a predicted block P corresponding to block S, using inter or intra frame prediction;\n\nb) calculating a residual block D from the original block the predicted block P, said residual block D having plurality of coefficients;\n\nc) applying an integer image transform to the coefficients of the residual block D so as to obtain a transformed residual block F*, said transformed residual block having a plurality of coefficients f,,*;\n\nd) finding a plurality of coefficients f,,* \"the coefficients i being defined by the equation QQ )), where Q is an operator which performs quantizing and Q is the inverse of Q operator; and\n\nPreferably the absolute value of each coefficient f,,* is iteratively compared to boundaries of quantization sub-zones having progressively higher quantization point values until said absolute value of said coefficient is lower than a quanti- zation sub-zone boundary. Because an absolute value is used, the sign (positive or negative) of the coefficient f,,* can be ignored in the look up process and introduced later to ensure that the i* and/or zy values are given the right sign. This makes the comparison process simpler and quicker and sim- pler (as only positive values have to be compared in the look up process and the look up table does not have to contain negative values).\n\ne) computing a sum of squared differences between f,,* and i\u2019.\n\nAS \u2018the sum of squared differences is calculated in the residual domain, it is not necessary to reconstruct the block in order to calculate the distortion. This saves some processing time. Furthermore, as the sum of squared differences is cal- culated in the transform domain, further processing is saved as it is not necessary to carry out the inverse image transform to calculate the distortion. In addition, as the method uses an integer image transform, the coefficients f,,*, will be integers. The coefficients f,,* may be integers or fractional numbers.\n\nto\n\na\n\nnal\n\nthe\n\noriginal\n\nS\n\nand\n\na\n\n.\n\nthe\n\n10\n\n15\n\n20\n\n25\n\n30\n\n35\n\n40\n\n45\n\n50\n\n55\n\n60\n\n65\n\nFor example, the ICT transform requires scaling to make it orthogonal. Carrying out pre-scaled quantizing on ICT transformed block F*, gives the same quantization matrix Z as would be obtained by (unscaled) quantizing of a DCT transformed residual block. The same is true of some other integer image transforms and their discrete equivalents. How- ever, not every integer image transform requires scaling; for example the Walsh and Hadamard transforms are integer image transforms which do not require scaling.\n\na\n\nThe look\n\ntable\n\ncomprise a plurality of quantization\n\ncarried out by using the look up table.\n\nUS 8,019,804 B2\n\n8\n\n7\n\nPreferably the method selects the encoding mode which\n\nPreferably the iterative table-look up process is carried out\n\nin parallel for each coefficient f* of the transformed residual\n\nwill produce the least distortion of the block or the encoding\n\nblock. This further enhances the efficiency of the computation\n\nmode which has the lowest rate-distortion.\n\nPreferably the distortion or rate-distortion produced by the\n\nprocess.\n\nPreferably for each coefficient f* of said transformed\n\nsecond block mode is estimated or calculated according to the\n\nresidual block, said quantization Sub-Zone boundaries\n\nmethods described above.\n\nreferred to in the look up table, depend on the position of the\n\nA fourth aspect of the present invention provides a method\n\ncoefficient f* in the transformed residual block.\n\nfor calculating the sum of squared differences between an\n\nWhile it would be possible to find the inverse quantized\n\noriginal block S and a reconstructed block R of image or\n\nvalue i, directly from the look up table, without first finding\n\n10\n\nVideo data, the method comprising the steps of\n\nthe quantized value, it is preferred that the quantized value is\n\na) computing a predicted block P corresponding to the\n\nfound as well as described above. Once the quantized values\n\noriginal block S. using inter or intra frame prediction;\n\nhave been found the numbers of bits required to entropy\n\nb) calculating a residual block D from the original block S\n\nencode the quantized block Z can then easily be found. This\n\nand the predicted block P. said residual block D having a\n\ninformation gives an indication of the effectiveness of the\n\n15\n\nplurality of coefficients:\n\ncompression process and can be used to calculate the rate\n\nc) applying an image transform to the coefficients of the\n\ndistortion.\n\nresidual block D so as to obtain a transformed residual block\n\nThe method may include the step of entropy encoding the\n\nF, said transformed residual block having a plurality of coef\n\nblock Z. Any suitable type of entropy encoding may be used\n\nficients;\n\nor considered by the method, for example VLR encoding, run\n\nd) finding the coefficients of a first matrix F, said first\n\nlength coding and arithmetic coding.\n\nThe source block may correspond to a single macroblock,\n\nmatrix being an inverse quantized transform of said residual\n\ncontain one or more Sub-sections of a macroblock, or contain\n\nblock; and\n\ne) computing the sum of squared differences between said\n\nseveral macroblocks.\n\nThe integer image transform may be any type of integer\n\ntransformed residual block F and said first matrix F.\n\n25\n\nimage transform. In a preferred embodiment an integercosine\n\nThis method is similar to the first aspect of the present\n\ntransform (ICT) is used. Alternatively a Hadamard transform\n\ninvention, but less restrictive in that the image transform does\n\nnot need to be an integer image transform and therefore\n\nor a Walsh transform could be used. Other possibilities will be\n\npre-scaling may not be necessary. For example, the image\n\napparent to a person skilled in the art.\n\nA second aspect of the present invention provides a method\n\ntransform may be a Discrete Cosine Transform. The method\n\n30\n\nof calculating the distortion caused by encoding image or\n\nhas the advantage that the sum of squared differences is\n\nvideo data according to a first encoding mode, the method\n\ncalculated in the transformed residual domain and so the\n\ncomprising carrying out the first aspect of the invention,\n\ncomputations involved in reconstruction and the inverse\n\nwherein in step (a) the predicted block is computed according\n\ntransform are avoided.\n\nPreferably the method further comprises the step of quan\n\nto said first encoding mode and wherein the calculated dis\n\n35\n\ntortion is based on the Sum of squared differences computed\n\ntizing the coefficients of said transformed residual block F to\n\nobtain a quantized transformed residual block Z.\n\nin step (e). This information can be used to decide whether the\n\nPreferably step (d) is carried out with the aid of a look up\n\nencoding mode is suitable or not.\n\nA third aspect of the present invention provides a method of\n\ntable.\n\nA fifth aspect of the present invention provides a system for\n\nencoding video or image data, the method comprising defin\n\n40\n\ncalculating the sum of squared differences between an origi\n\ning an area in a frame of video or image data, calculating the\n\ndistortion which would be caused by encoding said area\n\nnal block S and a reconstructed block R of image or video\n\ndata; the system comprising:\n\naccording to a first encoding mode, said distortion being\n\na) a predicting module for predicting a predicted block P.\n\ncalculated by using the method of the second aspect of the\n\ncorresponding to an original block of data S, by using inter or\n\npresent invention, comparing said distortion with the distor\n\n45\n\nintra prediction;\n\ntion which would be caused by encoding said area according\n\nb) a residual block defining module for calculating a\n\nto a second encoding mode, selecting one of said first and\n\nsecond encoding modes on the basis of said comparison, and\n\nresidual block D, which is the difference between said pre\n\nencoding said data according to the selected encoding mode.\n\ndicted block P and said original block S;\n\nc) a transform module for performing an integer image\n\nIt is usually best to take account of not just the distortion\n\n50\n\nwhich would be caused by a particular encoding mode, but\n\ntransform on said residual block D to obtain a transformed\n\nresidual block F* having a plurality of co-efficients f*:\n\nalso the bit rate required to encode a block according to that\n\nd) an inverse quantization module for finding a plurality of\n\nmode. Therefore, it is preferred that the second aspect of the\n\ncoefficients i. the coefficients i. being defined by the equa\n\npresent invention calculates the rate-distortion and the third\n\naspect of the invention selects an encoding mode on the basis\n\ntion f*=Q(Q(?)), where Q is an operator which performs\n\n55\n\nquantizing and Q is the inverse of the Q operator;\n\nof a comparison of the rate distortions caused by the various\n\npossible encoding modes.\n\ne) a difference function computing module for computing\n\na sum of squared differences between f* and i.e.\n\nThe rate-distortion caused for a particular encoding mode\n\nThe operator Q may perform pre-scaled quantization.\n\ncan be calculated based on the sum of squared differences\n\nPreferably the inverse quantization module is arranged to\n\ncomputed in step (e) of the methods above and on the number\n\n60\n\noperate by referring to a look up table stored in a memory of\n\nof bits required to entropy encode the quantized transformed\n\nthe system.\n\nresidual block Z.\n\nA sixth aspect of the present invention provides a system\n\nPreferably the rate-distortion is calculated by the formula\n\nfor encoding video or image data, the system comprising:\n\nJSSD+WR, where J\n\nis a parameter representing the rate\n\n(f) a block defining module for defining a first area in the\n\ndistortion, SSD is the sum of squared differences computed in\n\n65\n\nstep (e), R is the number of bits required to entropy encode the\n\nVideo or image data, said area comprising one or more blocks\n\nblock and W is a Lagrange multiplier.\n\nof data;\n\nUS 8,019,804 B2\n\n8\n\n7\n\nPreferably the method selects the encoding mode which will produce the least distortion of the block or the encoding mode which has the lowest rate-distortion.\n\nPreferably the iterative table-look up process is carried out parallel for each coefficient f,,* of the transformed residual block. This further enhances the efficiency of the computation process.\n\nPreferably the distortion or rate-distortion produced by second block mode is estimated or calculated according to the methods described above.\n\nPreferably for each coefficient fr of said transformed residual block, said quantization sub-zone boundaries referred to in the look up table, depend on the position of the coefficient f,,* in the transformed residual block.\n\nA aspect present provides a for calculating the sum of squared differences between an original block S and a reconstructed block R of image or video data, the method comprising the steps of:\n\nWhile it would be possible to find the inverse quantized value f,,* directly from the look up table, without first finding the quantized value, it is preferred that the quantized value is found as well as described above. Once the quantized values have been found the numbers of bits required to entropy encode the quantized block Z can then easily be found. This information gives an indication of the effectiveness of the compression process and can be used to calculate the rate- distortion.\n\na) computing a predicted block P corresponding to the original block S, using inter or intra frame prediction;\n\nb) calculating a residual block D from the original block S and the predicted block P, said residual block D having a plurality of coefficients;\n\nc) applying an image transform to the coefficients of residual block D so as to obtain a transformed residual block said transformed residual block having a plurality of coef- ficients;\n\nThe method may include the step of entropy encoding the block Z. Any suitable type of entropy encoding may be used or considered by the method, for example VLR encoding, run length coding and arithmetic coding.\n\nd finding the coefficients of a first matrix P, said first matrix being an inverse quantized transform of said residual block; and\n\nThe source block may correspond to a single macroblock, contain one or more sub-sections of a macroblock, or contain several macroblocks.\n\ne) computing the sum of squared differences between transformed residual block F and said first matrix F.\n\nThe integer image transform may be any type of integer image transform. Ina preferred embodiment an integer cosine transform (ICT) is used. Alternatively a Hadamard transform ora Walsh transform could be used. Other possibilities will be apparent to a person skilled in the art.\n\nThis method is similar to the first aspect of the present invention, but less restrictive in that the image transform does not need to be an integer image transform and therefore pre-scaling may not be necessary. For example, the image transform may be a Discrete Cosine Transform. The method has the advantage that the sum of squared differences is calculated in the transformed residual domain and so the computations involved in reconstruction and the inverse transform are avoided.\n\nA second aspect of the present invention provides a method of calculating the distortion caused by encoding image or video data according to a first encoding mode, the method comprising carrying out the first aspect of the invention, wherein in step (a) the predicted block is computed according to said first encoding mode and wherein the calculated dis- tortion is based on the sum of squared differences computed. in step (e). This information can be used to decide whether the encoding mode is suitable or not.\n\nPreferably the method further comprises the step of quan- tizing the coefficients of said transformed residual block F obtain a quantized transformed residual block Z.\n\nPreferably step (d) is carried out with the aid of a look up table.\n\nA third aspect of the present invention provides a method of encoding video or image data, the method comprising defin- ing an area in a frame of video or image data, calculating the distortion which would be caused by encoding said area according to a first encoding mode, said distortion being calculated by using the method of the second aspect of the present invention, comparing said distortion with the distor- tion which would be caused by encoding said area according to a second encoding mode, selecting one of said first and. second encoding modes on the basis of said comparison, and encoding said data according to the selected encoding mode.\n\nA fifth aspect of the present invention provides a system calculating the sum of squared differences between an origi- nal block S and a reconstructed block R of image or video data; the system comprising:\n\na) a predicting module for predicting a predicted block corresponding to an original block of data S, by using inter intra prediction;\n\nb) a residual block defining module for calculating a residual block D, which is the difference between said pre- dicted block P and said original block S;\n\nIt is usually best to take account of not just the distortion which would be caused by a particular encoding mode, but also the bit rate required to encode a block according to that mode. Therefore, it is preferred that the second aspect of the present invention calculates the rate-distortion and the third aspect of the invention selects an encoding mode on the basis of a comparison of the rate distortions caused by the various possible encoding modes.\n\nc) a transform module for performing an integer image transform on said residual block D to obtain a transformed residual block F* having a plurality of co-efficients f,,*;\n\nd) an inverse quantization module for finding a plurality coefficients f,,* the coefficients f,,* being defined by the equa- tion f,*#=Q\" Qk, 7 ))s Where Q is an operator which performs quantizing and Q\"' is the inverse of the Q operator;\n\ne) a difference function computing module for computing a sum of squared differences between f,,* and f,,*.\n\nThe rate-distortion caused for a particular encoding mode can be calculated based on the sum of squared differences computed in step (e) of the methods above and on the number bits required to entropy encode the quantized transformed. residual block Z.\n\nThe operator Q may perform pre-scaled quantization. Preferably the inverse quantization module is arranged operate by referring to a look up table stored ina memory the system.\n\nA sixth aspect of the present invention provides a system encoding video or image data, the system comprising:\n\n-SSD+i-R, where Jp is a parameter representing the rate distortion, SSD is the sum of squared differences computed in step (e), R is the number of bits required to entropy encode the block and 4 is a Lagrange multiplier.\n\n(f) a block defining module for defining a first area in the video or image data, said area comprising one or more blocks of data;\n\nin\n\nof\n\nPreferably the rate-distortion is calculated by the formula\n\nJep\n\n20\n\n25\n\n30\n\n40\n\n45\n\nthe\n\nfourth\n\nof the\n\ninvention\n\nmethod\n\nthe\n\nF,\n\nsaid\n\nto\n\nfor\n\nP,\n\nor\n\nof\n\nto of\n\nfor\n\nUS 8,019,804 B2\n\n9\n\n10\n\n(g) a system according to the fifth aspect of the present\n\nFIG. 10 is a flow diagram showing a preferred method of\n\ncomputing the rate-distortion cost of encoding a block;\n\ninvention for calculating the sum of squared differences\n\nFIG. 11 is a flow diagram showing a preferred method of\n\nbetween f* and i, when a block of data in said area is\n\nencoded according to an encoding mode;\n\nencoding an area in a frame of video or image data;\n\nFIG. 12 is a block diagram showing a system for computing\n\n(h) a quantizing module for carrying out quantizing of the\n\nthe rate-distortion cost of encoding a block;\n\ncoefficients of the transformed residual block F* to obtain a\n\nFIG. 13 is a block diagram showing a system for encoding\n\nquantized transformed residual block Z (i) an entropy encod\n\ning module for entropy encoding the quantized transformed\n\nan area in a frame of video or image data;\n\nFIG. 14 is a table comparing the encoding time for a stan\n\nresidual block Z:\n\ndard JM encoder with an encoderusing a method according to\n\n() a rate-distortion calculating module for calculating the\n\n10\n\nan embodiment of the present invention;\n\nrate-distortion of an encoding mode, based on the number of\n\nFIG. 15 is a table comparing the encoding time for a stan\n\nbits required to entropy encode one or more blocks of data\n\naccording to said encoding mode and the sum of squared\n\ndard JM encoder with an encoderusing a method according to\n\nan embodiment of the present invention;\n\ndifferences between f* and i. for one or more blocks of data\n\nencoded according to said encoding mode;\n\nFIG. 16 is a table comparing the encoding time for a stan\n\n15\n\ndard JM encoder with an encoderusing a method according to\n\n(k) an encoding mode selection module for selecting an\n\nencoding mode for encoding the video or image data from a\n\nan embodiment of the present invention;\n\nplurality of possible encoding modes, said module being\n\nFIG. 17 is a table comparing the encoding time for a stan\n\ndard JM encoder with an encoderusing a method according to\n\narranged to select the encoding mode on the basis of a com\n\nparison of the respective rate-distortions of the possible\n\nan embodiment of the present invention;\n\nencoding modes.\n\nFIG. 18 is a table showing the average number of iterative\n\nThe quantizing module may be arranged for carrying out\n\nlookup operations for different videos:\n\npre-scaled quantization.\n\nFIG. 19 is a table comparing the rate distortion perfor\n\nThe quantizing module and inverse quantizing module\n\nmance of a standard JM encoder with an encoder using the\n\nmay be provided as a single module.\n\nmethod of the present invention;\n\n25\n\nFIG. 20 is a table comparing the rate distortion perfor\n\nIn both the above aspects of the invention, the modules\n\ncarry out similar functions to the method of the first aspect of\n\nmance of a standard JM encoder with an encoder using the\n\nmethod of the present invention;\n\nthe present invention. The modules may be hardware, soft\n\nFIG. 21 is a table comparing the rate distortion perfor\n\nware or firmware elements or combinations thereof. For\n\nexample, they may be circuits or parts of an integrated circuit,\n\nmance of a standard JM encoder with an encoder using the\n\n30\n\nor may be software elements in a programmable logic device\n\nmethod of the present invention;\n\nor in a program run on a computer.\n\nFIG. 22 is a table comparing the rate distortion perfor\n\nA seventh aspect of the invention provides a system com\n\nmance of a standard JM encoder with an encoder using the\n\nprising hardware, Software or firmware elements, arranged\n\nmethod of the present invention;\n\nFIG. 23 is a table showing the performance of the method\n\nfor carrying out a method according to any one of the first to\n\n35\n\nfourth aspects of the present invention.\n\nof the present invention when combined with other fast algo\n\nA eighth aspect of the present invention provides a pro\n\nrithms;\n\ngram, stored on a computer-readable medium, the program\n\nFIG. 24 is a table showing the performance of the method\n\nincluding instructions for causing an apparatus to carry out\n\nof the present invention when combined with other fast algo\n\nthe method of any one of the first to fourth aspects of the\n\nrithms;\n\n40\n\npresent invention.\n\nFIG.25 is a table showing the performance of the method\n\nof the present invention when combined with other fast algo\n\nBRIEF DESCRIPTION OF THE\n\nrithms; and\n\nFIG. 26 is a table showing the performance of the method\n\nACCOMPANYING DRAWINGS\n\nof the present invention when combined with other fast algo\n\n45\n\nFIG. 1 is a table showing the rate-distortion performance of\n\nrithms.\n\nRDO-based, SAD-based and SATD-based cost functions;\n\nFIG. 2 is a schematic diagram showing the ICT and quan\n\nDETAILED DESCRIPTION\n\ntization process used in the H.264/AVC coding standard;\n\nFIG. 3 is a table showing the values of the quantization\n\nI. Introduction\n\n50\n\nparameter A, for different position regions;\n\nThe present invention relates to a method and apparatus for\n\nFIG. 4 is a quantization diagram;\n\ndetermining the distortion caused by encoding a block of\n\nVideo or image data. This may be conveniently calculated\n\nFIG. 5 is a table showing some inverse quantized values\n\nand corresponding Sub-Zone boundaries for Some quanitiza\n\nbased on the squared sum or differences between a source\n\ntion points;\n\nblock and a reconstructed block of image or video data. The\n\n55\n\nFIG. 6 is a table showing inverse quantized values and\n\nrate-distortion of a particular inter or intra encoding mode\n\nquantization Sub-Zone boundaries for different positions\n\nmay also be calculated on the basis of the distortion and the\n\nregions:\n\nnumber of bits required to entropy encode a block which has\n\nbeen encoding according to the particular inter or intra encod\n\nFIG. 7 is a schematic diagram showing a method of calcu\n\ning mode. Preferred embodiments of the present invention\n\nlating the SSD between source and reconstructed blocks\n\n60\n\ndirectly:\n\nrelate to a method of encoding image or video data, including\n\nselecting an encoding mode based on the rate-distortion of\n\nFIG. 8 is a schematic diagram showing a method of calcu\n\nlating an SSD according to a preferred embodiment of the\n\nsaid mode.\n\npresent invention;\n\nThe present invention may be utilized with any image or\n\nFIG.9 shows a possible hardware implementation for car\n\nVideo encoding standard which uses inter or intra prediction.\n\n65\n\nrying out an iterative table-lookup process to find quantized\n\nHowever, it may be particularly suitable for use with the new\n\nand inverse quantized coefficients;\n\nH.264/AVC standard. Accordingly this standard now will be\n\nUS 8,019,804 B2\n\n10\n\n9\n\nFIG. 10 is a flow diagram showing a preferred method computing the rate-distortion cost of encoding a block;\n\n(g) a system according to 1 invention for calculating the between f,,* and i\" when a encoded according to an enco e fifth aspect of the present sum of squared differences lock of data in said area is ing mode;\n\nFIG. 11 is a flow diagram showing a preferred method of encoding an area in a frame of video or image data;\n\nFIG. 12 isa block diagram showing a system for computing the rate-distortion cost of encoding a block;\n\n(bh) a quantizing module for coefficients of the transformed quantized transformed residual! module for entropy encodi carrying out quantizing of the residual block F* to obtain a block Z (i) an entropy encod- ing the quantized transformed. residual block Z;\n\nFIG. 13 is a block diagram showing a system for encoding an area in a frame of video or image data;\n\nG. 14 is a table comparing the encoding time for a stan- JM encoder with an encoder using a method according mbodiment of the present invention;\n\n(j) a rate-distortion calculating module for calculating the rate-distortion of an encoding mode, based on the number of bits required to entropy encode one or more blocks of data according to said encoding mode and the sum of squared. differences between f,,* and \u4e86 y* for one or more blocks of data encoded according to said encoding mode;\n\nG. 15 is a table comparing the encoding time for a JM encoder with an encoder using a method according mbodiment of the present invention;\n\nG. 16 is a table comparing the encoding time for a stan- JM encoder with an encoder using a method according mbodiment of the present invention;\n\n(k) an encoding mode selection module for selecting an encoding mode for encoding the video or image data from a plurality of possible encoding modes, said module being arranged to select the encoding mode on the basis of a com- parison of the respective rate-distortions of the possible encoding modes.\n\nG. 17 is a table comparing the encoding time for a stan- JM encoder with an encoder using a method according odiment of the present invention,\n\nG. 18 is a table showing the average number of iterative erations for different videos;\n\nThe quantizing module may be arranged for carrying out pre-scaled quantization.\n\nG. 19 is a table comparing the rate distortion perfor- mance of a standard JM encoder with an encoder using method of the present invention;\n\nThe quantizing module and inverse quantizing module may be provided as a single module.\n\nIn both the above aspects of the invention, the modules carry out similar functions to the method of the first aspect of the present invention. The modules may be hardware, soft- ware or firmware elements or combinations thereof. For example, they may be circuits or parts of an integrated circuit, or may be software elements in a programmable logic device or in a program run on a computer.\n\nFIG. 20 is a table comparing the rate distortion perfor- mance of a standard JM encoder with an encoder using method of the present invention;\n\nFIG. 21 is a table comparing the rate distortion perfor- mance of a standard JM encoder with an encoder using the method of the present invention;\n\nFIG, 22 is a table comparing the rate distortion perfor- mance of a standard JM encoder with an encoder using method of the present invention;\n\nA seventh aspect of the invention provides a system com- prising hardware, software or firmware elements, arranged carrying out a method according to any one of the first to fourth aspects of the present invention.\n\nFIG. 23 is a table showing the performance of the method the present invention when combined with other fast algo-\n\nA eighth aspect of the present invention provides a pro- gram, stored on a computer-readable medium, the program including instructions for causing an apparatus to carry out the method of any one of the first to fourth aspects of the present invention.\n\nFIG. 24 is a table showing the performance of the method the present invention when combined with other fast algo- rithms;\n\nFIG. 25 is a table showing the performance of the method the present invention when combined with other fast algo- and\n\nBRIEF DESCRIPTION OF THE ACCOMPANYING DRAWINGS\n\nFIG. 26 is a table showing the performance of the method the present invention when combined with other fast algo- rithms.\n\nFIG. 1 is a table showing the rate-distortion performance of RDO-based, SAD-based and SATD-based cost functions;\n\nDETAILED DESCRIPTION\n\nFIG. 2 is a schematic diagram showing the ICT and quan- tization process used in the H.264/AVC coding standard;\n\nI. Introduction\n\nFIG. 3 is a table showing the values of the quantization parameter A,, for different position regions:\n\nThe present invention relates to a method and apparatus for determining the distortion caused by encoding a block of video or image data. This may be conveniently calculated based on the squared sum or differences between a source block and a reconstructed block of image or video data. The rate-distortion of a particular inter or intra encoding mode may also be calculated on the basis of the distortion and the number of bits required to entropy encode a block which has been encoding according to the particular inter or intra encod- ing mode. Preferred embodiments of the present invention relate to a method of encoding image or video data, including selecting an encoding mode based on the rate-distortion of said mode.\n\nFIG. 4 is a quantization diagram;\n\nFIG. 5 is a table showing some inverse quantized values and corresponding sub-zone boundaries for some quanitiza- tion points;\n\na showing quantized quantization sub-zone boundaries for different positions regions;\n\nFIG. 7 is a schematic diagram showing a method of calcu- lating the SSD between source and reconstructed blocks\n\nFIG. 8 is a schematic diagram showing a method of calcu- lating an SSD according to a preferred embodiment of the present invention;\n\nThe present invention may be utilized with any image video encoding standard which uses inter or intra prediction. However, it may be particularly suitable for use with the new H.264/AVC standard. Accordingly this standard now will\n\nFIG. 9 shows a possible hardware implementation for car- rying out an iterative table-lookup process to find quantized and inverse quantized coefficients;\n\ning\n\nfor\n\nFIG. 6 is\n\ntable\n\ninverse\n\nvalues and\n\ndirectly;\n\n10\n\n15\n\n20\n\n25\n\n30\n\n35\n\n40\n\n45\n\n50\n\n55\n\n60\n\n65\n\nof\n\nto\n\nstan-\n\nto\n\nto\n\nto\n\nthe\n\nthe\n\nthe\n\nof rithms;\n\nof\n\nof rithms;\n\nof\n\nor\n\nbe\n\nUS 8,019,804 B2\n\n11\n\n12\n\nInverse transform the inverse quantized block: D\u2013DCT\n\nbriefly discussed, although it is to be understood that the\n\npresent invention may be used with other encoding standards.\n\n(F)\n\nM\n\nCompute the reconstructed image block: C-D--P\n\nH.264/AVC is one of the newest image and video encoding\n\nCalculate the R-D cost: JSSD(S,C)+WR\n\nstandards. H.264/AVC greatly outperforms the previous\n\n2.1 Differential-Domain SSD\n\nMPEG-1/2/4 and H.261/263 standards in terms of both pic\n\n5\n\nMathematically, the original block S and reconstructed\n\nture quality and compression efficiency. In some implemen\n\nblock C can be expressed as:\n\ntations it may provide the same picture quality as DVD (or\n\nMPEG-2) video while only consuming about 25% of the\n\nS=D-P\n\nEQUATION (10)\n\nstorage space and its bit-rate is about half of that of the\n\n10\n\nMPEG-4 advanced simple profile. To achieve this superior\n\nC=D--P\n\nEQUATION (11)\n\ncoding performance, H.264/AVC adopts many advanced\n\nwhere the P is the predicted block, D is the residual block\n\ntechniques, such as directional spatial prediction for intra\n\nand D is the reconstructed residual block. Based on this\n\nrelationship, the spatial-domain SSD(S,C) can be expressed\n\nframe coding, variable and hierarchical block transform,\n\narithmetic entropy coding, multiple reference frame motion\n\nas differential-domain SSD(D.D):\n\n15\n\ncompensation, deblocking, etc. It also uses 7 different block\n\nsizes for motion-compensation in the inter mode, and 3 dif\n\n(D.D)\n\n(EQUATION12)\n\nferent block sizes with various spatial directional prediction\n\nThat means the spatial-domain SSD(S,C) is equivalent to\n\nmodes in the intra mode. The main critical process employed\n\ndifferential-domain SSD(D.D)). Based on this relationship,\n\nis the rate-distortion optimized mode decision technique\n\nwe can calculate the rate distortion cost in the differential\n\nwhich provides H.264/AVC much better coding performance\n\ndomain with JSSD(D.D)+w R, which avoids computing\n\nin terms of compression efficiency and visual quality. To\n\nthe reconstructed image block (C\u2013D+P).\n\nselect the best macroblock coding mode, an H.264/AVC\n\n2.2 Transform-Domain SSD\n\nencoder needs to compute the rate-distortion cost of all pos\n\nBefore we define the transform-domain SSD, we need to\n\nsible modes, which involves computation of integer trans\n\n25\n\nemphasize that the DCT matrix T,\n\nused in MPEG-like or\n\nform, quantization, variable length coding and pixel recon\n\nH.264/AVC video coding is a unitary matrix, which has the\n\nstruction processes. All of this processing explains the high\n\nproperty 16 of:\n\ncomputational complexity of rate-distortion cost calculation.\n\nHence, the cost function computation makes H.264/AVC\n\n|Xtr-|TecpATecr\"If\n\n(EQUATION 13)\n\nimpossible to realize in real-time applications without high\n\nwhere X is a square matrix. As the DCT matrix T is a\n\n30\n\ncomputing hardware.\n\nunitary matrix, it is also possible to perform an inverse trans\n\nAccordingly, a preferred embodiment of the present inven\n\nform. According to Equations 12 and 13, we can also express\n\ntion proposes a new fast sum of squared difference (FSSD)\n\nthe SSD in transform-domain as:\n\ncomputation algorithm which uses an iterative table-lookup\n\nquantization process. This may reduce the complexity of the\n\n35\n\nH.264 rate-distortion cost function calculation with good\n\nSSD(S,C) = |D-DIC\n\n(EQUATION 14)\n\ncoding efficiency as compared with conventional methods of\n\nrate-distortion optimization. The proposed algorithm can also\n\nbe combined with fast bit-rate estimation algorithm to further\n\nspeed up the computation with minimal performance degra\n\n40\n\ndation.\n\nIn section II we give the inventors analysis of the funda\n\nmental causes, which determine distortion. In Section III, a\n\n= SSDF, F)\n\nFSSD algorithm for calculating distortion is presented. Sec\n\ntion IV describes certain preferred methods and apparatus for\n\n45\n\nperforming the methods and Section V presents simulation\n\nwhere F and F are the transformed residual block and\n\nresults generated by a preferred embodiment of the invention.\n\ninverse quantized-transformed residual block. Equation 14\n\nII. Transform Domain Sum Squared Difference\n\nshows that the cause of the SSD is due to the quantization\n\nIn this section, we analyze the major cause of the SSD (sum\n\nerrors in the DCT transformed residual block F. The reason\n\nof squared differences) between the original block and recon\n\nbehind this is that the quantization is applied to the trans\n\n50\n\nstructed block in the rate-distortion cost function. One\n\nformed coefficients of F. That is why SAD(SP) and SATD\n\nmethod of calculating the rate-distortion cost (J) for video\n\n(S.P) cannot well predict the SSD(S,C). Both SAD(S.P) and\n\nand image encoding schemes, such as MPEG-like or H.264/\n\nSATD(SP) are determined by the original block and pre\n\nAVC schemes, can be summarized as:\n\ndicted block, without considering the influence of quantiza\n\nCompute the predicted block using inter or intra frame\n\ntion which the inventors have determined is the real reason of\n\n55\n\nprediction: P\n\nthe SSD. For example, if the quantization step\u201318 and all the\n\nUsing the original block S and the predicted block P to\n\ntransform coefficients are multiples of 18, then the quantized\n\ncompute the residual (difference) block: D-S-P\n\ncoefficients would be the same as the inverse quantized coef\n\nDiscrete Cosine Transform (DCT) the residual block:\n\nficients without error. By way of example only if:\n\n60\n\nF-DCT(D)=TocrDTcz\n\n(EQUATION 9)\n\nwhere T is the DCT matrix which is a unitary matrix\n\n180 72 54 18\n\nand Toc, is the transported matrix of Tcz.\n\n72 36 18 18\n\nF =\n\nand the quanization step is 18, then\n\nQuantization of the transformed residual block: Z=Q(F)\n\n36 18 18 18\n\nEntropy code of the Z to find the number of bits to encode\n\n65\n\n18 18 18 O\n\nthe block: R-VLC(Z)\n\nInverse quantization: F=Q(Z)\n\nUS 8,019,804 B2\n\n12\n\n11\n\nInverse transform the inverse quantized block:\n\nbriefly discussed, although it is to be understood that the present invention may be used with other encoding standards.\n\nCompute the reconstructed image block: C=D+P\n\nH.264/AVC is one of the newest image and video encoding standards. H.264/AVC greatly outperforms the previous MPEG-1/2/4 and H.261/263 standards in terms of both pic- ture quality and compression efficiency. In some implemen- tations it may provide the same picture quality as DVD (or MPEG-2) video while only consuming about 25% of the storage space and its bit-rate is about half of that of the MPEG-4 advanced simple profile. To achieve this superior coding performance, H.264/AVC adopts many advanced techniques, such as directional spatial prediction for intra frame coding, variable and hierarchical block transform, arithmetic entropy coding, multiple reference frame motion compensation, deblocking, etc. It also uses 7 different block sizes for motion-compensation in the inter mode, and 3 dif- ferent block sizes with various spatial directional prediction modes in the intra mode. The main critical process employed is the rate-distortion optimized mode decision technique which provides H.264/AVC much better coding performance in terms of compression efficiency and visual quality. To select the best macroblock coding mode, an H.264/AVC encoder needs to compute the rate-distortion cost of all pos- sible modes, which involves computation of integer trans- form, quantization, variable length coding and pixel recon- struction processes. All of this processing explains the high computational complexity of rate-distortion cost calculation. Hence, the cost function computation makes H.264/AVC\n\nCalculate the R-D cost: Jp=SSD(S,C)+ \u548c \u6709\n\n2.1 Differential-Domain SSD\n\nMathematically, the original block S and reconstructed block C can be expressed as:\n\nS=D+P\n\nEQUATION (10)\n\nC=D4P\n\nEQUATION (11)\n\nwhere the P is the predicted block, D is the residual block D is the reconstructed residual block. Based on relationship, the spatial-domain SSD(S,C) can be expressed differential-domain SSD(D,D):\n\nSSD(S,C)=|S-C]|p\u00b0=|D+P-D-P|p?=||D-D]|p?=SSD (DD) (EQUATION\n\nThat means the spatial-domain SSD(S,C) is equivalent differential-domain SSD(D,D)). Based on this relationship, can calculate the rate distortion cost in the differential- domain with Jpn=SSD(D,D)+)-R, which avoids computing reconstructed image block (C=D+P).\n\n2.2 Transform-Domain SSD\n\nBefore we define the transform-domain SSD, we need emphasize that the DCT matrix Tp; used in MPEG-like H.264/AVC video coding is a unitary matrix, which has property [16] of:\n\n(We ZbexXTpcr\u201clle\n\n(EQUATION 13)\n\nwhere X is a square matrix. As the DCT matrix Tyo is unitary matrix, it is also possible to perform an inverse trans- form. According to Equations 12 and 13, we can also express SSD in transform-domain as:\n\nAccordingly, a preferred embodiment of the present inven- tion proposes a new fast sum of squared difference (FSSD) computation algorithm which uses an iterative table-lookup quantization process. This may reduce the complexity of the H.264 rate-distortion cost function calculation with good coding efficiency as compared with conventional methods of rate-distortion optimization. The proposed algorithm can also be combined with fast bit-rate estimation algorithm to further speed up the computation with minimal performance degra- dation.\n\nSSDS, C) = p- All. (EQUATION 14) = |!focr(D- ol Tr \u70ba \u4e86 \u4e86 2 = ||\" crPTher - Tocr Ther].\n\nIn section II we give the inventors\u2019 analysis of the funda- mental causes, which determine distortion. In Section III, a FSSD algorithm for calculating distortion is presented. Sec- tion IV describes certain preferred methods and apparatus for performing the methods and Section V presents simulation results generated by a preferred embodiment of the invention. IL. Transform Domain Sum Squared Difference\n\ninverse quantized-transformed residual block. Equation 14 shows that the cause of the SSD is due to the quantization errors in the DCT transformed residual block F. The reason behind this is that the quantization is applied to the trans- formed coefficients of F. That is why SAD(S,P) and SATD (S,P) cannot well predict the SSD(S,C). Both SAD(S,P) and SATD(S,P) are determined by the original block and pre- dicted block, without considering the influence of quantiza- tion which the inventors have determined is the real reason of the SSD. For example, ifthe quantization step=18 and all the transform coefficients are multiples of 18, then the quantize: coefficients would be the same as the inverse quantized coef-\n\nIn this section, we analyze the major cause of the SSD (sum of squared differences) between the original block and recon- structed block in the rate-distortion cost function. One method of calculating the rate-distortion cost (Jap) for video and image encoding schemes, such as MPEG-like or H.264/ AVC schemes, can be summarized as:\n\nCompute the predicted block using inter or intra frame prediction: P\n\nUsing the original block S and the predicted block P to compute the residual (difference) block: D=S-P\n\nDiscrete Cosine Transform (DCT) the residual block:\n\n(BQUATION 9)\n\nF=DCTD)=TpcPT pcr\"\n\n180 72 36 18 72 54 18 36 18 18 18 18 18 18 18 0 and the quanization step is 18, then\n\nwhere Tp\u00a27 is the DCT matrix which is a unitary matrix T,.7\u2019 is the transported matrix of Ther.\n\nQuantization of the transformed residual block: Z-Q(F)\n\nEntropy code of the Z to find the number of bits to encode block: R-VLC(Z)\n\nInverse quantization: F=Q-!(Z)\n\nimpossible to realize in real-time applications without high computing hardware.\n\nand\n\nthe\n\n20\n\n40\n\n55\n\n60\n\n_ ()\n\nD=pcT\n\nand\n\nthis\n\nas\n\n12)\n\nto\n\nwe\n\nthe\n\nto\n\nor\n\nthe\n\na\n\nthe\n\nwhere F and F are the transformed residual block and\n\nficients without error. By way of example only if:\n\nUS 8,019,804 B2\n\n14\n\nwhich may also be called a quantized transformed residual\n\ncontinued\n\nblock. In step 140 inverse quantization is carried out to de\n\n180 72 54 18\n\nquantize the coefficients of the quantized transformed\n\nr\n\n72 36 18 18\n\nresidual block Z. The inverse quantizing produces an inverse\n\nF =\n\nquantized transform of the residual block F. The block F is\n\n36 18 18 18\n\n18 18 18 O\n\nthen inverse scale transformed in step 150 and inverse ICT\n\ntransformed in step 160. Steps 150 and 160 have the com\n\nbined effect of performing a transform similar to an inverse\n\nThis demonstrates that even if most of the coefficients of F\n\nDCT and the result is the reconstructed residual block Din the\n\nare large, SSD(S,C) can be zero if ||F-FI\u2019\u20130. The example 1\n\n0 spatial domain.\n\nindicates that the elements of D or F are not directly related to\n\nThe relationship between the DCT and the ICT can be\n\nthe SSD(S,C) which is determined by the quantization error.\n\nexpressed as:\n\nThat is why the rate-distortion performance of SAD-based\n\nand SATD-based cost functions, which do not take account of\n\nthe quantization error, is Sub-optimum.\n\nwhere, C, is called ICT core matrices, Q is called scal\n\n15\n\nOn the other hand, the transform-domain SSD(FF) can be\n\ning factors and F* is the ICT transformed block. The symbol\n\nused to reduce the number of computations required for the\n\ns indicates the operator that each element of CDC, (or F*)\n\nrate distortion cost calculation; i.e. the rate distortion can be\n\nis multiplied by the scaling factor in the corresponding posi\n\ncalculated using the equation J-SSD(FF)+-R, which\n\ntion. The forward core and Scale transform matrices are\n\nallows the inverse DCT transform and image block recon\n\ndefined as:\n\nstruction to be avoided. Another advantage of using this trans\n\nform-domain SSD(F,F) is that, ignoring the clipping function\n\napplied in the practical computation, there should not be any\n\n2 ab\n\n2 ab\n\nperformance degradation in terms of both coding efficiency\n\na\n\na\n\nand reconstructed image distortion as SSD(FF) and SSD(S,\n\n1\n\n1\n\n1\n\n1\n\nab b ab b?\n\n25\n\nC) are theoretically equivalent.\n\n2 1 - 1 - 1\n\n4\n\np.\n\n4\n\nCF =\n\n, 9 forw =\n\nIn H.264/AVC, however, a DCT is not used as the image\n\n1 - 1 - 1\n\n1\n\nab\n\nab\n\ntransform. Rather an integer image transform, the Integer\n\n--\n\n--\n\n1 -2 2 - 1\n\n2\n\n2\n\nCosine Transform (ICT), is used instead to reduce the com\n\nab b ab b?\n\nputational complexity. This is discussed below.\n\n2,\n\n4,\n\n2\n\n4.\n\n30\n\nIII. Fast Sum of the Squared Difference Computation\n\n3.1 Review of Integer Cosine Transform in H.264\n\nwhere a=/2, b-v2/5. The purpose of carrying out an ICT\n\nThe practical implementation of the DCT and quantization\n\nrather than a DCT is to reduce the computation complexity,\n\nprocess in H.264/AVC is a little bit different from Equation 9\n\nbecause the core transform of the ICT can be realized by shift\n\nand its architecture is shown in FIG. 2. The DCT is imple\n\n35\n\nand addition operations only without multiplication. The\n\nmented by ICT with scaling factors for complexity reduction\n\nquantization process of Z=Q(F) for the transformed residual\n\n(See A. Hallapuro, M. Karczewicz, \"Low Complexity Trans\n\nblock F can be expressed as a rounding operation on each\n\nform and Quantization', in Joint Video Team (JVT) of ISO/\n\ncoefficient of F:\n\nIEC MPEG and ITU-T VCEG, Doc. JVT-B038 and JVT\n\nB039, January 2002., which is incorporated herein by\n\n40\n\nz-round.(f, A)\n\n(EQUATION 16)\n\nreference).\n\nwhere Z, and f, are coefficients of the quantized transform\n\nIn simple terms the ICT is an integer transform which is\n\nand unquantized transform blocks of Zand F, respectively. A\n\ncomputationally easier to calculate than a DCT because\n\nis the quantization step size, which is determined by the QP\n\nunlike a DCT, all of its coefficients are integers. Therefore\n\nfactor (the quantized step size). On the other hand, the inverse\n\nmany division and/or floating point operations are avoided\n\n45\n\nquantization process of F=Q(Z) can be expressed as an\n\nand the ICT may be realized by shift and addition operations\n\noperation on each coefficients of Z:\n\nonly. Prior to quantization, Scaling factors are applied to make\n\nthe ICT equivalent to a DCT.\n\nfi, Z'A\n\n(EQUATION 17)\n\nThe present invention is not limited to cosine transforms\n\nand other types of transform can be used instead, for example\n\nwhere f, are coefficients of the inverse quantized trans\n\n50\n\nan image a Hadamard Transform or a Walsh Transform. It is\n\nformed block F. In the inverse transform, the core matrix and\n\npreferred to use an integer image transform. Some integer\n\nscale matrix is not the same as those in forward transform.\n\nimage transforms such as an ICT, will need Scaling factors in\n\norder to make it an orthogonal transform, as being orthogonal\n\n(EQUATION 18)\n\nis necessary requirement for most video and image encoding\n\n55\n\nwhere C, and Q are defined as:\n\nstandards.\n\nFIG. 2 shows how the ICT and scaling factors are imple\n\nmented in practice to give a transform equivalent to a DCT. It\n\n1\n\n1\n\n1\n\n1\n\na\u2019 ab a' ab\n\ncan be seen that in step 110 the residual block D is ICT\n\n1\n\n1 f2 - 1 f2 - 1\n\nab b? ab b?\n\ntransformed to give an integer image transformed residual\n\n60\n\nCb = 1\n\n1\n\n1\n\n1\n\n, Qback = a? ab at ab\n\nblock F. The transformed residual block F is then scaled in\n\nstep 120 to give a scaled integer image transformed residual\n\n1 ? 2 - 1\n\n1\n\n1 f2\n\nab b ab b\n\nblock F. The combination of the operations 110 and 120 is\n\nequivalent to a Discrete Cosine Transform (DCT) and the\n\nblock F is equivalent to the block that would be obtained by\n\nIn the H.264/AVC, scale transform and quantization are\n\n65\n\ncombined together to further reduce computational complex\n\nperforming a DCT on the residual block D. The block F, is\n\nthen quantized in step 130 to give a quantization matrix Z.\n\nUS 8,019,804 B2\n\n14\n\n13\n\nwhich may also be called a quantized transformed residual block. In step 140 inverse quantization is carried out to de- quantize the coefficients of the quantized transformed residual block Z. The inverse quantizing produces an inverse quantized transform of the residual block F. The block F is then inverse scale transformed in step 150 and inverse ICT transformed in step 160. Steps 150 and 160 have the com- bined effect of performing a transform similar to an inverse DCT and the result is the reconstructed residual block D in the spatial domain.\n\n-continued\n\n180 72 54 18 \u5168 72 36 18 18 Fe 36 18 18 18 18 18 18 0\n\nThis demonstrates that even if most of the coefficients of F are large, SSD(S,C) can be zero if |F-F\\|,2=0. The example indicates that the elements of D or F are not directly related to the SSD(S,C) which is determined by the quantization error. That is why the rate-distortion performance of SAD-based and SATD-based cost functions, which do not take account of the quantization error, is sub-optimum.\n\nThe relationship between the DCT and the ICT can be expressed as:\n\nF=DCT(D)-CDCF@) Ojon ICID) Qj =F BLATION 15)\n\nwhere, Cris called ICT core matrices, Qy,,,, is called scal- ing factors and F* is the ICT transformed block. The symbol \u5168 indicates the operatorthat eachelement of CDCZ (OrEY) is multiplied by the scaling factor in the corresponding posi- tion. The forward core and scale transform matrices are defined as:\n\nOn the other hand, the transform-domain SSD(FF) can be used to reduce the number of computations required for the rate distortion cost calculation; i.e. the rate distortion can be calculated using the equation Jg,-SSD(FP)44:R, which allows the inverse DCT transform and image block recon- struction to be avoided, Another advantage of using this trans- form-domain SSD(F, F) is that, ignoring the clipping function applied in the practical computation, there should not be any performance degradation in terms of both coding efficiency and reconstructed image distortion as SSD(F.F) and SSD(S, C) are theoretically equivalent.\n\nab ab eT? > 1 1 1 1 ab B ab B 21-14 TPT CT pn PEEL ae, abt 1 -2 2 -1 \u548c \u4eba \u4eba ab \u8aaa \u6240 24\u00b020 4\n\nIn H.264/AVC, however, a DCT is not used as the image transform. Rather an integer image transform, the Integer Cosine Transform (ICT), is used instead to reduce the com- putational complexity. This is discussed below. Ill. Fast Sum of the Squared Difference Computation 3.1 Review of Integer Cosine Transform in H.264\n\nwhere a=, b=V2/5. The purpose of carrying out an ICT rather than a DCT is to reduce the computation complexity, because the core transform of the ICT can be realized by shift and addition operations only without multiplication. The quantization process of Z\u2014Q(F) for the transformed residual block F can be expressed as a rounding operation on each coefficient of F:\n\nThe practical implementation of the DCT and quantization process in H.264/AVC is a little bit different from Equation 9 and its architecture is shown in FIG. 2. The DCT is imple- mented by ICT with scaling factors for complexity reduction (See A. Hallapuro, M. Karezewicz, \u201cLow Complexity Trans- form and Quantization\u201d, in Joint Video Team (JVT) of ISO/ IEC MPEG and ITU-T VCEG, Doc. JVT-B038 and JVT- B039, January 2002., which is incorporated herein by reference).\n\n(EQUATION 16)\n\nwhere z,, and f,, are coefficients of the quantized transform and unquantized transform blocks of Z and F, respectively. A is the quantization step size, which is determined by the QP factor (the quantized step size). On the other hand, the inverse quantization process of F=Q-'(Z) can be expressed as an operation on each coefficients of Z:\n\nIn simple terms the ICT is an integer transform which is computationally easier to calculate than a DCT because unlike a DCT, all of its coefficients are integers. Therefore many division and/or floating point operations are avoided and the ICT may be realized by shift and addition operations only. Prior to quantization, scaling factors are applied to make the ICT equivalent to a DCT.\n\n(EQUATION 17)\n\nThe present invention is not limited to cosine transforms and other types of transform can be used instead, for example an image a Hadamard Transform or a Walsh Transform. It is preferred to use an integer image transform. Some integer image transforms such as an ICT, will need scaling factors in order to make it an orthogonal transform, as being orthogonal is necessary requirement for most video and image encoding standards.\n\nwhere \u540d are coefficients of the inverse quantized trans- formed block F. In the inverse transform, the core matrix matrix is not the same as those in forward transform.\n\n\u8aaa Ge ouacs\n\n(EQUATION 18)\n\nwhere C, and Q,,,.,, are defined as:\n\nFIG. 2 shows how the ICT and scaling factors are imple- mented in practice to give a transform equivalent to a DCT. It can be seen that in step 110 the residual block D is ICT transformed to give an integer image transformed residual block F*. The transformed residual block F* is then scaled in step 120 to give a scaled integer image transformed residual block F. The combination of the operations 110 and 120 is equivalent to a Discrete Cosine Transform (DCT) and the block F is equivalent to the block that would be obtained by performing a DCT on the residual block D. The block F, is then quantized in step 130 to give a quantization matrix Z, 60 65\n\n1 1 1 1 @ ab @ ab ce 1 1/2 -1/2 -1 ab \u53ca ab \u53ca 2 ee 1/2 -1 1 -1/2 ab Bab B\n\nIn the H.264/AVC, scale transform and quantization are combined together to further reduce computational complex- ity.\n\n10\n\n15\n\n20\n\n25\n\n30\n\n35\n\n40\n\n45\n\n50\n\n55\n\nzy-round(f;/A)\n\nhy\n\nand\n\nscale\n\nUS 8,019,804 B2\n\n15\n\n16\n\nrequired to perform the quantization and inverse quantization\n\nprocesses of f*. They are normally performed in the follow\n\nJill)\n\n(EQUATION 19)\n\ning operations:\n\nwhere q, are the scale coefficients of the Q matrix and\n\n(EQUATION 23)\n\nf* are coefficients of the ICT transformed block F* using the\n\n3 = Q(f) = round:\n\nICT core matrix.\n\n3.2 Fast Sum of Squared Difference Algorithm\n\nf = Q (Q(f;) = 3; A\n\n(EQUATION 24)\n\nAs illustrated in the last section, the SSD(S,C) could be\n\n10\n\ndetermined in transform domain using SSD(F, F)=|F-FI,\n\nSo it is unnecessary to calculate the distortion using the recon\n\nIn order to make use of the advantage given by Equation 22,\n\nstructed block C. The computation of DCT-transformed F is,\n\nwe propose to use an iterative table-lookup method for sim\n\nhowever, much more complex than the ICT-transformed F*\n\nplifying the quantization process off; and computing of the\n\nas the scale transform contains fractional coefficients. Thus, if\n\nSSD using i,. Thus, the computationally intensive division\n\n15\n\nwe can build a bridge between SSD(F,F) and F*, then we can\n\nand multiplication operations can be avoided.\n\nskip the calculation of F and F. In order to achieve this\n\n3.3 Iterative Table-Lookup Quantization Process\n\npurpose, we rearrange the quantization and inverse quantiza\n\nBasically, the quantization process is to find the nearest\n\ntion processes of F in terms of pre-scaled quantization and\n\nquantization point as shown in FIG. 4. In FIG. 4, axis 200\n\ninverse quantization of F*. The coefficients of F can be\n\nrepresents the value of f* and has quantization points 210,\n\nexpressed as:\n\n220, 230, 240 and 250. Quantization points 210, 220, 230,\n\n240 and 250 have quantized values of -2, -1, 0, 1 and 2\n\nrespectively and inverse quantized values of-2A-A.0, A,\n\ni = Arounds\n\n(EQUATION 20)\n\nand 2 A, respectively. Each quantization point is associated\n\nwith a respective quantization sub-zone and all values of f*\n\n25\n\nfi qi\n\nin that Sub-Zone are given the quantized value and inverse\n\n= A round A\n\nquantized value corresponding to that quantization point.\n\nSo, for example, quantization Sub-Zone 212 is bounded by\n\nArounds')\n\nf\n\nboundaries 213 and 214 (also referred to as boundary points).\n\nValues off, between those boundaries are given a quantized\n\n30\n\n= -round f\n\nal\n\nvalue Z, of -2 and an inverse quantized value of -2 A. f*\n\n4ii\n\nAfg) '\n\nshown in the diagram is in a sub-zone having boundaries 238\n\nand 242 and a quantization point 240. Therefore f* is given\n\n= Aji roun\n\na quantized value of 1 and an inverse quantized value of A.\n\nii\n\nExample quantization Sub Zone boundaries and corre\n\n35\n\nsponding inverse quantized values are shown in FIG. 5. It will\n\nbe appreciated that the value of the inverse quantized value\n\ndepends on the (i,j) position of the coefficient as A, varies\n\nwhere A, A/q, A, is a quantization parameter and repre\n\ndepending on the ij position. This is a consequence of the\n\nsents the scaled quantization step for ICT-transformed coef\n\nscaling factors which vary for different regions in the block\n\nficients f* of F*. The quantization steps are not equal for all\n\n40\n\nand are defined by the integer image transform and encoding\n\ncoefficients of F* and the values of A, depend on both A and\n\nstandard used. The values of A, for different position regions\n\nthe coefficients q, of Q. The values of A, differ for differ\n\nfor an ICT transform is given in FIG. 3.\n\nent positions as shown in FIG. 3. In addition, the inverse\n\nThe relation between A quantization sub-zones and the\n\nquantization of the ICT-transformed coefficients is defined\n\ninverse quantized values for an ICT transform is shown in the\n\n45\n\naS\n\ntable of FIG. 6. Regarding the parameters listed in the table,\n\nQstep is the quantization step, the \u201cposition regions' refer to\n\n(EQUATION 21)\n\nthe position of the coefficient f* in terms of i and j and are\n\nBased on this new relationship, we can reformulate the\n\ngiven in FIG. 3, q, is the scaling factor and A, is the quanti\n\nSSD(F,F) in terms of ICT transformed coefficients f* as:\n\nzation parameter which has been defined above. The look up\n\n50\n\ntable may contain some or all of the information shown in\n\nFIG. 6. It may also contain the quantized values Z, corre\n\nSSDF, F)=|F - FI\n\n(EQUATION 22)\n\nsponding to each quantization Sub Zone.\n\nA preferred embodiment of the invention proposes an itera\n\ntive table-lookup quantization process to find f* correspond\n\n55\n\ning Sub-Zone by searching from the Zero point towards posi\n\ntive axis direction by comparing the absolute value off, with\n\nboundary points held in the look up table until f* is smaller\n\nthan a certain boundary point.\n\nAfter this iterative look up process, we can obtain the\n\n60\n\nquantization value Z, which is equal to the number of com\n\nparison times. Besides, we can also get f* by multiplying Z,\n\nby a quantization parameter stored in the look up table or by\n\nThis equation indicates that SSD(F, F) can be directly\n\nreferring directly to the look up table if the inverse quantized\n\nrelated to the quantization error of f*. Therefore, we can\n\nvalues are stored in the look table.\n\n65\n\nTo use this approach, the boundary points of the quantiza\n\ncalculate SSD(F,F) more easily as we do not need to obtain f,\n\nand f. However, division and multiplication operations are\n\ntion Sub-Zones and the inverse quantized values or the quan\n\nUS 8,019,804 B2\n\n15\n\n16\n\nrequired to perform the quantization and inverse quantization processes of f,,*. They are normally performed in the follow- operations:\n\n(Ee i } (EQUATION 19) = QL ff) = round\n\nwhere q,, are the scale coefficients of the Q,,,,, matrix and are coefficients of the ICT transformed block F* using the core matrix.\n\naye ofj)= ound 2) (EQUATION 23)\n\n3.2 Fast Sum of Squared Difference Algorithm\n\n(EQUATION 24)\n\nAs illustrated in the last section, the SSD(S,C) could determined in transform domain using SSD(E, *)=||F-F'l,2, so it is unnecessary to calculate the distortion using the recon- structed block C. The computation of DCT-transformed F is, however, much more complex than the ICT-transformed F* as the scale transform contains fractional coefficients. Thus, if we can build a bridge between SSD(F, F) and F*, then we can skip the calculation of F and F. In order to achieve this purpose, we rearrange the quantization and inverse quantiza- tion processes of F in terms of pre-scaled quantization and inverse quantization of F*. The coefficients of F can be oO\n\nInorder to make use of the advantage given by Equation 22, we propose to use an iterative table-lookup method for sim- plifying the quantization process of f,,*; and computing of the SSD using i, * Thus, the computationally intensive division and multiplication operations can be avoided.\n\n3.3 Iterative Table-Lookup Quantization Process\n\nBasically, the quantization process is to find the nearest quantization point as shown in FIG. 4. In FIG. 4, axis 200 represents the value of fr* and has quantization points 210, 220, 230, 240 and 250. Quantization points 210, 220, 230, 240 and 250 have quantized values of -2, -1, 0, 1 and 2 respectively and inverse quantized values of -2 Ar -Ap0Ar and 2 A,, respectively. Each quantization point is associated with a respective quantization sub-zone and all values of f,,* in that sub-zone are given the quantized value and inverse quantized value corresponding to that quantization point.\n\nism vet (EQUATION 20) A \u51fa = \u4e8c -roun \u201c4 i ajay) \u00a9 Si wa = fia\n\nSo, for example, quantization sub-zone 212 is bounded by boundaries 213 and 214 (also referred to as boundary points). Values of f,,* between those boundaries are given a quantized value z,, of -2 and an inverse quantized value of -2 Ap f,* shown in the diagram is in a sub-zone having boundaries 238 and 242 and a quantization point 240. Therefore f,,* is given a quantized value of 1 and an inverse quantized value of A,,.\n\nExample quantization sub zone boundaries and corre- sponding inverse quantized values are shown in FIG. 5. It will be appreciated that the value of the inverse quantized value depends on the (ij) position of the coefficient as Ay varies depending on the ij position. This is a consequence of the scaling factors which vary for different regions in the block and are defined by the integer image transform and encoding standard used. The values of A,, for different position regions for an ICT transform is given in FIG. 3.\n\nwhere A,-A/q,,A,, is a quantization parameter and repre- sents the scaled quantization step for ICT-transformed coef- ficients f,,* of F*. The quantization steps are not equal for all coefficients of F* and the values of A,, depend on both A and the coefficients qy of Qy,,.,. The values of A,, differ for differ- ent positions as shown in FIG. 3. In addition, the inverse quantization of the ICT-transformed coefficients is defined as:\n\nThe relation between A quantization sub-zones and the inverse quantized values for an ICT transform is shown in the table of FIG. 6. Regarding the parameters listed in the table, Qstep is the quantization step, the \u201cposition regions\u201d refer to the position of the coefficient f,,* in terms of i and j and are given in FIG. 3, q,, is the scaling factor and A,, is the quanti- zation parameter which has been defined above. The look up table may contain some or all of the information shown in FIG. 6. It may also contain the quantized values z,, corre- sponding to each quantization sub zone.\n\nFy QOUy))-Ay round f\"/Ay) (BQUATION 21)\n\nBased on this new relationship, we can reformulate the F)i in terms of ICT transformed coefficients f,,* as:\n\nSSD(F, FP) =||F- flr (EQUATION 22) = UG 4 -\u2014 2 OU) ais = alti - fil\n\nApreferred embodiment of the invention proposes an itera- tive table-lookup quantization process to find f,,* correspond- ing sub-zone by searching from the zero point towards posi- tive axis direction by comparing the absolute value of f,,* with boundary points held in the look up table until {;,* is smaller than a certain boundary point.\n\nAfter this iterative look up process, we can obtain the quantization value zz which is equal to the number of com- parison times. Besides, we can also get f,,* by multiplying zy by a quantization parameter stored in the look up table or by referring directly to the look up table if the inverse quantized values are stored in the look table.\n\nThis equation indicates that SSD(F, F) can be directly related to the quantization error of f,,*. Therefore, we can calculate SSD(F, F) more easily as we do not need to obtain fy and fy. However, division and multiplication operations are\n\nTo use this approach, the boundary points of the quantiza- tion sub-zones and the inverse quantized values or the quan-\n\nf,* ICT\n\nexpressed as:\n\nSSD@,\n\n10\n\n5\n\n\u5fc6 0\n\n30\n\n40\n\n45\n\n55\n\n2 0\n\n65\n\ning\n\n\u70ba = 911(Q(0) = ay Ay\n\nUS 8,019,804 B2\n\n17\n\n18\n\ntization parameter are generated in advance during an initial\n\nblock D to obtain an integer transformed residual block F*\n\npart of the encoding process and their values are stored in\n\nhaving coefficients f*. In step 440 a look up table is referred\n\nto iteratively to find the corresponding quantized coefficients\n\nmemory for table lookup. Thus, no extra computation is\n\nrequired in this quantization process for determining the\n\nZ, which make up the quantized transformed residual block Z.\n\nquantization points and quantization Sub-Zones.\n\nThe values f* which make up a matrix F* are then found\n\nThe overall rate-distortion cost computation process using\n\neither directly from the look up table or by multiplying the\n\ncorresponding quantized coefficients Z., by quantization point\n\nthis proposed iterative table-lookup quantization for FSSD\n\ncomputation can be Summarized as:\n\nvalues found in the look up table.\n\nStep 1: Compute the predicted block using inter or intra\n\nThus compared to the conventional method, many proces\n\nframe prediction: P\n\nsor intensive processes are avoided. Furthermore, as men\n\n10\n\ntioned above, use of a look up table enables the quantization\n\nStep 2: Compute the residual (difference) block: D=S-P\n\nto be carried out by a simple comparison operation. This is\n\nStep 3: ICT transform the residual block: F*=ICT\n\n(D)-CDC,\n\ncomputationally efficient as addition, Subtraction, division or\n\nmultiplication operations may be avoided or at least mini\n\nStep 4: Set SSD=0 and for i=0 to N-1 and j=0 to N-1\n\ndetermine the quantized coefficients Z, and the SSD by the\n\nmized. Some of the benefit is obtained by carrying out the\n\n15\n\nfollowing iterative table-lookup quantization process:\n\nSSD in the residual transform domain (which avoids the\n\nStep I: Set k=0 and if f*<0 then set sign=-1, otherwise\n\ninverse transform and reconstruction operations), however it\n\nsign=1.\n\nis thought the most significant reduction in processing time\n\nStep II: If |f|2(k+0.5)Athen k-k+1 and goto Step II;\n\ncomes from use of the look up table to carry out the quanti\n\nStep III: Set Z. signk and f-signk'A:\n\nZation and inverse quantization operations (the quantization\n\nStep IV: SSD-SSD+q.(1,-i,): If not the last f * coef\n\noperation is a pre-scaled quantization operation if the trans\n\nficient, goto Step I.\n\nform is an ICT).\n\nFIG.9 shows a possible hardware structure for carrying out\n\nStep 5: Entropy code of the Z to find the number of bits to\n\nthe iterative table-lookup quantization process. Data 500\n\nencode the block: R=VLC(Z)\n\nfrom an integer image transformed residual block F is input\n\nStep 6: Calculate the R-D cost: JSSD+WR\n\n25\n\nto the hardware system 510. The data comprises all the coef\n\nIn the above procedures, we assume that the boundaries of\n\nquantization sub-zones (having values (k+0.5)A, for k=0, 1,\n\nficients f* of the block. As each coefficient does not depend\n\n2,...), the scaling factor or its square qf and the quantization\n\non the others, the quantization process can be performed in\n\nparameter A, for each position region of (i,j) are loaded in the\n\nparallel. In the other words, all the inverse quantized coeffi\n\ncients i. are found simultaneously. Accordingly, each coef\n\nencoder and stored in a look up table during the initial pro\n\n30\n\nficient f* is input to a respective circuit 520,530,540 and the\n\ncess. The above method has the advantage that arithmetic\n\noperations are avoided and only a simple comparison opera\n\npre-scaled quantization and inverse quantization is carried\n\ntion between |f|and boundary points is required. Therefore,\n\nout in parallel for each coefficient. FIG.9 only shows in detail\n\nthe circuits for calculating fo, f* and f*, but it is to be\n\nit is very suitable for hardware implementation.\n\nAn overview of the conventional SSD(S,C) calculation is\n\nunderstood there will be a similar circuit for each coefficient.\n\n35\n\nAt the beginning of the encoding process, quantization\n\nshown in FIG. 7 and contrasted with a preferred embodiment\n\ntable generator 550 generates a quantization table. The quan\n\nof the invention in FIG. 8.\n\ntization table contains the boundary points of quantization\n\nIn the conventional method in FIG.7, a predicted block Pis\n\nSub Zones for each (i,j) position region and the quantization\n\npredicted from the source block S and the difference between\n\npoint which each Sub Zone is associated with. For example,\n\nthe two is found in step 310 to produce a residual block D. The\n\n40\n\nboundary points A/2a, 3A2a and 5A/2a and corresponding\n\nresidual block D is integer image transformed in step 320 (e.g.\n\nquantization points 0, 1, 2 respectively\u2014see position region I\n\nby an ICT) to produce the transformed residual block F*. The\n\nin FIG. 6). The quantization point may be stored separately\n\nblock F is scaled in step 330 and then quantized in a separate\n\nfrom the boundary point or alternatively inferred from the\n\nstep 340 to produce a quantized transformed residual block Z.\n\nposition in which the boundary point is stored in the table. The\n\nThe block Zis entropy encoded in step 350 and the number of\n\n45\n\nbits required to entropy encode the block is noted. In step 360\n\ndata from the quantization table is stored in the look up table\n\nthe block Z is inverse quantized to obtain inverse quantized\n\n522,552,562 of each circuit 520,530,540. Alternatively each\n\nlook up table may only contain the data relevant for that\n\nresidual block F. The block F is then inverse scale trans\n\ncircuit's position region (so circuit 520 for calculating f*\n\nformed in step 370 and inverse integer image transformed in\n\nstep 380 (by the reverse of the operation of step 320). This\n\nhas the data for position region I, the look up table of circuit\n\n50\n\n530 for calculating for has data for position region III and\n\nprovides a reconstructed residual block D. The original block\n\ncircuit 540 for calculating f* has the data for position region\n\nis then reconstructed from the residual block using inter or\n\nintra prediction to arrive at reconstructed block C in step 340.\n\nII\u2014see FIG. 3). It may also be possible for each circuit to\n\nrefer to a single central look up table.\n\nThe SSD between the source block S and the reconstructed\n\nThe particular position regions, quantization points and\n\nblock C is finally calculated in step 395. This gives a measure\n\n55\n\nof the distortion caused by encoding the block.\n\nboundaries in the tables of FIGS. 3 and 6 are examples only\n\nIn the preferred embodiment of the present invention\n\nand are determined by the ICT transform and the H.264/AVC\n\nshown in FIG. 8 the separate Scaling, quantizing, inverse\n\nstandard. If another image or video encoding standard is used,\n\nquantizing, inverse Scaling, inverse integer image transform\n\nthen the tables will have different position regions, quantiza\n\ntion points and boundaries which can easily be determined by\n\nand block reconstruction steps 330, 340, 360, 370, 380 and\n\n60\n\nconsulting the encoding standard in question.\n\n390 are eliminated and replaced with an iterative lookup table\n\nprocess 440.\n\nOperation of the circuit 520 will now be discussed in detail,\n\nThus, in step 400 a predicted block P is predicted by intra\n\nit being understood that the other circuits 530, 540 etc operate\n\nor inter prediction from the original source block S. In step\n\nin the same way.\n\n410 the predicted block P is subtracted from the source block\n\nThe RAM 522 contains the look up table referred to above\n\n65\n\nand a pointer that points to the current boundary point. The\n\nS to obtain a residual block D. In step 420 an integer image\n\ncurrent boundary point is loaded in a register 523 and com\n\ntransform, for example an ICT, is performed on the residual\n\nUS 8,019,804 B2\n\n18\n\n17\n\nblock D to obtain an integer transformed residual block F* having coefficients f,,*. In step 440 a look up table is referred to iteratively to find the corresponding quantized coefficients z,, which make up the quantized transformed residual block Z. The values f,,* which make up a matrix F* are then found either directly from the look up table or by multiplying the corresponding quantized coefficients z,, by quantization point values found in the look up table.\n\ntization parameter are generated in advance during an initial part of the encoding process and their values are stored in memory for table lookup. Thus, no extra computation is required in this quantization process for determining the quantization points and quantization sub-zones.\n\nThe overall rate-distortion cost computation process using this proposed iterative table-lookup quantization for FSSD computation can be summarized as:\n\nStep 1: Compute the predicted block using inter or intra frame prediction: P\n\nmany proces- sor intensive processes are avoided. Furthermore, as men- tioned above, use of a look up table enables the quantization to be carried out by a simple comparison operation. This is computationally efficient as addition, subtraction, division or multiplication operations may be avoided or at least mini- mized. Some of the benefit is obtained by carrying out the SSD in the residual transform domain (which avoids the inverse transform and reconstruction operations), however it is thought the most significant reduction in processing time comes from use of the look up table to carry out the quanti- zation and inverse quantization operations (the quantization operation is a pre-scaled quantization operation if the trans- form is\n\nStep 2: Compute the residual (difference) block: D=S-P Step 3: ICT transform the residual block: F*=ICT (D)=CDCA\n\nStep 4: Set SSD=0 and for i=0 to N-1 and j=0 to N-1 determine the quantized coefficients z,, and the SSD by the following iterative table-lookup quantization process:\n\nStep I: Set k=0 and if f,*<0 then set sign=-1, otherwise\n\nStep IT: If If,*|=(k+0.5)A,,, then k=k+1 and goto Step II; Step III: Set 2,\u2014signk and \u6240 \u4e00 Sign k-A,;\n\nStep IV: SSD= \u201cssD+q,; PE \u5168 ys Ifnot the last f* coef- ficient, goto Step I.\n\nStep 5: Entropy code of the Z to find the number of bits encode the block: R=VLC(Z)\n\nFIG. 9 shows a possible hardware structure for carrying out the iterative table-lookup quantization process. Data 500 from an integer image transformed residual block F* is input to the hardware system 510. The data comprises all the coef- ficients f,,* of the block. As each coefficient does not depend on the others, the quantization process can be performed in parallel. In the other words, all the inverse quantized coeffi- cients f,,* are found simultaneously. Accordingly, each coef- ficient f,,* is input to a respective circuit 520, 530, 540 and the pre-scaled quantization and inverse quantization is carried out in parallel for each coefficient. FIG. 9 only shows in detail the circuits for calculating f,,*, f,,* and f,,*, but it is to be understood there will be a similar circuit for each coefficient.\n\nStep 6: Calculate the R-D cost: Jpn=SSD+A-R\n\nIn the above procedures, we assume that the boundaries of quantization sub-zones (having values +0. 5)A,, for k-0, 1, . .), the scaling factor or its square q,; ? and the quantization te A, for each position region of (i,j) are loaded in the encoder and stored in a look up table during the initial pro- cess. The above method has the advantage that arithmetic operations are avoided and only a simple comparison opera- tion between If,,*| and boundary points is required. Therefore, it is very suitable for hardware implementation.\n\nAn overview of the conventional SSD(S,C) calculation shown in FIG. 7 and contrasted with a preferred embodiment the invention in FIG. 8.\n\ntable generator 550 generates a quantization table. The quan- tization table contains the boundary points of quantization sub zones for each (i,j) position region and the quantization point which each sub zone is associated with. For example, boundary points A/2a2, 3A/2a and 5A/2a? and corresponding quantization points 0, 1, 2 respectively\u2014see position region I in FIG. 6). The quantization point may be stored separately from the boundary point or alternatively inferred from the position in which the boundary point is stored in the table. The data from the quantization table is stored in the look up table 522,552, 562 ofeach circuit 520, 530, 540. Alternatively each look up table may only contain the data relevant for that circuit\u2019s position region (so circuit 520 for calculating {,,* has the data for position region I, the look up table of circuit 530 for calculating \u4eba has data for position region II] and circuit 540 for calculating f,,* has the data for position region II\u2014see FIG. 3). It may also be possible for each circuit to\n\npredicted from the source block S and the difference between the two is found in step 310 to produce a residual block D. The residual block D is integer image transformed in step 320 (e.g. by an ICT) to produce the transformed residual block F*. The block F* is scaled in step 330 and then quantized in a separate step 340 to produce a quantized transformed residual block Z. The block Z is entropy encoded in step 350 and the number of bits required to entropy encode the block is noted. In step 360 the block Z is inverse quantized to obtain inverse quantized residual block F. The block F is then inverse scale trans- ormed in step 370 and inverse integer image transformed in step 380 (by the reverse of the operation of step 320). This provides a reconstructed residual block DB. The original block is then reconstructed from the residual block using inter or intra prediction to arrive at reconstructed block C in step 340. The SSD between the source block S and the reconstructed block C is finally calculated in step 395. This gives a measure\n\nThe particular position regions, quantization points and boundaries in the tables of FIGS. 3 and 6 are examples only and are determined by the ICT transform and the H.264/AVC standard. If another image or video encoding standard is used, then the tables will have different position regions, quantiza- tion points and boundaries which can easily be determined by consulting the encoding standard in question.\n\nIn the preferred embodiment of the present invention shown in FIG. 8 the separate scaling, quantizing, inverse quantizing, inverse scaling, inverse integer image transform and block reconstruction steps 330, 340, 360, 370, 380 and 390 are eliminated and replaced with an iterative lookup table process 440.\n\nOperation of the circuit 520 will now be discussed in detail, being understood that the other circuits 530, 540 etc operate the same way.\n\nThus, in step 400 a predicted block P is predicted by intra inter prediction from the original source block S. In step 410 the predicted block P is subtracted from the source block to obtain a residual block D. In step 420 an integer image transform, for example an ICT, is performed on the residual\n\nThe RAM 522 contains the look up table referred to above a pointer that points to the current boundary point. The current boundary point is loaded in a register 523 and com-\n\nsign=1.\n\nto\n\nis\n\nof In the conventional method in FIG. 7, a predicted\n\nblock P is\n\nof the distortion caused by encoding the block.\n\nor\n\nS\n\n10\n\n20\n\n25\n\n35\n\n40\n\n45\n\n50\n\n55\n\nThus compared to the conventional method,\n\nan ICT).\n\nAt the beginning of the encoding process, quantization\n\nrefer to a single central look up table.\n\nit\n\nin\n\nand\n\nUS 8,019,804 B2\n\n19\n\n20\n\npared with If, after the sign of f* is abstracted by a sign\n\ning to a first encoding mode is computed. For each block in\n\nselector device 521. If the comparator 524 judges that |f| is\n\nthe area the rate distortion (R-D cost) is determined by using\n\nlarger than the current boundary point, then a Loop signal\n\nthe method of FIG. 10. The rate distortion of each of the\n\nblocks in the area is then added together to determine the rate\n\nsignal is issued which tells counter 523 to increment its count\n\ndistortion caused by encoding the area according to the first\n\nby one and causes the pointer in RAM 522 to shift forward\n\nencoding mode. In step 730 the same procedure is carried out\n\nand point to the next boundary point in the look up table. This\n\nas in step 720, except for a second encoding mode. In step 740\n\nprocess continues until the comparator 524 finds f*I that is\n\nthe respective rate distortions caused by encoding the area\n\nsmaller than the current boundary point. The comparator 524\n\naccording to the first and second encoding modes are com\n\nthen generates an Out signal which resets the pointer to the\n\npared. The encoding mode giving the lowest rate distortion is\n\n10\n\ninitial position and causes the counter 525 to output its accu\n\nthus found. In step 750 the area is encoded according to the\n\nmulated count (which is the quantized value Z). The Out\n\nselected encoding mode (or alternatively the data which has\n\nsignal also causes the register to output the current inverse\n\nalready been encoded according to that mode in step 650 of\n\nquantized value, f, (which may be stored in the lookup table\n\nFIG. 10 is output).\n\nor calculated at that moment, for example by multiplying the\n\nWhile FIG. 11 shows just two different encoding modes, it\n\n15\n\nquantized value by a quantization parameter stored in the look\n\nis possible for there to be three or more different encoding\n\nup table). From the structure in FIG.9, it can be seen that the\n\nmodes. In that case the rate distortion of each encoding mode\n\nproposed table-lookup quantization process is very Suitable\n\nmay be computed separately, compared and the mode with\n\nfor hardware implementation, since it does not require com\n\nthe lowest rate distortion selected.\n\nplicated operation modules and can execute in parallel mode.\n\nAs mentioned above the area for which the rate-distortion\n\nA preferred embodiment of the present invention will now\n\nis calculated may contain one or more blocks. The area may\n\nbe described with reference to FIG. 10. In Step 600 a source\n\ncontain a different number of blocks according to the encod\n\nblock S of video or image data is defined or received by\n\ning mode used (i.e. the encoding mode determines the num\n\ncomputing or image processing apparatus. In step 610 a pre\n\nber and size of the blocks which the area is split into). How\n\ndicted block P is predicted from the source block using inter\n\never, as the rate-distortion for the entire area is computed (e.g.\n\n25\n\nor intra predicting according to a particular encoding mode\n\nas the sum of the rate-distortion cost of all the blocks in the\n\n(for example, one of the encoding modes allowed by the\n\narea), the rate-distortion of different encoding modes may be\n\nH.264/AVC standard). In step 620 a residual block is com\n\ncompared even if the different encoding modes produce dif\n\nputed by subtracting the predicted block P from the source\n\nferent numbers and sizes of blocks.\n\nblock S. In step 630 an integer image transform (e.g. an ICT)\n\nAlternatively the area may just contain one block (e.g. one\n\n30\n\nis performed on the residual block D to obtain a transformed\n\nmacroblock) in all the encoding modes. In that case the rate\n\nresidual block F* having a plurality of co-efficient f*. In step\n\ndistortion of the area according to a particular encoding mode\n\n640 a look up table is referred to iteratively to carry out\n\nis simply the rate-distortion of that block.\n\npre-scaled quantizing of the block F* to obtain the coefficient\n\nFIG. 12 shows a system for computing the Sum of squared\n\nZ of the quantized transformed residual block. In step 650 the\n\ndifferences between a source and reconstructed block of\n\n35\n\nquantized transformed residual block is entropy encoded and\n\nimage or video data that is encoded by inter or intra predic\n\nin step 660 the number of bits required to entropy encode the\n\ntion. It comprises a plurality of modules which may be soft\n\nblock are noted. In step 670 the inverse quantized coefficients\n\nware or hardware components.\n\nare found by referring to the look up table. Preferably the\n\nSource block defining module 900 receives or defines a\n\ninverse quantized coefficients will be stored in the look up\n\nsource block S in the image or video data. Prediction module\n\n40\n\ntable, however if they are not, then they could be found by\n\n910 predicts a predicted block P based on the source block S\n\nmultiplying the coefficient Z., by a corresponding pre-scaled\n\nusing inter or intra prediction according to one of a plurality\n\nquantization step A, held in the look up table.\n\nof possible block encoding modes. Residual block defining\n\nIn step 680 the sum of squared differences (SSD) between\n\nmodule 920 computes a residual block D by subtracting the\n\nf* and f* is computed. Preferably it is a weighted SSD, for\n\npredicted block P from the source block S. The residual block\n\n45\n\nexample given by the equation\n\ncomputed by the module 920 is then output to an integer\n\nimage transform module 930 which performs an integer\n\nimage transform (e.g. an ICT) on the residual block D in order\n\nto obtain a transformed residual block F*. A quantizating and\n\ninverse quantizing module 940 iteratively refers to a look up\n\n50\n\ntable in order to perform pre-scaled quantizing of the coeffi\n\ncients of the transformed residual block F* which produces a\n\nplurality of quantized coefficients Z. The module 940 also\n\nSteps 640, 650, 660 and 670 may be carried out in parallel for\n\ninverse quantizes the coefficients Z, to obtain inverse quan\n\neach of the ij values. In step 690 the rate distortion is calcu\n\nlated from the SSD, which was computed in step 680, and the\n\ntized coefficients f*. The coefficients Z, are output to an\n\n55\n\nentropy encoding module 950 which entropy encodes the\n\nnumber of bits required to entropy encode the block, which\n\nwas noted in step 660. The rate distortion may for example be\n\ncoefficients. Meanwhile a difference computing module 960\n\ncomputes a weighted sum of squared differences (SSD)\n\ncalculated according to the equation J. SSD+WR; where\n\nbetween f* and f*, using the coefficients f* of the block F*\n\nJ\n\nis the rate distortion, SSD is the Sum of squared differ\n\ncomputed by module 930 and the coefficients f* computed\n\nences calculated in step 680, w is a Lagrange multiplier and R\n\n60\n\nis the number of bits required to entropy encode the block.\n\nby module 940. A rate-distortion calculating module then\n\nFIG. 11 illustrates a method of encoding video or image\n\ncalculates the rate distortion on the basis of the sum of\n\ndata according to a preferred embodiment of the present\n\nsquared differences output by modules 960 and the number of\n\nbits which module 950 required to entropy encode the coef\n\ninvention. In step 700 an area is defined in the video or image\n\ndata. In step 710 one or more blocks (e.g. macroblocks) are\n\nficients Z.\n\n65\n\nFIG. 13 shows a preferred embodiment of a system for\n\ndefined in the area of image or video data. In step 720 the rate\n\nencoding video or image data. The system has a plurality of\n\ndistortion caused by encoding the one or more blocks accord\n\nUS 8,019,804 B2\n\n19\n\n20\n\ning to a first encoding mode is computed. For each block in the area the rate distortion (R-D cost) is determined by using the method of FIG. 10. The rate distortion of each of the blocks in the area is then added together to determine the rate distortion caused by encoding the area according to the first encoding mode. In step 730 the same procedure is carried out as in step 720, except fora second encoding mode. In step 740 the respective rate distortions caused by encoding the area according to the first and second encoding modes are com- pared. The encoding mode giving the lowest rate distortion is thus found. In step 750 the area is encoded according to the selected encoding mode (or alternatively the data which has already been encoded according to that mode in step 650 of FIG. 10 is output).\n\npared [| sign f by a sign selector device 521. If the comparator 524 judges that | \u4e86 zl is larger than the current boundary point, then a \u2018Loop\u2019 signal signal is issued which tells counter 523 to increment its count by one and causes the pointer in RAM 522 to shift forward and point to the next boundary point in the look up table. This process continues until the comparator 524 finds If,,*| that is smaller than the current boundary point. The comparator 524 then generates an \u2018Out\u2019 signal which resets the pointer to the initial position and causes the counter 525 to output its accu- mulated count (which is the quantized value z,,). The \u2018Out\u2019 signal also causes the register to output the current inverse quantized value, f, yy (which may be stored in the look up table or calculated at that moment, for example by multiplying the quantized value by a quantization parameter stored in the look up table). From the structure in FIG. 9, it can be seen that the proposed table-lookup quantization process is very suitable for hardware implementation, since it does not require com- plicated operation modules and can execute in parallel mode.\n\nWhile FIG. 11 shows just two different encoding modes, possible for there to be three or more different encoding modes. In that case the rate distortion of each encoding mode may be computed separately, compared and the mode with lowest rate distortion selected.\n\nAs mentioned above the area for which the rate-distortion is calculated may contain one or more blocks. The area may contain a different number of blocks according to the encod- ing mode used (i.e. the encoding mode determines the num- ber and size of the blocks which the area is split into). How- ever, as the rate-distortion for the entire area is computed (e.g. as the sum of the rate-distortion cost of all the blocks in the area), the rate-distortion of different encoding modes may be compared even if the different encoding modes produce dif- ferent numbers and sizes of blocks.\n\nbe described with reference to FIG. 10. In Step 600 a source block S of video or image data is defined or received by computing or image processing apparatus. In step 610 a pre- dicted block P is predicted from the source block using inter or intra predicting according to a particular encoding mode (for example, one of the encoding modes allowed by the H.264/AVC standard). In step 620 a residual block is com- puted by subtracting the predicted block P from the source block S. In step 630 an integer image transform (e.g. an ICT) is performed on the residual block D to obtain a transformed. residual block F* having a plurality of co-efficient f,,*. In step 640 a look up table is referred to iteratively to carry out pre-scaled quantizing of the block F* to obtain the coefficient z,, of the quantized transformed residual block. In step 650 the quantized transformed residual block is entropy encoded and in step 660 the number of bits required to entropy encode the block are noted. In step 670 the inverse quantized coefficients are found by referring to the look up table. Preferably the inverse quantized coefficients will be stored in the look up table, however if they are not, then they could be found by multiplying the coefficient zy by a corresponding pre-scaled\n\nAlternatively the area may just contain one block (e.g. one macroblock) in all the encoding modes. In that case the rate- distortion of the area according to a particular encoding mode simply the rate-distortion of that block.\n\nFIG. 12 shows a system for computing the sum of squared differences between a source and reconstructed block image or video data that is encoded by inter or intra predic- tion. It comprises a plurality of modules which may be soft- ware or hardware components.\n\nsource block S in the image or video data. Prediction module 910 predicts a predicted block P based on the source block S using inter or intra prediction according to one of a plurality of possible block encoding modes. Residual block defining module 920 computes a residual block D by subtracting the predicted block P from the source block S. The residual block computed by the module 920 is then output to an integer image transform module 930 which performs an integer image transform (e.g. an ICT) on the residual block D in order to obtain a transformed residual block F*. A quantizating and inverse quantizing module 940 iteratively refers to a look up table in order to perform pre-scaled quantizing of the coeffi- cients of the transformed residual block F* which produces a plurality of quantized coefficients z,,. The module 940 also inverse quantizes the coefficients z,, to obtain inverse quan- tized coefficients f,,*. The coefficients zz are output to an entropy encoding module 950 which entropy encodes the coefficients. Meanwhile a difference computing module 960 computes a weighted sum of squared differences (SSD) between f,,* and f,,*, using the coefficients f,,* of the block F* computed by module 930 and the coefficients f,* computed by module 940. A rate-distortion calculating module then calculates the rate distortion on the basis of the sum of squared differences output by modules 960 and the number of bits which module 950 required to entropy encode the coef-\n\nIn step 680 the sum of squared differences (SSD) between f,* and {,,* is computed. Preferably it is a weighted SSD, for example given by the equation\n\nss= > Yr ailag FP.\n\nSteps 640, 650, 660 and 670 may be carried out in parallel for each of the i,j values. In step 690 the rate distortion is calcu- lated from the SSD, which was computed in step 680, and the number of bits required to entropy encode the block, which was noted in step 660. The rate distortion may for example be calculated according to the equation Jp,-SSD+A-R; where Jap is the rate distortion, SSD is the sum of squared differ- ences calculated in step 680, A is a Lagrange multiplier and R is the number of bits required to entropy encode the block.\n\nFIG. 11 illustrates a method of encoding video or image data according to a preferred embodiment of the present invention. In step 700 an area is defined in the video or image data. In step 710 one or more blocks (e.g. macroblocks) are defined in the area of image or video data. In step 720 the rate distortion caused by encoding the one or more blocks accord-\n\nFIG. 13 shows a preferred embodiment of a system for encoding video or image data. The system has a plurality of\n\nwith\n\nafter the\n\nof\n\nis abstracted\n\nA preferred embodiment of the present invention will now\n\nquantization step A,, held in the look up table.\n\n10\n\n15\n\n20\n\n25\n\n30\n\n35\n\n40\n\n45\n\n50\n\n55\n\n60\n\n65\n\nit\n\nis\n\nthe\n\nis\n\nof\n\nSource block defining module 900 receives or defines a\n\nficients z,,.\n\nUS 8,019,804 B2\n\n21\n\n22\n\nexpect that in a hardware implementation the reduction due to\n\nmodules, which may be software or hardware components.\n\nthe look-up table process will be even greater.\n\nAn area defining module 1000 defines an area in the video or\n\nThe reduction in encoding time for the low motion\n\nimage data which is to be encoded. A block defining module\n\nsequence (Akiyo) was more than that for the high motion\n\n1010 defines one or more blocks in said area in accordance\n\nsequence (Stefan). A possible reason for this is that since the\n\nwith a first encoding mode. A rate distortion calculating mod\n\nprediction accuracy of low motion sequence is better than that\n\nule 1020 computes the rate distortion for each of the blocks\n\nof high motion sequence, its residue is Smaller and so less\n\nencoded according to said first mode. The rate distortion\n\ntime is spent on the iterative table-lookup operation. FIG. 18\n\ncalculating module 1020 may have a structure such as that\n\nshows the average number of table-lookup operations for\n\nshown in FIG. 12. The rate distortion module 1020 Sums the\n\ndifferent video sequences in various QP values. The result\n\n10\n\nrate distortion of the one or more blocks to find the total rate\n\nindicates that the iterative table-lookup quantization process\n\ndistortion for the area when it is encoded according to the first\n\ndoes not cost much time so that our proposed quantization\n\nmode. The block defining and rate distortion modules 1010\n\nmethod is practical. In addition, these experimental results\n\nand 1020 then carry out the same process but for a second\n\nare obtained using integer rounding precision in the compu\n\nencoding mode. The rate distortion of the area when encoded\n\ntation of the equation 22 in the JM encoder. The rate-distor\n\n15\n\nby the second encoding mode is thus found. The process may\n\ntion performance comparison of the conventional SSD and\n\nbe repeated for one or more further encoding modes. A com\n\nproposed FSSD in terms of PSNR and bit-rate are shown in\n\nparison module 1030 compares the rate distortion cost for\n\ntables or FIGS. 19 to 22. These results show that the errors due\n\neach of the encoding modes (as computed by the module\n\nto the clipping functions in computing the transform-domain\n\n1020) and selects one of the encoding modes to be used for\n\nSSD were small and the rate-distortion performance differ\n\nencoding the data. For example the encoding mode with the\n\nences between these two methods was less than 0.1% and\n\n0.03 dB in terms of bit-rate and PSNR, respectively.\n\nlowest rate distortion cost may be chosen. Output module\n\nSince the proposed FSSD computing method improved the\n\n1040 then outputs the encoded data which represents the area\n\ncomputational efficiency of distortion measure with very\n\nas encoded by the selected encoding mode. The output mod\n\nlittle loss of rate-distortion performance, it could be com\n\nule 1040 may carry out the encoding itself, or alternatively\n\n25\n\nbined with different types of H.264/AVC fast algorithms,\n\nread from a memory encoded data which was stored earlier in\n\nSuch as fast inter/intra mode selection algorithms and rate\n\nthe process (for example the output of entropy encoding\n\nestimation algorithm. Here, FSSD algorithm is combined\n\nmodule 950 of FIG. 12).\n\nwith a conventional rate estimation method to reduce more\n\nSimulation Results\n\ncomputation complexity. The way to estimate the number of\n\n30\n\nAn embodiment of the invention using the proposed itera\n\nbits is:\n\ntive table-lookup quantization processing and FSSD compu\n\ntation was tested using the first 100 frames from four video\n\nTotal bits=C. total zeros+B total coeff-SAD\n\n(EQUATION 26)\n\nsequences (Akiyo. Foreman, Stefan and Container) all in\n\nwhere total Zeros and total coeff present the number of\n\nQCIF format 176x144. They present different kinds of video\n\nZeros and the number of non-zero coefficients respectively\n\n35\n\nsequences respectively: Akiyo (slow motion). Foreman and\n\nafter quantization. SAD is the Sum of absolute value of quan\n\nContainer (medium motion), Stefan (high motion). The\n\ntized transform coefficients. The experiences values of C. and\n\nexperiments were carried out in the JVT JM 8.3 encoder. Test\n\nB are 1 and 3. Experimental results are listed in the tables in\n\nparameters are listed below:\n\nFIGS. 23 to 26. From the results, the reduction of encoding\n\nTest condition:\n\ntime was about 30% to 40% with ignorable performance\n\n40\n\nRate Distortion Optimization is enabled;\n\ndegradation. This indicates that the proposed FSSD algorithm\n\nCAVLC is enabled;\n\ncan be easily combined with other fast H.264/AVC algo\n\nGOP structure is IPPPIPPP;\n\nrithms and achieves a good tradeoff between computation\n\nQP values are 28, 32, 36 and 40.\n\ncomplexity and rate-distortion performance.\n\nThe percentage of reduced time of calculating distortion is\n\nWhat is claimed is:\n\n45\n\ndefined as:\n\n1. A method for calculating the Sum of squared differences\n\nbetween an original block S and a reconstructed block R of\n\nimage or video data, the method comprising the steps of:\n\nTorgTOT - TproposedTOT\n\n(EQUATION 25)\n\n(a) computing with a processor a predicted block P corre\n\nx 100%\n\nTorg TOT\n\nsponding to the original block S, using inter or intra\n\n50\n\nframe prediction,\n\nwhere Tor is the computation time of the original\n\n(b) calculating with the processor a residual block D from\n\nthe original block S and the predicted block P. said\n\nH.264/AVC encoder using conventional spatial-domain SSD\n\n(S,C) algorithm; while Troy is the computation time\n\nresidual block D having a plurality of coefficients,\n\n(c) applying with the processor an integer image transform\n\nof a H.264/AVC encoder using the proposed FSSD compu\n\n55\n\ntation method according to an embodiment of the present\n\nto the coefficients of the residual block D so as to obtain\n\na transformed residual block F, said transformed\n\ninvention.\n\nresidual block having a plurality of coefficients f*\n\nThe tables in FIGS. 14-17 show the comparison of com\n\n(d) finding with the processora plurality of coefficients f*\n\nputation complexity between original JM encoder and an\n\nencoder using the proposed FSSD computation method.\n\nthe coefficients f, being defined by the equation\n\n60\n\nf-Q' (Q(?)), where Q is an operator which per\n\nFrom the simulation results, we can conclude that the pro\n\nforms quantizing and Q is the inverse of the Q opera\n\nposed FSSD computation method may reduce the encoding\n\ntime by around 10% to 15% in different QP values. We\n\ntor,\n\nwherein finding the coefficients comprises iteratively\n\nestimate that about 4% to 7% reduction is achieved by the\n\niterative table-lookup quantization process and 5% to 7%\n\ncomparing the absolute value of each coefficient f,\n\n65\n\nreduction is achieved by avoiding the inverse transform and\n\nof the transformed residual block to boundaries quan\n\npixel reconstruction. This was in a software simulation we\n\ntization Sub-Zones in a look up table, said boundaries\n\nUS 8,019,804 B2\n\n22\n\n21\n\nexpect that in a hardware implementation the reduction due look-up table process will be even greater.\n\nmodules, which may be software or hardware components. An area defining module 1000 defines an area in the video or image data which is to be encoded. A block defining module 1010 defines one or more blocks in said area in accordance with a first encoding mode. A rate distortion calculating mod- ule 1020 computes the rate distortion for each of the blocks encoded according to said first mode. The rate distortion calculating module 1020 may have a structure such as that shown in FIG. 12. The rate distortion module 1020 sums the rate distortion of the one or more blocks to find the total rate distortion for the area when it is encoded according to the first mode. The block defining and rate distortion modules 1010 and 1020 then carry out the same process but for a second encoding mode. The rate distortion of the area when encoded by the second encoding mode is thus found. The process may be repeated for one or more further encoding modes. A com- parison module 1030 compares the rate distortion cost for each of the encoding modes (as computed by the module 1020) and selects one of the encoding modes to be used for encoding the data. For example the encoding mode with the lowest rate distortion cost may be chosen. Output module 1040 then outputs the encoded data which represents the area as encoded by the selected encoding mode. The output mod- ule 1040 may carry out the encoding itself, or alternatively read from a memory encoded data which was stored earlier in the process (for example the output of entropy encoding module 950 of FIG. 12).\n\nThe reduction in encoding time for the low motion sequence (Akiyo) was more than that for the high motion sequence (Stefan). A possible reason for this is that since the prediction accuracy of low motion sequence is better than that of high motion sequence, its residue is smaller and so less time is spent on the iterative table-lookup operation. FIG. 18 shows the average number of table-lookup operations for different video sequences in various QP values. The result indicates that the iterative table-lookup quantization process does not cost much time so that our proposed quantization method is practical. In addition, these experimental results are obtained using integer rounding precision in the compu- tation of the equation 22 in the JM encoder. The rate-distor- tion performance comparison of the conventional SSD and. proposed FSSD in terms of PSNR and bit-rate are shown in tables or FIGS. 19 to 22. These results show that the errors due to the clipping functions in computing the transform-domain SSD were small and the rate-distortion performance differ- ences between these two methods was less than 0.1% and 0.03 dB in terms of bit-rate and PSNR, respectively.\n\nSince the proposed FSSD computing method improved the computational efficiency of distortion measure with very little loss of rate-distortion performance, it could be com- bined with different types of H.264/AVC fast algorithms, such as fast inter/intra mode selection algorithms and rate estimation algorithm. Here, FSSD algorithm is combined with a conventional rate estimation method to reduce more computation complexity. The way to estimate the number of bits is:\n\nSimulation Results\n\nAn embodiment of the invention using the proposed itera- tive table-lookup quantization processing and FSSD compu- tation was tested using the first 100 frames from four video sequences (Akiyo, Foreman, Stefan and Container) all in QCIF format 176x144. They present different kinds of video sequences respectively: Akiyo (slow motion), Foreman and Container (medium motion), Stefan (high motion). The experiments were carried out in the JVT JM 8.3 encoder. Test parameters are listed below:\n\n(EQUATION 26)\n\nwhere total_zeros and total_coeff present the number of zeros and the number of non-zero coefficients respectively after quantization. SAD is the sum of absolute value of quan- tized transform coefficients. The experiences values of a and Pare 1 and 3. Experimental results are listed in the tables in FIGS. 23 to 26. From the results, the reduction of encoding time was about 30% to 40% with ignorable performance degradation. This indicates that the proposed FSSD algorithm can be easily combined with other fast H.264/AVC algo- rithms and achieves a good tradeoff between computation complexity and rate-distortion performance.\n\nTest condition:\n\nRate Distortion Optimization is enabled;\n\nCAVLC is enabled;\n\nGOP structure is IPPPIPPP;\n\nQP values are 28, 32, 36 and\n\nThe percentage of reduced time of calculating distortion is defined as:\n\nWhat is claimed is:\n\ncalculating sum squared between an original block S and a reconstructed block R of image or video data, the method comprising the steps of:\n\nTorgror ~ T proposed TOT (EQUATION 25) x 100% Torgror \u00b0 ATssp =\n\ncomputing a processor a predicted corre- sponding to the original block S, using inter or intra frame prediction,\n\nwhere Tszor is the computation time of the original H.264/AVC encoder using conventional spatial-domain SSD (S,C) algorithm; while Twoposearoris the computation time of a H.264/AVC encoder using the proposed FSSD compu- tation method according to an embodiment of the present invention. 55\n\ncalculating with the processor a residual block D from the original block S and the predicted block P, said residual block D having a plurality of coefficients,\n\n(c) applying with the processor an integer image transform to the coefficients of the residual block D so as to obtain a transformed residual block F*, said transformed residual block having a plurality of coefficients f*,,,\n\nThe tables in FIGS. 14-17 show the comparison of com- putation complexity between original JM encoder and an encoder using the proposed FSSD computation method. From the simulation results, we can conclude that the pro- posed FSSD computation method may reduce the encoding time by around 10% to 15% in different QP values. We estimate that about 4% to 7% reduction is achieved by the iterative table-lookup quantization process and 5% to 7% reduction is achieved by avoiding the inverse transform and pixel reconstruction. This was in a software simulation we 60 65\n\nfinding processor a plurality the coefficients fy being defined by the equation ne *QU,)): where Q is an operator which per- forms quantizing and Q\u2122 is the inverse of the Q opera- tor,\n\nwherein finding the coefficients comprises iteratively comparing the absolute value of each coefficient of the transformed residual block to boundaries quan- tization sub-zones in a look up table, said boundaries\n\n40.\n\n10\n\n15\n\n20\n\n25\n\n30\n\n40\n\n45\n\nto\n\nthe\n\nTotal_bits=c-total_zeros+P-total_coefi+SAD\n\n1. A method for\n\nthe\n\nof\n\ndifferences\n\n(a)\n\nwith\n\nblock P\n\n(b)\n\n(d)\n\nwith the\n\nof coefficients \u548c\n\nf*,,\n\nUS 8,019,804 B2\n\n23\n\n24\n\nof quantization Sub-Zones having progressively\n\n12. A method according to claim 11, wherein the encoding\n\nhigher quantization point values, until said absolute\n\nmode which will produce the lowest rate-distortion is\n\nselected.\n\nvalue of said coefficient is lower than a quantization\n\n13. A method of calculating the distortion caused by encod\n\nSub-Zone boundary, and\n\ning image or video data according to a first encoding mode,\n\n(e) computing with the processor a Sum of squared differ\n\nthe method comprising carrying out the steps of claim 1,\n\nences between f*, and f\n\nwherein in step (a) the predicted block is computed according\n\n2. A method according to claim 1, wherein the operator Q\n\nto said first encoding mode, and wherein the calculated dis\n\nperforms pre-scaled quantization.\n\ntortion is based on the Sum of squared differences computed\n\n3. A method according to claim 1, wherein the sum of\n\nin step (e).\n\n10\n\nsquared differences (SSD) is calculated according to the\n\n14. A method according to claim 1, wherein said integer\n\nequation\n\ntransform is an integer cosine transform.\n\n15. A method for calculating the sum of squared differ\n\nences between an original block S and a reconstructed block\n\nR of image or video data, the method comprising the steps of\n\n15\n\n(a) computing with a processor a predicted block P corre\n\nsponding to the original block S, using inter or intra\n\nframe prediction,\n\nwhere q is a scaling factor which depends upon the values of\n\n(b) calculating with the processor a residual block D from\n\ni and j.\n\nthe original block S and the predicted block P. said\n\n4. A method according to claim 1, wherein the iterative\n\nresidual block D having a plurality of coefficients,\n\ntable-look up process is carried out in parallel for each coef\n\n(c) applying with the processor an image transform to the\n\nficient f, of the transformed residual block.\n\ncoefficients of the residual block D so as to obtain a\n\n5. A method according to claim 1, wherein for each coef\n\ntransformed residual block F, said transformed residual\n\nblock having a plurality of coefficients,\n\nficient f* of said transformed residual block, said quantiza\n\n25\n\n(d) finding with the processor the coefficients of a first\n\ntion Sub-Zone boundaries and quantization point values,\n\nmatrix F, said first matrix being an inverse quantized\n\nreferred to in the look up table, depend on the position of the\n\ntransform of said residual block,\n\ncoefficient f* in the transformed residual block.\n\nwherein finding the coefficients comprises iteratively\n\n6. A method according to claim 1, further comprising the\n\ncomparing the absolute value of each coefficient of\n\n30\n\nstep of quantizing the coefficients of the transformed residual\n\nthe first matrix to boundaries quantization Sub-Zones\n\nblock F*, to obtain a quantized transformed residual block Z.\n\nin a look up table, said boundaries of quantization\n\n7. A method according to claim 6, wherein the step of\n\nSub-Zones having progressively higher quantization\n\nquantizing the coefficients is performed with the aid of a look\n\npoint values, until said absolute value of said coeffi\n\nup table.\n\ncient is lower than a quantization Sub-Zone boundary,\n\n35\n\n8. A method according to claim 6, further comprising the\n\nand\n\nstep of entropy encoding the quantized transformed residual\n\n(e) computing with the processor the Sum of squared dif\n\nblock Z.\n\nferences between said transformed residual block F and\n\n9. A method of calculating the rate-distortion caused by\n\nsaid first matrix F.\n\nencoding image or video data according to a first encoding\n\n16. A method according to claim 15, further comprising the\n\n40\n\nmode, the method comprising carrying out the steps of claim\n\nstep of quantizing the coefficients of said transformed\n\n8, wherein in step (a) the predicted block is computed accord\n\nresidual block F to obtain a quantized transformed residual\n\ning to said first encoding mode, and wherein the rate-distor\n\nblock Z.\n\ntion is calculated based on the sum of squared differences\n\n17. A system for calculating the sum of squared differences\n\ncomputed in step (e) and on the number of bits required to\n\nbetween an original block S and a reconstructed block R of\n\n45\n\nimage or video data; the system comprising:\n\nentropy encode the quantized transformed residual block Z.\n\na) a processor having a predicting module for predicting a\n\n10. A method according to claim 9, wherein said rate\n\npredicted block P. corresponding to an original block of\n\ndistortion is calculated by the formula J, SSD+WR, where\n\ndata S, by using inter or intra prediction,\n\nJ\n\nis a parameter representing the rate distortion, SSD is the\n\nb) the processor also having a residual block defining mod\n\nSum of squared differences computed in step (e), R is the\n\n50\n\nule for calculating a residual block D, which is the dif\n\nnumber of bits required to entropy encode the block, and is\n\nference between said predicted block P and said original\n\na Lagrange multiplier.\n\nblock S,\n\n11. A method of encoding video or image data, the method\n\nc) the processor further having a transform module for\n\ncomprising the steps of\n\nperforming an integer image transform on said residual\n\n55\n\ndefining an area in a frame of video or image data,\n\nblock D to obtain a transformed residual block F* having\n\ncalculating the rate-distortion which would be caused by\n\na plurality of co-efficients f*\n\nencoding said area according to a first encoding mode,\n\nd) the processor still further having an inverse quantization\n\nsaid rate-distortion being calculated by using the method\n\nmodule for finding a plurality of coefficients f, , the\n\nof claim 9,\n\ncoefficients f, being defined by the equation f-Q' (Q\n\n60\n\ncomparing said rate-distortion with the rate-distortion\n\n(f)), where Q is an operator which performs quantiz\n\nwhich would be caused by encoding said area according\n\ning and Q is the inverse of the Q operator,\n\nto a second encoding mode,\n\nwherein the inverse quantization module finds the coeffi\n\nSelecting one of said first and second encoding modes on\n\ncients by iteratively comparing the absolute value of\n\nthe basis of said comparison, and\n\neach coefficient f of the transformed residual block to\n\n65\n\nencoding said data according to the selected encoding\n\nboundaries quantization Sub-Zones in a look up table,\n\nsaid boundaries of quantization Sub-Zones having pro\n\nmode.\n\nUS 8,019,804 B2\n\n23\n\n24\n\n12. A method according to claim 11, wherein the encoding mode which will produce the lowest rate-distortion selected.\n\nof quantization sub-zones having progressively higher quantization point values, until said absolute value of said coefficient is lower than a quantization sub-zone boundary, and\n\n13. A method of calculating the distortion caused by encod- ing image or video data according to a first encoding mode, the method comprising carrying out the steps of claim 1, wherein in step (a) the predicted block is computed according to said first encoding mode, and wherein the calculated dis- tortion is based on the sum of squared differences computed. in step (e).\n\n(e) computing with the processor a sum of squared differ- ences between fy and \u5404\n\n2. A method according to claim 1, wherein the operator pre-scaled quantization.\n\n3. A method according to claim 1, wherein the sum squared differences (SSD) is calculated according to\n\n14. A method according to claim 1, wherein said integer transform is an integer cosine transform.\n\n15. A method for calculating the sum of squared differ- ences between an original block S and a reconstructed block R of image or video data, the method comprising the steps of:\n\n(a) computing with a processor a predicted block P corre- sponding to the original block S, using inter or intra frame prediction,\n\nwhere q,, is a scaling factor which depends upon the values iand j.\n\n(b) calculating with the processor a residual block D from the original block S and the predicted block P, said residual block D having a plurality of coefficients,\n\n4. A method according to claim 1, wherein the iterative table-look up process is carried out in parallel for each coef- ficient f,,* of the transformed residual block.\n\napplying with the processor an image transform to coefficients of the residual block D so as to obtain transformed residual block F, said transformed residual block having a plurality of coefficients,\n\n5. A method according to claim 1, wherein for each coef- ficient f,;\" of said transformed residual block, said quantiza- tion sub-zone boundaries and quantization point values, referred to in the look up table, depend on the position of the coefficient f,,* in the transformed residual block.\n\n(d) finding with the processor the coefficients of a first matrix F, said first matrix being an inverse quantized transform of said residual block,\n\nwherein finding the coefficients comprises iteratively comparing the absolute value of each coefficient of the first matrix to boundaries quantization sub-zones in a look up table, said boundaries of quantization sub-zones having progressively higher quantization point values, until said absolute value of said coeffi- cient is lower than a quantization sub-zone boundary, and\n\n6. A method according to claim 1, further comprising the of quantizing the coefficients of the transformed residual block F*, to obtain a quantized transformed residual block Z.\n\n7. A method according to claim 6, wherein the step quantizing the coefficients is performed with the aid ofa look table.\n\n35\n\n8. A method according to claim 6, further comprising the step of entropy encoding the quantized transformed residual block Z.\n\ncomputing with the processor the sum of squared dif- ferences between said transformed residual block F and said first matrix F.\n\n9. A method of calculating the rate-distortion caused by encoding image or video data according to a first encoding mode, the method comprising carrying out the steps of claim 8, wherein in step (a) the predicted block is computed accord- ing to said first encoding mode, and wherein the rate-distor- tion is calculated based on the sum of squared differences computed in step (e) and on the number of bits required to entropy encode the quantized transformed residual block Z.\n\n16. A method according to claim 15, further comprising step of quantizing the coefficients of said transforme residual block F to obtain a quantized transformed residua block Z.\n\n17. A system for calculating the sum of squared differences between an original block S and a reconstructed block Ro image or video data; the system comprising:\n\na) a processor having a predicting module for predicting a predicted block P, corresponding to an original block o. data S, by using inter or intra prediction,\n\n10. A method according to claim 9, wherein said rate- distortion is calculated by the formula J,,=SSD+A-R, where Jgp is a parameter representing the rate distortion, SSD is the sum of squared differences computed in step (e), R is the number of bits required to entropy encode the block, and is a Lagrange multiplier.\n\nb) the processor also having a residual block defining mod- ule for calculating a residual block D, which is the dif- ference between said predicted block P and said origina block S,\n\n11. A method of encoding video or image data, the metl comprising the steps of:\n\nc) the processor further having a transform module for performing an integer image transform on said residua block D to obtaina transformed residual block F* having a plurality of co-efficients fi\n\ndefining an area in a frame of video or image data,\n\ncalculating the rate-distortion which would be caused encoding said area according to a first encoding mode, said rate-distortion being calculated by using the method of claim 9,\n\nthe processor still further having an inverse quantization module for finding a plurality of coefficients fy , the coefficients \u2122,, being defined by the equation \u00a3,-Q\" Q (f*,,)), where Q is an operator which performs quantiz- ing and Q\u201d! is the inverse of the Q operator,\n\ncomparing said rate-distortion with the rate-distortion which would be caused by encoding said area according to a second encoding mode,\n\nwherein the inverse quantization module finds the coeffi- cients by iteratively comparing the absolute value of each coefficient f*,, of the transformed residual block to boundaries quantization sub-zones in a look up table, said boundaries of quantization sub-zones having pro-\n\nselecting one of said first and second encoding modes on the basis of said comparison, and\n\nencoding said data according to the selected enco mode. ing\n\nQ\n\nperforms\n\nof\n\nthe\n\nequation\n\nof\n\nstep\n\nof\n\nup\n\nby\n\nod\n\n10\n\n15\n\n20\n\n25\n\n30\n\n40\n\n45\n\n50\n\n55\n\n60\n\n65\n\nis\n\n(c)\n\nthe\n\na\n\n(e)\n\nthe\n\nd)\n\nUS 8,019,804 B2\n\n25\n\n26\n\ngressively higher quantization point values, until said\n\nencoding modes, said module being arranged to select\n\nthe encoding mode on the basis of a comparison of the\n\nabsolute value of said coefficient is lower than a quanti\n\nrespective rate-distortions of the possible encoding\n\nZation Sub-Zone boundary, and\n\ne) the processor still further having a difference function\n\nmodes.\n\ncomputing module for computing a sum of squared dif- 5\n\n20. A system according to claim 19, wherein the quantizing\n\nmodule and inverse quantizing module are provided as a\n\nferences between f, and f\n\n18. A system according to claim 17, wherein the Q operator\n\nsingle module.\n\nperforms pre-scaled quantizing.\n\n21. A non-transitory computer readable medium contain\n\n19. A system for encoding video or image data, the system\n\ning executable instructions stored thereon which, when\n\ncomprising a system for calculating the Sum of squared dif- 10\n\nexecuted, perform the following steps:\n\n(a) computing a predicted block P corresponding to the\n\nferences according to claim 17, wherein:\n\noriginal block S. using inter or intra frame prediction,\n\na) the processor still further has a block defining module for\n\n(b) calculating a residual block D from the original blockS\n\ndefining a first area in the video or image data, said area\n\nand the predicted block P. said residual block Dhaving a\n\ncomprising one or more blocks of data;\n\nplurality of coefficients\n\nb) the system according to claim 17 calculates the sum of 15\n\n(c) applying an integer image transform to the coefficients\n\nsquared differences between f, and f, when a block of\n\ndata in said area is encoded according to an encoding\n\nof the residual block D so as to obtain a transformed\n\nmode;\n\nresidual block F, said transformed residual block hav\n\ning a plurality of coefficients f*,\n\nc) the processor still further has a quantizing module for\n\n(d) finding a plurality of coefficients f, the coefficients\n\ncarrying out quantizing of the coefficients of the trans- 20\n\nf, being defined by the equation f-Q' (Q(?)),\n\nformed residual block F* to obtain a quantized trans\n\nwhere Q is an operator which performs quantizing and\n\nformed residual block Z:\n\nQ is the inverse of the Q operator,\n\nd) the processor still further has an entropy encoding mod\n\nule for entropy encoding the quantized transformed\n\nwherein finding the coefficients comprises iteratively\n\ncomparing the absolute value of each coefficient f,\n\nresidual block Z:\n\n25\n\ne) the processor still further has a rate-distortion calculat\n\nof the transformed residual block to boundaries quan\n\ning module for calculating the rate-distortion of an\n\ntization Sub-Zones in a look up table, said boundaries\n\nof quantization Sub-Zones having progressively\n\nencoding mode, based on the number of bits required to\n\nhigher quantization point values, until said absolute\n\nentropy encode one or more blocks of data according to\n\nsaid encoding mode and the Sum of squared differences 30\n\nvalue of said coefficient is lower than a quantization\n\nSub-Zone boundary, and\n\nbetween f, and f for one or more blocks of data\n\n(e) computing a sum of squared differences between f,\n\nencoded according to said encoding mode; and\n\nf) the processor still further has an encoding mode selec\n\nand f*\n\ntion module for selecting an encoding mode for encod\n\ning the video or image data from a plurality of possible\n\nUS 8,019,804 B2\n\n25\n\n26\n\ngressively higher quantization point values, until said absolute value of said coefficient is lower than a quanti- zation sub-zone boundary, and\n\nencoding modes, said module being arranged to select the encoding mode on the basis ofa comparison of the respective rate-distortions of the possible encoding modes.\n\ne) the processor still further having a difference function computing module for computing a sum of squared dif- ferences between fy and Pr,\n\n20. A system according to claim 19, wherein the quantizing module and inverse quantizing module are provided as module.\n\n18. A system according to claim 17, wherein the Q operator performs pre-scaled quantizing.\n\n21. A non-transitory computer readable medium contain- ing executable instructions stored thereon which, when executed, perform the following steps:\n\n19. A system for encoding video or image data, the system comprising a system for calculating the sum of squared dif- ferences according to claim 17, wherein:\n\n(a) computing a predicted block P corresponding to the original block S, using inter or intra frame prediction,\n\nprocessor further has a defining defining a first area in the video or image data, said area comprising one or more blocks of data;\n\n(b) calculating a residual block D from the original block S and the predicted block P, said residual block D having a plurality of coefficients\n\nb) the system according to claim 17 calculates the sum of squared differences between fy and f*,, when a block of data in said area is encoded according to an encoding mode;\n\n(c) applying an integer image transform to the coefficients of the residual block D so as to obtain a transformed residual block F*, said transformed residual block hav- inga plurality of coefficients fy\n\nprocessor a quantizing carrying out quantizing of the coefficients of the trans- formed residual block F* to obtain a quantized trans- formed residual block Z;\n\n(d) ing a plurality \u5404 , being defined by the equation te, pi QD \u2018Q&,)): where Q is an operator which performs \u2018quantizing and. Q\"' is the inverse of the Q operator,\n\nd) the processor still further has an entropy encoding mod- ule for entropy encoding the quantized transformed residual block Z;\n\nwherein finding the coefficients comprises iteratively comparing the absolute value of each coefficient f*,, of the transformed residual block to boundaries quan. tization sub-zones in a look up table, said boundaries of quantization sub-zones having progressively higher quantization point values, until said absolute value of said coefficient is lower than a quantization sub-zone boundary, and\n\ne) the processor still further has a rate-distortion calculat- ing module for calculating the rate-distortion of an encoding mode, based on the number of bits required to entropy encode one or more blocks of data according to said encoding mode and the sum of squared differences between f*,, and P*,, for one or more blocks of data encoded according to said encoding mode; and\n\n(e) computing a sum of squared differences between f*,, and fy\n\nf) the processor still further has an encoding mode selec- tion module for selecting an encoding mode for encod- ing the video or image data from a plurality of possible\n\na) the\n\nstill\n\nblock\n\nmodule for\n\nc) the\n\nstill further has\n\nmodule for\n\n\u7684\n\n10\n\n20\n\n25\n\n30\n\na\n\nsingle\n\nfin\n\nof coefficients\n\nthe coefficients", "type": "Document"}}