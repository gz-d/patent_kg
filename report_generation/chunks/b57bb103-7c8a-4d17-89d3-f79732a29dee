{"lc": 1, "type": "constructor", "id": ["langchain", "schema", "document", "Document"], "kwargs": {"metadata": {"source": "/home/guanzhideng145/research/ip_portal/patent_kg/patents/1023 outsourced (Done on website).pdf"}, "page_content": "20\n\ncollection process 206.\n\n[0045]\n\nFIG. 3 illustrates the pre-processing pipeline of structured data used in the\n\n25\n\n30\n\nstroke assessment system. Raw data 301 are the data received from data collection process 206. In certain embodiments, it is configured to generate a processed dataset for the machine learning models and deep learning models 113, 114, 115 and 116. The raw data have patients\u2019 information and three different types of data which are structured data, textural data, and image data. Of which, only the structured data is sent to first filter 302. The first filter 302 is used to filter non-stroke patients as they are not within the scope of this system. Some patients are classified as suspected patients because they have stroke-like symptoms, but after a series of clinical examinations, the diagnosis is cancelled or diagnosed with other diseases. Only samples that have been principle\n\ndiagnosed as a stroke can pass through the first filter 302. The second filter 303 pre-\n\nDocket No. UM1104HK00\n\n11\n\nHK 30057394 A\n\nprocesses the data to remove samples with excessive missing values as well as other\n\n5\n\n10\n\n15\n\nirrelevant samples. For a given feature, a certain threshold of missing values will be", "type": "Document"}}