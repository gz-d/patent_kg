{"lc": 1, "type": "constructor", "id": ["langchain", "schema", "document", "Document"], "kwargs": {"metadata": {"source": "/home/guanzhideng145/research/ip_portal/patent_kg/patents/1361_US11822732B1.pdf"}, "page_content": "US 11,822,732 B1\n\n9\n\n10\n\n(j)\n\nDown microgesture, (e) Swipe Left microgesture, (f) Swipe Right microgesture, (g) Triangle microgesture, (h) Check microgesture, (i) Counterclockwise Circle microgesture, and Clockwise Circle microgesture.\n\nIn the step S110: Wearing-angle training data sets are measured, by the receiving electrode portions RP of the receiving electrode layer 114, during a period of performing each of microgestures by two fingers of each of wearers under different wearing angles. In some embodiments, the wearing angle is, for example without limitation, 0 degree, 45 degrees, or 90 degrees.\n\n10\n\nIn the embodiments of the present invention, the interac- tive wearable device 100 is configured to recognize and analyze a movement event caused by an index finger and a thumb finger of the wearer. Specifically, the interactive wearable device 100 recognizes one or more known micro- gestures and provides a regression result of estimating a position of the thumb finger on the index finger of 1D continuous movement performed by two thumb and index fingers. In order to achieve the above objective, three ML models ML1, CM, ML2, are trained. Each of the training methods of the ML models ML1, CM, ML2 is fully described as follows.\n\nIn the step $120: A Convolutional Neural Network (CNN) based encoder-decoder ML model is trained with the wear- ing-angle training data sets in response to microgestures, thereby regenerating/reconstructing output electrical signals of each of the wearing-angle training data set. Referring to FIG. 7, in some embodiments, the CNN based encoder- decoder model includes six 2D convolutional layers for the encoder and six 2D transposed convolutional layers for the decoder.", "type": "Document"}}