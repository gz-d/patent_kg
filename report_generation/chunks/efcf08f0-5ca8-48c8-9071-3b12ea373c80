{"lc": 1, "type": "constructor", "id": ["langchain", "schema", "document", "Document"], "kwargs": {"metadata": {"source": "/home/guanzhideng145/research/ip_portal/patent_kg/patents/723-US20210044791A1(Pending) re (Done on website already).pdf"}, "page_content": "trative , not restrictive .\n\nConversion can be used to extract X - T or Y - T planes for\n\n1. A computer - implemented method for determining a\n\ntemporal flickering detection . The synthesized video data\n\nquality of a synthesized video file , comprising :\n\n( XYT ) can be decomposed as multiple XT or YT planes . The\n\nprocessing a reference video file and a synthesized video\n\nGradient Feature Extraction and Depth Image based Flicker\n\nDistortion Area Detection detect candidate flickering\n\nfile associated with the reference video file to compare\n\nregions and / or flickering features in the synthesized videos\n\nthe referencevideo file and the synthesized video file ;\n\nin XT or YT planes . The gradient feature of the depth map\n\nand\n\nmay be used as the feature to locate the flickering regions .\n\ndetermining an extent of flicker distortion of the synthe\n\nSparse representation can be adopted to represent the flick\n\nsized video file based on the processing .\n\nering features in 3D synthesized videos , in which the ampli\n\n2. The computer - implemented method of claim 1 ,\n\ntude and phase information can be jointly used to X - T or Y - T\n\nwherein determining an extent of flicker distortion of the\n\nplanes . The sparse representation can be 3D sparse repre\n\nsynthesized video file based on the comparison comprises :\n\nsentation , which is more complex , or 2D sparse represen\n\ndetermining respective extents of flicker distortion for\n\ntation ( to X - T or Y - T planes to capture the temporal flick\n\neach temporal frame of the synthesized video file ; and\n\nering features in synthesized video ) , which is less complex\n\ndetermining an overall extent of flicker distortion of the\n\nhence more computationally efficient . Amplitude and phase\n\nsynthesized video file based on the respective extents of\n\ninformation the learned 2D sparse representation can be\n\nflicker distortion .\n\nused to represent the temporal flickering features . A\n\n3. The computer - implemented method of claim 2 ,", "type": "Document"}}