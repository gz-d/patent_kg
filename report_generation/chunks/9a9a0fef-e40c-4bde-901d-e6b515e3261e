{"lc": 1, "type": "constructor", "id": ["langchain", "schema", "document", "Document"], "kwargs": {"metadata": {"source": "/home/guanzhideng145/research/ip_portal/patent_kg/patents/723-US20210044791A1(Pending) re (Done on website already).pdf"}, "page_content": "[0093] 3\u201d is the learned 3D dictionary. oa2 is a simpli- fied form of the sparse coeflicients of the overall 3D patches. ||, refers to the Li norm of the vector. ||a,3||, denotes that the sparse coefficient a7\u201d of patch i should satisfy the sparsity constraint, where u regulates the sparsity. p(X*\u201d) represents the task-driven constraint, and \u5165 regulates the weight of this term. The advantage of 3D sparse represen- tation is that it can learn 3D dictionaries for better repre- sentation ability. However, the computational complexity of learning 3D dictionaries increases dramatically. One alter- native solution is degrading 3D dictionary learning and approximating it with multi-layer 2D dictionaries. In fact, 2D sparse representation for 2D image (i.e., 2D-XY data) can be regarded as a special case or degradation of 3D sparse representation (i.e., 3D-XYT data) by fixing the temporal dimension. In order to represent the flicker distortion in the temporal domain of synthesized video, this embodiment attempts to keep the temporal dimension and fix either X or Y in the 3D sparse representation, 1.e., 2D-XT or 2D-YT plane. Then, the sparse representation is customized to represent the temporal flickering features for the synthesized video.", "type": "Document"}}