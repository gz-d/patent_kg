{"lc": 1, "type": "constructor", "id": ["langchain", "schema", "document", "Document"], "kwargs": {"metadata": {"source": "/home/guanzhideng145/research/ip_portal/patent_kg/patents/723-US20210044791A1(Pending) re (Done on website already).pdf"}, "page_content": "conventional spatial - temporal activity distortions ( such as\n\notube ( Xn , Yn , yn ) ,\n\nif otube ( Xn , Yn , in ) > T\n\n( 18 )\n\nRube\n\ncompression artifacts , rendering distortion , contour and hole\n\notherwise\n\nT ,\n\nartifacts ) in synthesized video .\n\n[ 0114 ] FIG . 8 shows a sparse representation based 3D\n\nwhere t is the perceptible threshold for spatial - temporal\n\nview quality assessment ( SR - 3DVQA ) method in one\n\ngradient standard deviation , and is set as 180 in this\n\nembodiment of the invention . The SR - 3DVQA model\n\nexample . Afterwards , the distortion score of a QA - GOP is\n\nmainly includes two modules : SR - FDM ( as presented\n\nFeb. 11, 2021\n\nUS 2021/0044791 Al\n\nwhere the weight map W(Uv) is obtained by\n\nabove) and the spatial-temporal activity distortion measure- ment. Both the original video and the distorted synthesized video are input into the two modules. Additionally, synthesized depth video is input into the SR-FDM module.\n\n. isk (12) wan {#9 cS 0, otherwise\n\n[0115] The overall quality score of a compressed synthe- sized video is predicted by pooling the flicker distortion score and the spatial-temporal activity distortion score.\n\nA, Spatial-Temporal Activity Distortion Measurement\n\nE. Weighted Pooling for Temporal Layers", "type": "Document"}}