{"lc": 1, "type": "constructor", "id": ["langchain", "schema", "document", "Document"], "kwargs": {"metadata": {"source": "/home/guanzhideng145/research/ip_portal/patent_kg/patents/723-US20210044791A1(Pending) re (Done on website already).pdf"}, "page_content": "layers in total were extracted . Temporal layer images with\n\nSR - 3DVQA test is conducted subsequently . Finally , the\n\npixel intensity are directly employed as the feature maps in\n\nimpacts of the pooling method and the reference depth video\n\ndictionary learning . These images were then divided into\n\nare evaluated .\n\npatches with size 8x8 and one - pixel overlap , which were\n\ncollected as the training dataset for temporal dictionary\n\nA. Canny Threshold Determination\n\nlearning .\n\n[ 0120 ]\n\nIt is important to choose a suitable Canny threshold\n\n[ 0124 ]\n\n2 ) Dataset and Settings for SR - 3DVQA Prediction :\n\nin depth edge detection for flicker area detection . In this\n\nThe SIAT synthesized video database of X. Liu , Y. Zhang ,\n\nexample , the edge detection effects among different canny\n\nS. Hu , S. Kwong , C. C. J. Kuo and Q. Peng , \u201c Subjective and\n\nthresholds are compared .\n\nobjective video quality assessment of 3D synthesized views\n\n[ 0121 ] FIGS . 10A to 121 demonstrate the relationship\n\nwith texture / depth compression distortion , IEEE Trans .\n\nImage Process . , vol . 24 , no . 12 , pp . 4847-4861 , December\n\nbetween the flicker areas in the synthesized view and the\n\nCanny thresholds in depth edge detection on sequence\n\n2015 was adopted as the testing dataset . This testing dataset\n\nis totally different from the learning dataset . This testing\n\n\u201c Balloons \" ( FIGS . 10A to 101 ) , \u201c Lovebird1 \" ( FIGS . 11A to\n\ndataset consists of 10 MVD sequences and 140 synthesized\n\n111 ) , and \" Undodancer \u201d ( FIGS . 12A to 121 ) . FIGS . 10A ,\n\nHA , and 12A are the respective synthesized textural image ,\n\nvideos in 1024x768 and 1920x1088 resolution which were\n\nobtained by 14 different combinations of compressed tex\n\nFIGS . 10B , 11B , and 12B are the respective depth image ,\n\nture / depth videos , namely generated with different quanti\n\nand FIGS . 10C - 101 , 11C - 111 , 12C - 121 are edge maps gen\n\nzation parameters . Each video was synthesized by two views", "type": "Document"}}