{"lc": 1, "type": "constructor", "id": ["langchain", "schema", "document", "Document"], "kwargs": {"metadata": {"source": "/home/guanzhideng145/research/ip_portal/patent_kg/patents/723-US20210044791A1(Pending) re (Done on website already).pdf"}, "page_content": "[0091] Sparse representation can be used to represent visual features and receptive field. In this embodiment, sparse representation is used to represent temporal flickering and to evaluate the 3D video quality.\n\nProcessing a reference depth video file associated with the reference video file for facilitating comparison of the refer-\n\nof the synthesized video file.\n\n1\n\n[0089]\n\nFor\n\na\n\nsynthesized view\n\nor\n\nvideo generated via\n\nflicker distortion).\n\nFIGS.\n\n2A and 2B\n\nillustrate\n\nof the\n\nFeb. 11 , 2021\n\nUS 2021/0044791 A1\n\n5\n\n[ 0092 ]\n\nConventional sparse representation and dictionary\n\ntion A ) , respectively . Then , each layer will be transformed to\n\ngradient feature map after gradient feature extraction ( sub\n\nlearning based on 2D spatial patches were used to represent\n\nthe 2D image features . Currently , 3D dictionary learning ,\n\nsection B ) . Afterwards , for each layer , the location of\n\npossible flicker distortion is identified through flicker dis\n\nwhich further include the temporal or depth dimension , has\n\nbeen employed in several video applications , such as online\n\ntortion detection module with the help of the associated\n\ndepth video ( subsection C ) . Subsequently , flicker distortion\n\nsequence de - noising in M. Protter and M. Elad ,\n\n\u201c Image\n\nSequence Denoising via Sparse and Redundant Represen\n\nstrengths are measured through the sparse coefficients fea\n\ntations , \u201d IEEE Trans . Image Process . , vol . 18 , no . 1 , pp .\n\ntures at the identified flicker distortion location , and the\n\nsparse representation is based on the learned temporary\n\n27-35 , January 2009 , video super - resolution in H. Xiang , Z.\n\ndictionary through training stage ( subsection D ) . Finally , the\n\nPan , X. Ye and C. W. Chen , \u201c Sparse spatio - temporal rep\n\nresentation with adaptive regularized dictionary learning\n\noverall flicker distortion score is obtained by weighted layer\n\npooling ( subsection E ) .\n\nfor Low bitrate video coding , \u201d IEEE Trans . Circuits Syst .", "type": "Document"}}