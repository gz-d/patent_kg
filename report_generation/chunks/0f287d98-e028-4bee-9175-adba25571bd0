{"lc": 1, "type": "constructor", "id": ["langchain", "schema", "document", "Document"], "kwargs": {"metadata": {"source": "/home/guanzhideng145/research/ip_portal/patent_kg/patents/1361_US11822732B1.pdf"}, "page_content": "10\n\n20\n\n30\n\nprocessor P, on each of the electrical output signals in each the measurement frames of each of the gesture samples X, as to extract the temporal gradient feature set dT(X) response to the corresponding known microgesture, which dT(X)eRO\u2122.\n\nof\n\nso\n\nIn the step $270: a final feature set F(X) in response to the corresponding known microgesture is determined, by the processor P, with according to at least one of the correspond- ing channel-wise gradient feature set dC(X) and the corre- sponding temporal gradient feature set dT(X). In some embodiments, only the channel-wise gradient feature set dC(X) serves as the final feature set F(X). In some embodi- ments, only the temporal gradient feature set dT(X) serves as the final feature set F(X). In some embodiments, a combination of the channel-wise gradient feature set dC(X) and the temporal gradient feature set dT(X), in which F(X)=dC(X)UdT(X),eRo*\u2122, serves as the final feature set F(X).\n\nIn the step $280: the ML model ML1 is selected, by processor P, according to a signal type of the feature\n\nF(X).\n\nFor example, in some embodiments, if the signal type of the final feature set F(X) is time-domain, the ML model ML1 is selected, by the processor \u4e86 from a support vector machine (SVM) model, a multilayer perceptron (MLP) model, or a convolutional neural network (CNN) model.\n\nIn some embodiments, a Short-time Fourier transform (STFT) operation is performed on each feature channel of the final feature set F(X), such that signal type of the feature set F(X) is transformed into frequency-domain. Under such acondition, the ML model ML1 is selected, by the processor P, from a visual geometry group (VGG) model, a visual geometry group (VGG) model, a residual networks (ResNet) model, a densely connected convolutional network (DenseNet) model, or a vision transformer (ViT) model.", "type": "Document"}}