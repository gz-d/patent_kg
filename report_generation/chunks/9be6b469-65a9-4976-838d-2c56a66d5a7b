{"lc": 1, "type": "constructor", "id": ["langchain", "schema", "document", "Document"], "kwargs": {"metadata": {"source": "/home/guanzhideng145/research/ip_portal/patent_kg/patents/723-US20210044791A1(Pending) re (Done on website already).pdf"}, "page_content": "distortion to avoid the interference of the static situation . For\n\na static object , an arbitrary point on its boundaries as time\n\ndistortion assessment . As shown in FIG . 3 , first , an original\n\nvideo and the distorted synthesized video are converted to\n\nvaries would be a vertical line , which would result in large\n\nhorizontal gradient in temporal layer .\n\nthe temporal layers via temporal layer conversion ( subsec\n\nFeb. 11, 2021\n\nUS 2021/0044791 Al\n\ntion A), respectively. Then, each layer will be transformed to gradient feature map after gradient feature extraction (sub- section B). Afterwards, for each layer, the location of possible flicker distortion is identified through flicker dis- tortion detection module with the help of the associated depth video (subsection C). Subsequently, flicker distortion strengths are measured through the sparse coeflicients fea- tures at the identified flicker distortion location, and the sparse representation is based on the learned temporary dictionary through training stage (subsection D). Finally, the overall flicker distortion score is obtained by weighted layer pooling (subsection E).", "type": "Document"}}