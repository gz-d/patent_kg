{"lc": 1, "type": "constructor", "id": ["langchain", "schema", "document", "Document"], "kwargs": {"metadata": {"source": "/home/guanzhideng145/research/ip_portal/patent_kg/patents/1361_US11822732B1.pdf"}, "page_content": "temporal gradient operation, the method further comprising: for each of the microgesture training data sets,\n\ndenoising each of the gesture samples; and\n\nperforming a Fourier re-sampling operation on each of the denoised gesture samples.\n\n15. The method of claim 9, wherein before the step of training the ML model, further comprising:\n\nselecting the ML model, by the processor, according to signal type of the final feature set.\n\n16. A machine learning (ML) based training method to train a wearable device to track a position of a thumb finger on an index finger during a period of performing a one- dimensional (1D) continuous movement by the thumb finger and the index finger, the method comprising:\n\na\n\n40\n\nmeasuring each of the 1D-continuous-movement training data sets, by the processor, while the thumb finger the corresponding wearer moves between two positions on the index finger of the corresponding wearer lowing the moving of the reference slider.\n\n18. The method of claim 17, wherein the ML regression model is trained with the feature sets and a ground-truth information about position information of the first second positions on the screen.\n\n19. The method of claim 17, wherein the ML regression model comprises a k-nearest neighbors (KNN) model, Epsilon-Support Vector Regression (\u20ac-SVR) model, or small multilayer perceptron (MLP) model.\n\n\u515a \u4e8b \u7576 \u515a\n\nof\n\nin\n\na\n\nthe\n\nthe\n\non\n\n1D\n\nthe\n\nof\n\nfol-\n\nand.\n\nan\n\na", "type": "Document"}}