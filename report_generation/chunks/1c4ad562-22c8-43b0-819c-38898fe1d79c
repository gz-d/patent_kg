{"lc": 1, "type": "constructor", "id": ["langchain", "schema", "document", "Document"], "kwargs": {"metadata": {"source": "/home/guanzhideng145/research/ip_portal/patent_kg/patents/723-US20210044791A1(Pending) re (Done on website already).pdf"}, "page_content": "there are multiple views of colour videos and corresponding\n\nsystem and method for determining a quality of a synthe\n\ndepth videos to represent the 3D video . This is denoted as\n\nsized video file such as a synthesized view video file of 3D\n\n\u201c multi - view video plus depth ( MVD ) \" . In these cases , the\n\nor VR video system .\n\ndepth video file ( or reference depth video file ) is part of the\n\n[ 0006 ]\n\nIn accordance with a first aspect of the invention ,\n\nthere is provided a computer - implemented method for deter\n\n3D video file .\n\n[ 0015 ]\n\nPreferably , processing the reference depth video\n\nmining a quality of a synthesized video file . The method\n\nfile includes : processing the reference depth video file to\n\nincluding : processing a reference video file and a synthe\n\ndetect edges of the reference depth video file to generate a\n\nsized video file associated with the reference video file to\n\ndepth edge video file ; and segmenting the depth edge video\n\ncompare the reference video file and the synthesized video\n\nfile into a plurality of temporal depth layers .\n\nfile ; and determining an extent of flicker distortion of the\n\n[ 0016 ]\n\nPreferably , processing the reference depth video\n\nsynthesized video file based on the processing . The synthe\n\nfile further includes : processing the temporal depth layers to\n\nsized video file may be a 3D video file containing 3D video\n\nexpand the detected edge width in the temporal depth layers .\n\ndata , or it may be a virtual reality video file containing\n\n[ 0017 ]\n\nPreferably , processing the reference video file and\n\nvirtual reality video data .\n\nthe synthesized video file further includes : processing the\n\n[ 0007 ]\n\nIn one embodiment of the first aspect , the synthe\n\ntemporal gradient layers of the reference video file based on\n\nsized video at virtual viewpoint is rendered from the colour\n\nthe temporal depth layers to obtain weighted temporal\n\nvideos and depth videos of the neighboring real viewpoints ,", "type": "Document"}}