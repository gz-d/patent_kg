{"lc": 1, "type": "constructor", "id": ["langchain", "schema", "document", "Document"], "kwargs": {"metadata": {"source": "/home/guanzhideng145/research/ip_portal/patent_kg/patents/723-US20210044791A1(Pending) re (Done on website already).pdf"}, "page_content": "[0097] Therefore, to assess the flicker distortion more effectively, this embodiment converts the distorted 3D syn- thesized video V into temporal layers {L,}, ie., 2D-XT Jane, as shown in the left part of the FIG. 4. It can be observed that the intense movement of the human and the variable motion of one point along the rim of the pillar are represented as a drastically twisted stripe and a smooth curve line respectively. This illustrates that the temporal layer can capture the temporal features. In addition, the distortion in the patches with flicker distortion is obvious, e.g., the crumbling and disorderly edges, while the non- flicker patch has clear edges. This phenomenon implies that the flicker distortion could be captured in the temporal layer. Thus, the original view V, and the distorted synthesized view Vz are converted to sets of temporal layers {L,,} and respectively.\n\nB. Gradient Feature Extraction\n\nI. Sparse Representation Based Flicker Distortion Measurement (SR-FDM)\n\n[0098] The gradient features are more suitable to extract the flicker distortion as compared with the pixel intensity itself because: (1) human eyes are sensitive to the change rate of the intensity which leads to the significant change in the gradient; and (2) the flicker distortion caused by tem- poral inconsistency of depth map usually locate at edges or regions with gradient. In this embodiment, vertical gradient features of the temporal layers are used to capture the flicker distortion to avoid the interference of the static situation. For a static object, an arbitrary point on its boundaries as time varies would be a vertical line, which would result in large horizontal gradient in temporal layer.", "type": "Document"}}