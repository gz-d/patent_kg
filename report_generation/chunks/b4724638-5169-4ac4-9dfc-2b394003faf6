{"lc": 1, "type": "constructor", "id": ["langchain", "schema", "document", "Document"], "kwargs": {"metadata": {"source": "/home/guanzhideng145/research/ip_portal/patent_kg/patents/723-US20210044791A1(Pending) re (Done on website already).pdf"}, "page_content": "and determining an overall extent of spatial - temporal activ\n\nmetrical distortions among frames ( also known as temporal\n\nflicker distortion ) .\n\nity distortion of the synthesized video file based on the\n\nrespective extents of spatial - temporal activity distortion .\n\n[ 0090 ] FIGS . 2A and 2B illustrate an example of the\n\nOptionally , the respective extents of spatial - temporal activ\n\nflicker distortion along the rim of a pillar in the synthesized\n\nity distortion for each temporal frame of the synthesized\n\nvideo with depth compression distortion of Undodancer . It\n\nvideo file are weighted to determine the overall extent of\n\ncan be observed that the intensity of point A in the original\n\nspatial - temporal activity distortion .\n\nview ( FIG . 2A ) changes little and relatively smoothly in the\n\n[ 0088 ] One specific implementation of the method of FIG .\n\ntwenty frames . In contrast , the intensity of corresponding\n\n1 is presented below . Table I shows the definitions of key\n\npoint in synthesized view ( FIG . 2B ) , i.e. , point Asm in the\n\nsymbols or variables used in the following disclosure .\n\nsynthesized view , fluctuated drastically in temporal domain .\n\nThis would appear unnatural to the viewers , potentially\n\nTABLE I\n\nannoying them . Existing 2D and 3D view quality assessment\n\nDefinitions of Key Symbols or Variables\n\n( VQA ) metrics have not well considered the properties of\n\nthe synthesized virtual view videos and the flicker distortion .\n\nDescriptions\n\nVariables\n\nTherefore , there is a need for a more effective quality\n\nThe i - th temporal layer of the video V\n\nL ;\n\nassessment method for application in synthesized videos .\n\nTemporal layers set denotation of video V\n\n{ L ; ll sis H }\n\nLa } , { Lai\n\nThe original and distorted video V , and Va\n\n[ 0091 ]\n\nSparse representation can be used to represent\n\ndenoted by temporal layers set , respectively\n\nvisual features and receptive field . In this embodiment ,\n\nThe pixel value ( x , y , t ) in video V", "type": "Document"}}